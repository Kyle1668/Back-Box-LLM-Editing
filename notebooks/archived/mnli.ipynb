{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\").to(device)\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Premise</th>\n",
       "      <th>Hypothesis</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It focuses on desktop, client/server, and ente...</td>\n",
       "      <td>It lacks focus on desktop and enterprise compu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huh do you have your own kiln or do you do you</td>\n",
       "      <td>Did somebody give you your kiln?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no chemicals and plus then you can use it as a...</td>\n",
       "      <td>You can use those chemicals as a fertilizer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In Texas, the legislature was instrumental in ...</td>\n",
       "      <td>The benefit program in place already had littl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 1654 Oliver Cromwell, Lord Protector of Eng...</td>\n",
       "      <td>Cromwell sent nobody to the Caribbean.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Premise   \n",
       "0  It focuses on desktop, client/server, and ente...  \\\n",
       "1     huh do you have your own kiln or do you do you   \n",
       "2  no chemicals and plus then you can use it as a...   \n",
       "3  In Texas, the legislature was instrumental in ...   \n",
       "4  In 1654 Oliver Cromwell, Lord Protector of Eng...   \n",
       "\n",
       "                                          Hypothesis  Label  \n",
       "0  It lacks focus on desktop and enterprise compu...      2  \n",
       "1                   Did somebody give you your kiln?      1  \n",
       "2        You can use those chemicals as a fertilizer      2  \n",
       "3  The benefit program in place already had littl...      2  \n",
       "4             Cromwell sent nobody to the Caribbean.      2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_test_set = pd.read_csv(\"/home/kyle/repos/Parameter-Free-LM-Editing/datasets/boss_benchmark/NaturalLanguageInference/mnli/test.tsv\", sep=\"\\t\")\n",
    "mnli_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'entailment', 'score': 0.7289925813674927}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_entry = mnli_test_set.iloc[9810]\n",
    "classifier(test_entry[\"Premise\"] + \" - \" + test_entry[\"Hypothesis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"It focuses on desktop, client/server, and enterprisewide computing. / It lacks focus on desktop and enterprise computing sector.\")[0][\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicitons = []\n",
    "labels = []\n",
    "for i in range(len(mnli_test_set)):\n",
    "    current_entry = mnli_test_set.iloc[i]\n",
    "    input_text = current_entry[\"Premise\"] + \" / \" + current_entry[\"Hypothesis\"]\n",
    "    label = current_entry[\"Label\"]\n",
    "    \n",
    "    tokenized_input = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    logits = model(**tokenized_input).logits\n",
    "    prediction = model.config.id2label[logits.argmax().item()].lower()\n",
    "    \n",
    "    token_label_map = {\n",
    "        \"entailment\": 0,\n",
    "        \"neutral\": 1,\n",
    "        \"contradiction\": 2\n",
    "    }   \n",
    "    predicitons.append(token_label_map[prediction])\n",
    "    labels.append(label)\n",
    "     \n",
    "    break\n",
    "\n",
    "\n",
    "display(predicitons)\n",
    "display(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
