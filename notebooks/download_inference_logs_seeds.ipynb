{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json5 as json\n",
    "# import json\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"kyledevinobrien1/In-Context Domain Transfer Improves Out-of-Domain Robustness\"\n",
    "seeds = [3, 17]\n",
    "all_table_paths = {}\n",
    "for seed in seeds:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    # handle comments in json\n",
    "    seed_table_path = json.load(open(f\"wandb_paths/wandb_path_seed={seed}.json\"))\n",
    "    all_table_paths[seed] = seed_table_path\n",
    "    print(json.dumps(seed_table_path, indent=4))\n",
    "\n",
    "all_table_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_logs_path(directory):\n",
    "    try:\n",
    "        for contents in os.listdir(directory):\n",
    "            if contents.endswith(\"style_logs.table.json\"):\n",
    "                return os.path.join(directory, contents)\n",
    "\n",
    "            if os.path.isdir(os.path.join(directory, contents)):\n",
    "                return get_local_logs_path(os.path.join(directory, contents))\n",
    "    except:\n",
    "        # print(\"No style logs found in {}\".format(directory))\n",
    "        return None\n",
    "\n",
    "print(get_local_logs_path(\"data/BOSS_Toxicity_ID_Falcon_Paraphrase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each table path, run.use_artifact and download the artifact.\n",
    "local_paths = {}\n",
    "missing_tables = []\n",
    "for seed in all_table_paths:\n",
    "    local_paths[seed] = {}\n",
    "    for table_name, table_path in tqdm(list(all_table_paths[seed].items())[:]):\n",
    "        try:\n",
    "            if table_path == \"\":\n",
    "                missing_tables.append(table_name)\n",
    "                continue\n",
    "\n",
    "            if get_local_logs_path(f\"data/{seed}/{table_name}\") is None:\n",
    "                download_path = f\"{project_name}/{table_path}\"\n",
    "                print(f\"Downloading {table_name} --- {download_path}\")\n",
    "                artifact = run.use_artifact(download_path, type=\"run_table\")\n",
    "                artifact_dir = artifact.download(root=f\"data/{seed}/{table_name}\")\n",
    "\n",
    "            local_paths[seed][table_name] = get_local_logs_path(f\"data/{seed}/{table_name}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(table_name)\n",
    "            missing_tables.append(table_name)\n",
    "\n",
    "        # print(json.dumps(missing_tables, indent=4))\n",
    "\n",
    "local_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_renaming = {\n",
    "    \"entropy\": \"tta_prediction_entropy\",\n",
    "    \"mean probs\": \"tta_mean_class_probs\",\n",
    "    \"all probs\": \"tta_all_class_probs\",\n",
    "    \"all entropies\": \"tta_all_class_entropy\",\n",
    "    \"latency\": \"tta_inference_latency\",\n",
    "    \"input\": \"augmentations\",\n",
    "    \"original_input\": \"original_text\",\n",
    "    \"judgment\": \"tta_predicted_class\",\n",
    "    \"original judgment\": \"original_predicted_class\",\n",
    "    \"original entropy\": \"original_prediction_entropy\",\n",
    "    \"entropy decrease\": \"prediction_entropy_decrease\",\n",
    "    \"entropy decreased\": \"prediction_entropy_decreased\",\n",
    "}\n",
    "columns_to_drop = [\"style prompt\", \"mean exemplar distance\", \"prompt\"]\n",
    "columns_order = [\"outcome\", \"original_text\", \"augmentations\", \"generations\", \"original_predicted_class\", \"tta_predicted_class\", \"label\", \"tta_inference_latency\", \"original_prediction_entropy\", \"tta_prediction_entropy\", \"prediction_entropy_decreased\", \"prediction_entropy_decrease\", \"tta_mean_class_probs\", \"tta_all_class_probs\", \"tta_all_class_entropy\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_augmentations(augmentations):\n",
    "    if augmentations is None or len(augmentations) == 0:\n",
    "        return []\n",
    "\n",
    "    return [aug.replace(\"<aug>\", \"\").replace(\"</aug>\", \"\") for aug in augmentations[:4]]\n",
    "\n",
    "formatted_augs = parse_augmentations([ \"<aug>too not much of anything this well - well acted but dangerously slow thriller feels somehow like simply a terrible preamble to a bigger, much more too complicated horror story, one reality that never materializes.</aug>\", \"<aug>one too too much apprehension of this well - being acted but dangerously still slow thriller feels like only a preamble to a seemingly bigger, yet more more complicated story, and one that never materializes.</aug>\", \"<aug>too much of this a well - well acted but dangerously slow thriller film feels like a big preamble opening to a somehow bigger, more complicated dream story, the one concept that almost never materializes.</aug>\", \"<aug>too am much of this this well - acted but dangerously slow paced thriller feels somehow like a prime preamble to creating a bigger, more painfully complicated story, but one one that never ever materializes.</aug>\", \"<aug>Too much of this well-acted but dangerously slow thriller feels like a preamble to a bigger , more complicated story , one that never materializes .</aug>\", \"<aug>Too much of this well-acted but dangerously slow thriller feels like a preamble to a bigger , more complicated story , one that never materializes .</aug>\" ])\n",
    "\n",
    "print(formatted_augs)\n",
    "print(len(formatted_augs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datset = DatasetDict()\n",
    "for seed in local_paths:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    for split in tqdm(local_paths[seed]):\n",
    "        path = local_paths[seed][split]\n",
    "        json_logs = json.load(open(path))\n",
    "        frame = pd.DataFrame(data=json_logs[\"data\"], columns=json_logs[\"columns\"])\n",
    "        frame = frame.rename(columns=column_renaming)\n",
    "        frame = frame.drop(columns=columns_to_drop)\n",
    "        frame[\"augmentations\"] = frame[\"augmentations\"].apply(parse_augmentations)\n",
    "\n",
    "        if \"BERT\" not in split:\n",
    "            for col in columns_order:\n",
    "                if col not in frame.columns:\n",
    "                    if col == \"original_prediction_entropy\" or col == \"tta_prediction_entropy\" or col == \"prediction_entropy_decrease\":\n",
    "                        frame[col] = float(\"nan\")\n",
    "                    elif col == \"prediction_entropy_decreased\":\n",
    "                        frame[col] = False\n",
    "                    elif col == \"tta_all_class_probs\":\n",
    "                        frame[col] = frame.apply(lambda x: [[float(0.0)]], axis=1)\n",
    "                    elif \"probs\" in col:\n",
    "                        frame[col] = frame.apply(lambda x: [float(0.0)], axis=1)\n",
    "                    elif col == \"tta_all_class_entropy\":\n",
    "                        frame[col] = frame.apply(lambda x: [float(0.0)], axis=1)\n",
    "\n",
    "        if \"generations\" not in frame.columns:\n",
    "            frame[\"generations\"] = [[\"\"]] * len(frame)\n",
    "\n",
    "        frame = frame[columns_order]\n",
    "        formatted_split_name = f\"seed={seed}_{split}\"\n",
    "        combined_datset[formatted_split_name] = Dataset.from_pandas(frame)\n",
    "\n",
    "combined_datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datset.save_to_disk(\"data/combined_dataset_multiseed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(combined_datset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(combined_datset[\"BOSS_Toxicity_ID_BERT_Insert\"].features) == len(combined_datset[\"BOSS_Toxicity_ID_T5_Insert\"].features)\n",
    "for feature, value_data in combined_datset[\"BOSS_Toxicity_ID_BERT_Insert\"].features.items():\n",
    "    bert_dtype = value_data.dtype\n",
    "    t5_dtype = combined_datset[\"BOSS_Toxicity_ID_T5_Insert\"].features[feature].dtype\n",
    "    error_message = f\"Feature {feature} has different dtypes for BERT and T5: {bert_dtype} and {t5_dtype}\"\n",
    "    assert bert_dtype == t5_dtype, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datset[\"BOSS_Sentiment_ID_BERT_ICR\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datset[\"BOSS_Sentiment_ID_T5_Insert\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_datset.push_to_hub(\"Kyle1668/LLM-TTA-Augmentation-Logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_datset.push_to_hub(\"Kyle1668/LLM-TTA-Augmentation-Logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ValueError: All datasets in `DatasetDict` should have the same features but features for 'BOSS_Sentiment_ID_BERT_ICR' and 'BOSS_Sentiment_ID_T5_Insert' don't match: \n",
    "\n",
    "{'outcome': Value(dtype='string', id=None), \n",
    "'original_text': Value(dtype='string', id=None), \n",
    "'augmentations': Sequence(feature=Value(dtype='string', id=None),length=-1, id=None), 'generations': Sequence(feature=Value(dtype='null', id=None), length=-1, id=None), 'original_predicted_class': Value(dtype='int64', id=None), 'tta_predicted_class': Value(dtype='int64', id=None), 'label': Value(dtype='int64', id=None), 'tta_inference_latency': Value(dtype='float64', id=None), 'original_prediction_entropy': Value(dtype='float64', id=None), 'tta_prediction_entropy': Value(dtype='float64', id=None), 'prediction_entropy_decreased': Value(dtype='bool', id=None), 'prediction_entropy_decrease': Value(dtype='float64', id=None), 'tta_mean_class_probs': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'tta_all_class_probs': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None), 'tta_all_class_entropy': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)} != \n",
    "\n",
    "{'outcome': Value(dtype='string', id=None), 'original_text': Value(dtype='string', id=None), 'augmentations': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'generations': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'original_predicted_class': Value(dtype='int64', id=None), 'tta_predicted_class': Value(dtype='int64', id=None), 'label': Value(dtype='int64', id=None), 'tta_inference_latency': Value(dtype='float64', id=None), 'original_prediction_entropy': Value(dtype='float64', id=None), 'tta_prediction_entropy': Value(dtype='float64', id=None), 'prediction_entropy_decreased': Value(dtype='bool', id=None), 'prediction_entropy_decrease': Value(dtype='float64', id=None), 'tta_mean_class_probs': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'tta_all_class_probs': Sequence(feature=Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), length=-1, id=None), 'tta_all_class_entropy': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-aug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
