{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate ICL Methods on Selected Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from openicl import DatasetReader, PromptTemplate, TopkRetriever, PPLInferencer, AccEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wilds import get_dataset\n",
    "# from wilds.common.data_loaders import get_train_loader\n",
    "# dataset = get_dataset(dataset=\"amazon\", download=True)\n",
    "# display(dataset)\n",
    "\n",
    "# for record in dataset.get_subset(\"train\"):\n",
    "#     print(record)\n",
    "#     break\n",
    "\n",
    "# train_dict = {\n",
    "#     \"text\": [],\n",
    "#     \"label\": [],\n",
    "#     \"reviewer_id\": []\n",
    "# }\n",
    "# for text, label, reviewer_id in dataset.get_subset(\"train\"):\n",
    "#     train_dict[\"text\"].append(text)\n",
    "#     train_dict[\"label\"].append(label.item())\n",
    "#     train_dict[\"reviewer_id\"].append(reviewer_id.tolist())\n",
    "\n",
    "# test_dict = {\n",
    "#     \"text\": [],\n",
    "#     \"label\": [],\n",
    "#     \"reviewer_id\": []\n",
    "# }\n",
    "# for text, label, reviewer_id in dataset.get_subset(\"test\"):\n",
    "#     test_dict[\"text\"].append(text)\n",
    "#     test_dict[\"label\"].append(label.item())\n",
    "#     test_dict[\"reviewer_id\"].append(reviewer_id.tolist())\n",
    "\n",
    "# full_dataset = DatasetDict()\n",
    "# full_dataset[\"train\"] = Dataset.from_pandas(pd.DataFrame(train_dict))\n",
    "# full_dataset[\"test\"] = Dataset.from_pandas(pd.DataFrame(test_dict))\n",
    "# full_dataset\n",
    "\n",
    "# display(full_dataset[\"train\"].to_pandas().head())\n",
    "# display(full_dataset[\"test\"].to_pandas().head())\n",
    "\n",
    "# full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset[\"test\"].to_pandas().value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/kyle/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 26.30it/s]\n",
      "[2023-04-26 21:51:30,191] [openicl.icl_retriever.icl_topk_retriever] [INFO] Creating index for index set...\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 1000/1000 [00:27<00:00, 36.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a DatasetReader, with specified column names where input and output are stored.\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(1000))\n",
    "dataset[\"test\"] = dataset[\"test\"].select(range(1000))\n",
    "data = DatasetReader(dataset, input_columns=[\"text\"], output_column=\"label\")\n",
    "tp_dict = {\n",
    "    0: \"</E>World (0) Article: </text>\",\n",
    "    1: \"</E>Sports (1) Article: </text>\",\n",
    "    2: \"</E>Business (2) Article: </text>\",\n",
    "    3: \"</E>Sci/Tech (3) Article: </text>\",\n",
    "}\n",
    "\n",
    "template = PromptTemplate(tp_dict, {'text': '</text>'}, ice_token='</E>')\n",
    "\n",
    "# TopK Retriever\n",
    "retriever = TopkRetriever(data, ice_num=2, index_split='train', test_split='test')\n",
    "\n",
    "# # Define a Inferencer\n",
    "# inferencer = PPLInferencer(model_name='distilgpt2')\n",
    "\n",
    "# # Inference\n",
    "# predictions = inferencer.inference(retriever, ice_template=template, output_json_filename='sst2')\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Gunmen ambush Chalabi #39;s convoy, wound 2 BAGHDAD - Gunmen ambushed the convoy of former Iraqi governing council president Ahmed Chalabi on Wednesday, wounding two of his bodyguards, aides said.',\n",
       " 'label': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape: (1, 768)\n",
      "distances: [[0.5458629 0.535096  0.52293  ]]\n",
      "indices: [[989 505 569]]\n",
      "\n",
      "2 More Turkish Men Taken Hostage in Iraq (AP) AP - Armed assailants attacked a convoy of Turkish trucks delivering supplies to U.S. forces in Iraq and took two Turkish drivers hostage, their company said Monday.\n",
      "0\n",
      "\n",
      "Mortars Mark Opening of Iraqi Political Conference  BAGHDAD (Reuters) - Insurgents fired mortars at a meeting  where Iraqi leaders met to pick an interim national assembly  Sunday, killing at least two people in a grim reminder of the  country's tortured path toward democracy.\n",
      "0\n",
      "\n",
      "Mortars Mark Opening of Iraqi Political Conference (Reuters) Reuters - Insurgents fired mortars at a meeting\\where Iraqi leaders met to pick an interim national assembly\\Sunday, killing at least two people in a grim reminder of the\\country's tortuous path toward democracy.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entry in which we wish to edit\n",
    "input_entry = dataset[\"test\"][999]\n",
    "display(input_entry)\n",
    "\n",
    "# input_ids.shape\n",
    "example_embedding = retriever.model.encode([input_entry[\"text\"]], convert_to_numpy=True)\n",
    "distances, indices = retriever.index.search(example_embedding, 3)\n",
    "\n",
    "print(f\"embedding shape: {example_embedding.shape}\")\n",
    "print(f\"distances: {distances}\")\n",
    "print(f\"indices: {indices}\")\n",
    "\n",
    "for index in indices[0]:\n",
    "    print()\n",
    "    print(dataset[\"train\"][int(index)][\"text\"])\n",
    "    print(dataset[\"train\"][int(index)][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'World (0) Article: Gunmen ambush Chalabi #39;s convoy, wound 2 BAGHDAD - Gunmen ambushed the convoy of former Iraqi governing council president Ahmed Chalabi on Wednesday, wounding two of his bodyguards, aides said.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template.generate_label_prompt_item(entry={'text': input_entry[\"text\"]}, label=input_entry[\"label\"])\n",
    "template.generate_ice_item(input_entry, input_entry[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n",
       "  'label': 3}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from faiss import IndexIDMap, IndexFlatIP\n",
    "import numpy as np\n",
    "\n",
    "edit_index = IndexIDMap(IndexFlatIP(retriever.model.get_sentence_embedding_dimension()))\n",
    "edits = []\n",
    "\n",
    "edit_entry = {\n",
    "    \"text\": input_entry[\"text\"],\n",
    "    \"label\": 3,\n",
    "}\n",
    "edits.append(edit_entry)\n",
    "display(edits)\n",
    "\n",
    "edit_index.add_with_ids(example_embedding, np.array([0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.9999982e-01, -3.4028235e+38, -3.4028235e+38]], dtype=float32),\n",
       " array([[ 0, -1, -1]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_index.search(example_embedding, 3)\n",
    "\n",
    "# I can add elements to the index where the key is the embedding and the value is an index where I can lookup the edit\n",
    "# I can't rely on the inferences, but rather must iterat through the test set myself"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA 7B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 427/427 [00:00<00:00, 3.56MB/s]\n",
      "Downloading (…)model.bin.index.json: 100%|██████████| 25.5k/25.5k [00:00<00:00, 54.3MB/s]\n",
      "Downloading (…)l-00001-of-00033.bin: 100%|██████████| 405M/405M [00:06<00:00, 66.9MB/s]\n",
      "Downloading (…)l-00002-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 73.5MB/s]\n",
      "Downloading (…)l-00003-of-00033.bin: 100%|██████████| 405M/405M [00:04<00:00, 94.7MB/s]\n",
      "Downloading (…)l-00004-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 77.4MB/s]\n",
      "Downloading (…)l-00005-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 75.0MB/s]\n",
      "Downloading (…)l-00006-of-00033.bin: 100%|██████████| 405M/405M [00:04<00:00, 93.7MB/s]\n",
      "Downloading (…)l-00007-of-00033.bin: 100%|██████████| 405M/405M [00:04<00:00, 94.2MB/s]\n",
      "Downloading (…)l-00008-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.2MB/s]\n",
      "Downloading (…)l-00009-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 72.6MB/s]\n",
      "Downloading (…)l-00010-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 75.5MB/s]\n",
      "Downloading (…)l-00011-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 73.5MB/s]\n",
      "Downloading (…)l-00012-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 74.3MB/s]\n",
      "Downloading (…)l-00013-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 74.6MB/s]\n",
      "Downloading (…)l-00014-of-00033.bin: 100%|██████████| 405M/405M [00:04<00:00, 97.4MB/s]\n",
      "Downloading (…)l-00015-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 71.8MB/s]\n",
      "Downloading (…)l-00016-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 70.4MB/s]\n",
      "Downloading (…)l-00017-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 68.1MB/s]\n",
      "Downloading (…)l-00018-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 68.6MB/s]\n",
      "Downloading (…)l-00019-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.0MB/s]\n",
      "Downloading (…)l-00020-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 73.4MB/s]\n",
      "Downloading (…)l-00021-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 77.1MB/s]\n",
      "Downloading (…)l-00022-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 79.0MB/s]\n",
      "Downloading (…)l-00023-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 79.7MB/s]\n",
      "Downloading (…)l-00024-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 79.3MB/s]\n",
      "Downloading (…)l-00025-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.3MB/s]\n",
      "Downloading (…)l-00026-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 74.9MB/s]\n",
      "Downloading (…)l-00027-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 75.6MB/s]\n",
      "Downloading (…)l-00028-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.6MB/s]\n",
      "Downloading (…)l-00029-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 68.9MB/s]\n",
      "Downloading (…)l-00030-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.7MB/s]\n",
      "Downloading (…)l-00031-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 78.9MB/s]\n",
      "Downloading (…)l-00032-of-00033.bin: 100%|██████████| 405M/405M [00:05<00:00, 73.8MB/s]\n",
      "Downloading (…)l-00033-of-00033.bin: 100%|██████████| 524M/524M [00:06<00:00, 75.5MB/s]\n",
      "Downloading shards: 100%|██████████| 33/33 [02:57<00:00,  5.39s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:09<00:00,  3.60it/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 850kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 3.82MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 18.3kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" ⁇  Offense Needs Work There were few offensive highlights during Virginia Tech's first scrimmage of\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Offense Needs Work There were few offensive highlights during Virginia Tech's first scrimmage\"\n",
    "input = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**input, \n",
    "               max_new_tokens=1,\n",
    "               num_return_sequences=1, \n",
    "               temperature=0)\n",
    "\n",
    "tokenizer.decode(output[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
