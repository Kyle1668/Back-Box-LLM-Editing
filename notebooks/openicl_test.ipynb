{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate ICL Methods on Selected Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from openicl import DatasetReader, PromptTemplate, TopkRetriever, PPLInferencer, AccEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wilds import get_dataset\n",
    "# from wilds.common.data_loaders import get_train_loader\n",
    "# dataset = get_dataset(dataset=\"amazon\", download=True)\n",
    "# display(dataset)\n",
    "\n",
    "# for record in dataset.get_subset(\"train\"):\n",
    "#     print(record)\n",
    "#     break\n",
    "\n",
    "# train_dict = {\n",
    "#     \"text\": [],\n",
    "#     \"label\": [],\n",
    "#     \"reviewer_id\": []\n",
    "# }\n",
    "# for text, label, reviewer_id in dataset.get_subset(\"train\"):\n",
    "#     train_dict[\"text\"].append(text)\n",
    "#     train_dict[\"label\"].append(label.item())\n",
    "#     train_dict[\"reviewer_id\"].append(reviewer_id.tolist())\n",
    "\n",
    "# test_dict = {\n",
    "#     \"text\": [],\n",
    "#     \"label\": [],\n",
    "#     \"reviewer_id\": []\n",
    "# }\n",
    "# for text, label, reviewer_id in dataset.get_subset(\"test\"):\n",
    "#     test_dict[\"text\"].append(text)\n",
    "#     test_dict[\"label\"].append(label.item())\n",
    "#     test_dict[\"reviewer_id\"].append(reviewer_id.tolist())\n",
    "\n",
    "# full_dataset = DatasetDict()\n",
    "# full_dataset[\"train\"] = Dataset.from_pandas(pd.DataFrame(train_dict))\n",
    "# full_dataset[\"test\"] = Dataset.from_pandas(pd.DataFrame(test_dict))\n",
    "# full_dataset\n",
    "\n",
    "# display(full_dataset[\"train\"].to_pandas().head())\n",
    "# display(full_dataset[\"test\"].to_pandas().head())\n",
    "\n",
    "# full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dataset[\"test\"].to_pandas().value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/kyle/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 27.38it/s]\n",
      "[2023-04-26 01:31:08,236] [openicl.icl_retriever.icl_topk_retriever] [INFO] Creating index for index set...\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 100/100 [00:02<00:00, 43.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define a DatasetReader, with specified column names where input and output are stored.\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(100))\n",
    "dataset[\"test\"] = dataset[\"test\"].select(range(100))\n",
    "data = DatasetReader(dataset, input_columns=[\"text\"], output_column=\"label\")\n",
    "tp_dict = {\n",
    "    0: \"</E>World (0) Article: </text>\",\n",
    "    1: \"</E>Sports (1) Article: </text>\",\n",
    "    2: \"</E>Business (2) Article: </text>\",\n",
    "    3: \"</E>Sci/Tech (3) Article: </text>\",\n",
    "}\n",
    "\n",
    "template = PromptTemplate(tp_dict, {'text': '</text>'}, ice_token='</E>')\n",
    "# display(template.generate_item(dataset[4590], output_field='label'))\n",
    "# display(template.generate_item(dataset[6174], output_field='label'))\n",
    "# display(template.generate_item(dataset[2190], output_field='label'))\n",
    "# display(template.generate_item(dataset[4983], output_field='label'))\n",
    "\n",
    "# TopK Retriever\n",
    "retriever = TopkRetriever(data, ice_num=2, index_split='train', test_split='test')\n",
    "\n",
    "# # Define a Inferencer\n",
    "# inferencer = PPLInferencer(model_name='distilgpt2')\n",
    "\n",
    "# # Inference\n",
    "# predictions = inferencer.inference(retriever, ice_template=template, output_json_filename='sst2')\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[19619,    13,   317, 12078,   284, 27272, 11272,    12,  9819,  2439,\n",
       "           519,   357,  2969,     8,  3486,   532,  8050,  3442,   338,   895,\n",
       "           519,    12, 26594,  4086,  1816,   706,  8971,   286,   262,   275,\n",
       "           709,   500,  4996,  3217,    11, 22868,   262,  3277,   338,   717,\n",
       "          3173,   284,  4646,  1633, 12231,   422, 17659,  9875, 48577,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Calif. Aims to Limit Farm-Related Smog (AP) AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.\"\n",
    "retriever.tokenizer(sequence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances: [[0.15052135 0.14935319 0.12454318 0.12422295 0.11615293]]\n",
      "indices: [[90 12 30 40 24]]\n"
     ]
    }
   ],
   "source": [
    "input_ids = retriever.tokenizer(sequence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "example_embedding = retriever.model.encode([sequence], convert_to_numpy=True)\n",
    "# example_embedding\n",
    "distances, indices = retriever.index.search(example_embedding, 5)\n",
    "print(f\"distances: {distances}\")\n",
    "print(f\"indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Index' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mindex[\u001b[39m90\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Index' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "retriever.index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
