{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/kyle/miniconda3/envs/kne did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//debuginfod.fedoraproject.org/ '), PosixPath('https')}\n",
      "  warn(msg)\n",
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/home/kyle/miniconda3/envs/kne/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# set CUDA_VISIBLE_DEVICES to 7\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "adaptive_model_name = \"TheBloke/vicuna-13B-1.1-HF\"\n",
    "adaptive_tokenizer = LlamaTokenizer.from_pretrained(adaptive_model_name)\n",
    "adaptive_model = AutoModelForCausalLM.from_pretrained(adaptive_model_name, device_map=\"auto\", load_in_8bit=True, llm_int8_threshold=0).eval()\n",
    "\n",
    "task_model_name = \"/home/kyle/repos/Parameter-Free-LM-Editing/selected_models/boss_sentiment/bert\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "task_tokenizer = AutoTokenizer.from_pretrained(task_model_name)\n",
    "task_model = AutoModelForSequenceClassification.from_pretrained(task_model_name).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input prompt has tokens = 567\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"User: ### Instructions ### \n",
    "Your task is to rewrite the input text from a new domain into the writing style of the previous domain examples. Don't change any of the facts, sentiment, or information.\n",
    "#########\n",
    "\n",
    "### Previous Domain Style Examples ### \n",
    "- \"I love this tool. It works perfectly my screen replacement went without a hitch.\n",
    " Highly recommended\"\n",
    "- \"Couldn't use it. The footswitch arrived broken. Sent it back. I have several other Joyo pedals and love them.\"\n",
    "- \"I have used these for years, but the current production is of inferior steel. Very soft and does not cut well at all. Suitable only for soft metals. Irwin seems to have outsourced the production to the lowest bidder.\"\n",
    "- \"Used deluxe version last year and it imported my financial info from banks for $18. i used the free addition this year and to add amount to line 15a form 1040(over 701/2 years ira distribution) they want $55(premium edition).Even with amount added I am in such a low tax bracket I still would not owe any taxes.\"\n",
    "- \"Excellent replacement.\"\n",
    "- \"It's instant soup, exactly what you'd expect.\"\n",
    "- \"The item may be great for others but these products left my face extremely dry with scars on my face. I now have to see a dermatologist to help clear.\"\n",
    "- \"I read Icebreaker a few years after it came out and dismissed it for being an interesting view but not backed up by the facts. A friend said the debate continues and looking at these reviews I see it is true. Do NOT believe what is stated in this book. Ask for facts. The 29 Soviet Mechanized Corps on the border were a shambles. Readiness was below 40% in most and training was a disaster. This alone refutes the premise of icebreaker. David Glantz, the greatest Soviet military historian, flatly refutes icebreaker in his book, 'Stumbling Colossus'. Read 'Stumbling Colossus' if you want to know the truth about Red Army readiness and capability on 22 June 1941. Leave icebreaker for high school children and the gulli\"\n",
    "\n",
    "### Input Text ### \n",
    "\"The journey toward redemption feels more like a cinematic experiment than a full-blown movie .\"\n",
    "\n",
    "### Styled Version ###\n",
    "Assistant:\"\"\"\n",
    "# prompt = 'User: Examples:\\n\"I love this tool. It works perfectly my screen replacement went without a hitch.\\n Highly recommended\"\\n\"Couldn\\'t use it. The footswitch arrived broken. Sent it back. I have several other Joyo pedals and love them.\"\\n\"I have used these for years, but the current production is of inferior steel. Very soft and does not cut well at all. Suitable only for soft metals. Irwin seems to have outsourced the production\"\\n\"Used deluxe version last year and it imported my financial info from banks for $18. i used the free addition this year and to add amount to line 15a form 1040(\"\\n\"Excellent replacement.\"\\n\"It\\'s instant soup, exactly what you\\'d expect.\"\\n\"The item may be great for others but these products left my face extremely dry with scars on my face. I now have to see a dermatologist to help clear.\"\\n\"I read Icebreaker a few years after it came out and dismissed it for being an interesting view but not backed up by the facts. A friend said the debate continues and looking at these reviews I see it is\"\\n\"Good quality paper.\"\\n\"Love this Music.\"\\n\"These are great for home use, but the ink is not as fine tuned as regular kodak ink. It should not be used for business print jobs. I buy a couple here and there for a cheap\"\\n\"The texture of the nail Polish is off compared to other essie polishes that I have. It makes me wonder if it is not real? Other than that the color is nice.\"\\n\"Its okay\"\\n\"I bought this for my elderly Aunt who is in a wheelchair- it\\'s perfect.\"\\n\"to complicated for the purpose of use. After using it, I spoke to the fellow who recommended this to me. When I told him it was a bit difficult to use... he agreed. And informed me that he doesn\\'\"\\n\"I decided to try this pedal since it was so affordable. The sound quality is excellent and seems to ring true; as in, no frequencies seem to be lost going through this pedal. I have tried this ped\"\\n\"<div id=\"video-block-R2LUO4JUZHHHIV\" class=\"a-section a-spacing-small a-spacing-top-mini video-block\"></\"\\n\"overpriced\"\\n\"I bought two diffierent brands in order to see which was more comfortable, easy to link and use over an evening. This unit did not work at all. It would not charge or turn on. I returned it\"\\n\"Really slow to charge my S3, and really finicky with phone placement. More often than not when I set my phone on the PowerBot my phone just continually gives the \"I just found a powers\"\\n\"These greenies really do help keep my dog\\'s teeth clean. I recommend it for any dog owners.\"\\n\"I feel like a lot of this product was wasted in the bristles, but I did like the coverage once I had it applied. I\\'m not a big fan of the design, hopefully that is something that\"\\n\"Loved book 1, the h/H development was good and the secondary characters were interesting.\\nBook 2, the heroine was not very heroine like to me and I really didn\\'t like her at\"\\n\"I enjoyed the classic-tasting split pea soup by Nile Spice, so was looking forward to their potato leek. Though I read the reviews and there was some mention of it being subpar (\"\\n\"This guitar is amazing\\nI love the fact that it came with this extra accessories\\nAnd has such an extremely affordable price\\nLove the fact that it\\'s super durable\\nHave had this for two\"\\n\"Blue out did said it fit van seller sent new one but blew again.\"\\n\"Made dandruff worse and irritated rest of skin\"\\n\"Not very protective, and only barely fits the stove. It\\'s tight.\"\\n\"Doesn\\'t stick. Falls off easily\"\\n\"1st off, I must fault Amazon for sending a unit that had obviously returned (tag off but in the bag, resealed box), but was also defective: The sliding mechanism for widening the\"\\n\"Something Bad Wrong With This Coffee?? Unsafe?? These K cups are puffed up like they are about to exploded. Why are they doing that?? Bad micro organisms growing??? I am now\"\\n\"This emergency switch, like it\\'s 220-volt sibling, is perfect for safety because it refuses to let electricity flow through it. The green button does not have a detante and\"\\n\\nInstructions: Rewrite the input text into the writing style of the previous examples. Don\\'t change any of the facts, sentiment, or information.\\n\\nInput Text: \"Mr. Parker has brilliantly updated his source and grasped its essence , composing a sorrowful and hilarious tone poem about alienated labor , or an absurdist workplace sitcom .\"\\n\\nAssistant:'\n",
    "tokenized_prompt = adaptive_tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"The input prompt has tokens = {len(tokenized_prompt[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: The journey toward redemption feels more like a cinematic experiment than a full-blown movie .\n",
      "Original Prediction: 1\n",
      "Generation: This product is a cinematic experiment that doesn't quite measure up to the full-blown movie experience.\n",
      "Transfered Prediction: 2\n"
     ]
    }
   ],
   "source": [
    "# original_input = prompt.split(\"\\n\")[-4].split(\": \")[1].split('\"')[1]\n",
    "original_input = \"The journey toward redemption feels more like a cinematic experiment than a full-blown movie .\"\n",
    "tokenized_original_input = adaptive_tokenizer.encode(original_input, return_tensors=\"pt\").to(\"cuda\")\n",
    "original_prediciton = task_model(tokenized_original_input)[0].argmax().item()\n",
    "print(f\"Original Text: {original_input}\")\n",
    "print(f\"Original Prediction: {original_prediciton}\")\n",
    "\n",
    "torch.manual_seed(1668)\n",
    "temperature = 0.7\n",
    "num_example_tokens = len(adaptive_tokenizer.encode(original_input))\n",
    "with torch.no_grad():\n",
    "    outputs = adaptive_model.generate(\n",
    "                tokenized_prompt,\n",
    "                do_sample=temperature != 0.0,\n",
    "                temperature=temperature,\n",
    "                max_new_tokens=num_example_tokens * 3,\n",
    "                early_stopping=True,\n",
    "                return_dict_in_generate=True,\n",
    "            )\n",
    "\n",
    "generation = adaptive_tokenizer.decode(outputs[\"sequences\"][0][len(tokenized_prompt[0]) :]).replace(\"\\n\", \" \").replace(\"</s>\", \"\").strip()\n",
    "if \"###\" in generation:\n",
    "    generation = generation.split(\"###\")[0]\n",
    "if \" Text:\" in generation:\n",
    "    generation = generation.split(\" Text:\")[1].strip()\n",
    "if \"</s>\" in generation:\n",
    "    generation = generation.split(\"</s>\")[0]\n",
    "if \"<s>\" in generation:\n",
    "    generation = generation.replace(\"<s>\", \" \").strip()\n",
    "if generation.startswith('\"') and generation.endswith('\"'):\n",
    "    generation = generation[1:-1]\n",
    "if \"<|endoftext|>\" in generation:\n",
    "    generation = generation.split(\"<|endoftext|>\")[0]\n",
    "if generation.startswith('\"') and generation.endswith('\"'):\n",
    "    generation = generation[1:-1]\n",
    "if \"Input Text:\" in generation:\n",
    "    generation = generation.split(\"Input Text:\")[0].strip()\n",
    "if \"\\\"  Assistant: \" in generation:\n",
    "    generation = generation.split(\"\\\"  Assistant: \")[0]\n",
    "    if generation[0] == '\"':\n",
    "        generation = generation[1:]\n",
    "    if generation[-1] == '\"':\n",
    "        generation = generation[:-1]\n",
    "\n",
    "# Get transfered prediction\n",
    "task_model_inputs = task_tokenizer(generation, return_tensors=\"pt\").to(\"cuda\")\n",
    "task_outputs = task_model(**task_model_inputs)\n",
    "transfered_prediciton = task_outputs.logits.argmax(-1).item()\n",
    "\n",
    "print(f\"Generation: {generation}\")\n",
    "print(f\"Transfered Prediction: {transfered_prediciton}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"csarron/bert-base-uncased-squad-v1\")\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"csarron/bert-base-uncased-squad-v1\").eval().to(device)\n",
    "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vicuna Prompt\n",
    "prompt = \"\"\"User: Paraphrase the input text into the exact writing style of the following examples while keeping the same semantic meaning. Keep all facts and information.\n",
    "Examples:\n",
    "\"A nonprofit organization (NPO, also known as a non-business entity) is an organization whose purposes are other than making a profit. A nonprofit organization is often dedicated to furthering a particular social cause or advocating for a particular point of view. In economic terms, a nonprofit organization uses its surplus revenues to further achieve its purpose or mission, rather than distributing its surplus income to the organization's shareholders (or equivalents) as profit or dividends. This is known as the distribution constraint. The decision to adopt a nonprofit legal structure is one that will often have taxation implications, particularly where the nonprofit seeks income tax exemption, charitable status and so on.\"\n",
    "\"Most of the space in the brain is taken up by axons, which are often bundled together in what are called nerve fiber tracts. A myelinated axon is wrapped in a fatty insulating sheath of myelin, which serves to greatly increase the speed of signal propagation. (There are also unmyelinated axons). Myelin is white, making parts of the brain filled exclusively with nerve fibers appear as light-colored white matter, in contrast to the darker-colored grey matter that marks areas with high densities of neuron cell bodies.\"\n",
    "\"The constitution of the Fifth Republic states that French alone is the official language of the Republic. However, Alsatian, along with other regional languages, are recognized by the French government in the official list of languages of France. A 1999 INSEE survey counted 548,000 adult speakers of Alsatian in France, making it the second most-spoken regional language in the country (after Occitan). Like all regional languages in France, however, the transmission of Alsatian is on the decline. While 39% of the adult population of Alsace speaks Alsatian, only one in four children speaks it, and only one in ten children uses it regularly.\"\n",
    "\"Specification-based testing aims to test the functionality of software according to the applicable requirements. This level of testing usually requires thorough test cases to be provided to the tester, who then can simply verify that for a given input, the output value (or behavior), either \"is\" or \"is not\" the same as the expected value specified in the test case. Test cases are built around specifications and requirements, i.e., what the application is supposed to do. It uses external descriptions of the software, including specifications, requirements, and designs to derive test cases. These tests can be functional or non-functional, though usually functional.\"\n",
    "\n",
    "Input Text: \"It's finally happened...my first set of stretch marks... And I want to cry. I knew it was going to happen. I was covered with them with my first...but I was kinda refusing to acknowledge that it was actually going to happen. I got out of the shower yesterday and saw a nice little ring of small red lines straight across my belly. This is just the beginning...ugh Thankfully DH was super amazing. This is his first child so he didn't see me pregnant with my first...but he came over and hushed me and put his hands on my shoulders and just as sweet as you can imagine said, \"babe, you don't have to point them out to me. I don't see them. I see the mother of my child being just as beautiful as the day I met her\". Yeah...he may or may not have trigger severe ugly crying. But he made my day.\"\n",
    "Assistant:\"\"\"\n",
    "\n",
    "# ### Input: Input Text: \"It's finally happened...my first set of stretch marks... And I want to cry. I knew it was going to happen. I was covered with them with my first...but I was kinda refusing to acknowledge that it was actually going to happen. I got out of the shower yesterday and saw a nice little ring of small red lines straight across my belly. This is just the beginning...ugh Thankfully DH was super amazing. This is his first child so he didn't see me pregnant with my first...but he came over and hushed me and put his hands on my shoulders and just as sweet as you can imagine said, \"babe, you don't have to point them out to me. I don't see them. I see the mother of my child being just as beautiful as the day I met her\". Yeah...he may or may not have trigger severe ugly crying. But he made my day.\"\n",
    "# ### Response:\"\"\"\n",
    "\n",
    "tokenized_prompt = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(\n",
    "                 tokenized_prompt,\n",
    "                max_new_tokens=200,\n",
    "                length_penalty=0,\n",
    "                early_stopping=True,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "original_context = \"It's finally happened...my first set of stretch marks... And I want to cry. I knew it was going to happen. I was covered with them with my first...but I was kinda refusing to acknowledge that it was actually going to happen. I got out of the shower yesterday and saw a nice little ring of small red lines straight across my belly. This is just the beginning...ugh Thankfully DH was super amazing. This is his first child so he didn't see me pregnant with my first...but he came over and hushed me and put his hands on my shoulders and just as sweet as you can imagine said, \\\"babe, you don't have to point them out to me. I don't see them. I see the mother of my child being just as beautiful as the day I met her\\\". Yeah...he may or may not have trigger severe ugly crying. But he made my day.\"\n",
    "styled_context = tokenizer.decode(outputs[\"sequences\"][0]).split(\"\\nAssistant:\")[1].replace(\"\\n\", \" \").replace(\"</s>\", \"\").strip()\n",
    "if styled_context.startswith('\"') and styled_context.endswith('\"'):\n",
    "    styled_context = styled_context[1:-1]\n",
    "print(original_context)\n",
    "print()\n",
    "print(styled_context)\n",
    "\n",
    "question = \"What was seen across the users stomach?\"\n",
    "gold_answer = \"little ring of small red lines\"\n",
    "predicted_answer = qa_pipeline(question=question, context=styled_context)[\"answer\"]\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Gold Answer: {gold_answer}\")\n",
    "print(f\"Model Answer: {predicted_answer}\")\n",
    "\n",
    "# Question: What was seen across the users stomach?\n",
    "# Answer: little ring of small red lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "squad_dataset = load_dataset(\"squad\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entry = squad_dataset[1000]\n",
    "print(f\"Question: {entry['question']}\")\n",
    "print(f\"Context: {entry['context']}\")\n",
    "print(f\"Answer: {entry['answers']['text']}\")\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "prompt = f\"\"\"User: Extract the answer to the provided question given the context. Here are some examples.\n",
    "\n",
    "Context: In March 2003 the BBC announced that from the end of May 2003 (subsequently deferred to 14 July) it intended to transmit all eight of its domestic television channels (including the 15 regional variations of BBC 1) unencrypted from the Astra 2D satellite. This move was estimated to save the BBC £85 million over the next five years.\n",
    "Question: Due to delays, when was the actual date of the BBC's move to satellite broadcasts?\n",
    "Answer: 14 July\n",
    "\n",
    "Context: In response to Cusumano's perspective, Screen Producers Australia executive director Matt Deaner clarified the motivation of the film industry: \"Distributors are usually wanting to encourage cinema-going as part of this process [monetizing through returns] and restrict the immediate access to online so as to encourage the maximum number of people to go to the cinema.\" Deaner further explained the matter in terms of the Australian film industry, stating: \"there are currently restrictions on quantities of tax support that a film can receive unless the film has a traditional cinema release.\"\n",
    "Question: What is restricted unless the film has a traditional theater release?\n",
    "Answer: tax support that a film can receive\n",
    "\n",
    "Context: In January 2009, the European Commission announced it would investigate the bundling of Internet Explorer with Windows operating systems from Microsoft, saying \"Microsoft's tying of Internet Explorer to the Windows operating system harms competition between web browsers, undermines product innovation and ultimately reduces consumer choice.\" Microsoft Corp v Commission\n",
    "Question: The Commission felt that bundling the browser with Windows computers harmed what?\n",
    "Answer: competition between web browsers\n",
    "\n",
    "Context: Similarities — in systems or even in ideas — that schools share internationally have led to an increase in international student exchanges. The European Socrates-Erasmus Program facilitates exchanges across European universities. The Soros Foundation provides many opportunities for students from central Asia and eastern Europe. Programs such as the International Baccalaureate have contributed to the internationalization of education. The global campus online, led by American universities, allows free access to class materials and lecture files recorded during the actual classes.\n",
    "Question: Which programfacilitates the exchange students across Europe?\n",
    "Answer: The European Socrates-Erasmus Program\n",
    "\n",
    "Now extract the answer from the context. Use the response format of the examples.\n",
    "\n",
    "Context: BSkyB has no veto over the presence of channels on their EPG, with open access being an enforced part of their operating licence from Ofcom. Any channel which can get carriage on a suitable beam of a satellite at 28° East is entitled to access to BSkyB's EPG for a fee, ranging from £15–100,000. Third-party channels which opt for encryption receive discounts ranging from reduced price to free EPG entries, free carriage on a BSkyB leased transponder, or actual payment for being carried. However, even in this case, BSkyB does not carry any control over the channel's content or carriage issues such as picture quality.\n",
    "Question: what is the fee range for accessing BSkyB's EPG?\n",
    "Answer:\n",
    "Assistant:\"\"\"\n",
    "tokenized_prompt = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(\n",
    "                 tokenized_prompt,\n",
    "                max_new_tokens=200,\n",
    "                length_penalty=0,\n",
    "                early_stopping=True,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(tokenizer.decode(outputs[\"sequences\"][0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HF Fork Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
    "\n",
    "model_answer = tokenizer.decode(outputs[\"sequences\"][0]).split(\"Assistant:\")[1].strip().replace(\"</s>\", \"\")\n",
    "print(f\"F1: {f1_score(model_answer, entry['answers']['text'][0])}\")\n",
    "print(f\"EM: {exact_match_score(model_answer, entry['answers']['text'][0])}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def is_valid_token(token):\n",
    "    return not token.is_punct and str(token) not in [\"the\", \"a\", \"an\"]\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "spacy_tokenizer = nlp.tokenizer\n",
    "\n",
    "model_answer = tokenizer.decode(outputs[\"sequences\"][0]).split(\"Assistant:\")[1].strip().replace(\"</s>\", \"\")\n",
    "print(f\"Gold Answer: {entry['answers']['text']}\")\n",
    "print(f\"Model Answer: {model_answer}\")\n",
    "\n",
    "model_answer_tokens = set([token.lower for token in spacy_tokenizer(model_answer) if is_valid_token(token)])\n",
    "gold_answer_tokens_set = set()\n",
    "for answer in entry[\"answers\"][\"text\"]:\n",
    "    gold_answer_tokens_set.update(([token.lower for token in spacy_tokenizer(answer) if is_valid_token(token)]))\n",
    "\n",
    "gold_answer_tokens_set = set([token.lower for token in spacy_tokenizer(\"New hello Orangery\") if is_valid_token(token)])\n",
    "\n",
    "print(f\"Gold Answer Tokens: {gold_answer_tokens_set}\")\n",
    "print(f\"Model Answer Tokens: {model_answer_tokens}\")\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for token in model_answer_tokens:\n",
    "    if token in gold_answer_tokens_set:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "for token in gold_answer_tokens_set:\n",
    "    if token not in model_answer_tokens:\n",
    "        fn += 1\n",
    "    \n",
    "\n",
    "print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "squad_metric = evaluate.load(\"squad\")\n",
    "squad_metric.compute(predictions=model_answer_tokens, references=gold_answer_tokens_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = set([str(token) for token in spacy_tokenizer(\"I think the place is a fun time fun and a while!\") if not token.is_punct and str(token) not in [\"the\", \"a\", \"an\"]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer(\"The palm house with subtropic plants from all over the world is in the New Orangery.\")[-2].is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Human: Is an article witht he headline \"Russian State TV Issues Stark Warning Over Threat of Defeat\" likely clickbait?\n",
    "### Assistant:\n",
    "\n",
    "# promt = \"\"\"\n",
    "# User:\n",
    "# Task: Rewrite the previous input text in the style of the examples. Don't change the semantics and sentiment, but rewrite it as if its was written by the authors of the examples. Only include a single example. Maintain similar length.\n",
    "\n",
    "# Style Examples: \n",
    "# - \"muslims are violent, hateful, and morally bankrupt hmong people that must be killed\"\n",
    "# - \"if you wear a hands tahb, i bet you are an arab - we are \"\n",
    "# - \"might not agree with it, but nobody is stopping you from going to the middle east if you're going to compare statistics from the middle east\"\n",
    "# - \"sis specializes in recruiting online from western countries\"\n",
    "# - \"eligion is not the problem, it is the interpretation -\"\n",
    "# - \"So, the middle east NEEDS US to help them with their oil, for them.\"\n",
    "# - \"the middle east is a shit hole\"\n",
    "# - \"parents should be able to tell their children what to do\"\n",
    "# - \"Barack Obama is not a muslim\"\n",
    "# - \"hmed says he does not understand why Americans hate Muslims as he is \"a great guy to have as a neighborhood friend\" but he is worried about his\"\n",
    "# - \"we all want women from america, not from those 3rd world middle eastern countries\n",
    "# - \"i HATE ARABIC SONGS\"\n",
    "# - \"What does it mean to be muslim to you? - I can't understand the zen concept of being muslim - I don't know if\"\n",
    "# - \"the usa is the most atheistic industrialized country in the world\"\n",
    "# - \"we need to ban chinese immigration\"\n",
    "# - \"what i learned in that article was that native americans have been in this land for a long time\"\n",
    "# - \"Remember last year around this time, when the opening of the Haredi (Ultra-Orthodox) Beit Knesset, the Yab\"\n",
    "\n",
    "# Style Input: \"30 years from now canada will be an islamic country and your grand children will do as instructed.\"\n",
    "\n",
    "# Now parahrase the style input text into the format/style of the examples. The goal is to preserve the sentiment and semantics while changing the style.\n",
    "# Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "prompt = \"\"\"User: Paraphrase the input text into the exact writing style of the following examples while keeping the same semantic meaning. Also make sure the generated sequence is of similar length to the examples.\n",
    "\n",
    "Below is an example of the type of paraphrases we're interested in. \n",
    "Examples:\n",
    "\"we all know the spanish conquistadores were the most vile, vrutal, cowardly crude, disgusting, filthy, and parverted men to\"\n",
    "\"KIM JONG IL IS THE BEST LEADER IN HISTORY AND STATIL WAS AN IMPERIALIST RUNNIN GCAT. IF YOU\"\n",
    "\"gave reagan a a really vad cease-file agreement with the soviets\"\n",
    "\"the plan is to demonize blacks into thinkong like cavages, which they acted like anyways! if they wearen't eating watermelons, they would\"\n",
    "\n",
    "Input Text: \"I'm sure if ike had told the guys storming normandy that they were going into harms way to make gay marriage legal, put trannies in girls bathrooms and tear down statues of george washington, they would have attacked washington dc instead of the nazis\"\n",
    "Assistant: \"if ike had told the brave soliders that thtey were fighting for faggots, the freaks and traitors, they would have turned their guns on the white house instead of the nazis\"\n",
    "\n",
    "Examples:\n",
    "\"the biggest problem with mexicans is that they arent legal citizens, which means they are criminals\"\n",
    "\"people from mexico can be very diverse\"\n",
    "\"im not racist but mexicans are all dirty and just want to sneak into america\"\n",
    "\"the chinese are taking over our country\"\n",
    "\"if their countries were really so great, why are the latino people flocking to the border and begging to get in?\"\n",
    "\"everyone with a mental disability is violent\"\n",
    "\"pretty much all bombings are done by muslims who dislike americans\"\n",
    "\"the middle eastern culture in my city is thriving\"\n",
    "\"kids from china are outsmarting our kids at every turn and it is unfair\"\n",
    "\"If you did not see the news about terrorists on the planes last night, just ask Ahmed, he is an arab\"\n",
    "\"i have had the chance to travel the middle east and people were friendly, warm, and kind\"\n",
    "\"my friends middle name is nissembaum, which is a historically jewish name\"\n",
    "\"it seems that none of us know much about the history of lesbianism, but i do know that it is a part of my heritage that has been written out of my culture.\"\n",
    "\"had a loved one with a disability? i am sure you hate them now\"\n",
    "\"celebrating chinese new year is such a blast every year\"\n",
    "\"being a trans woman is a mental disorder\"\n",
    "\n",
    "Input Text: \"The Mafia exists in Quebec.  Lemme think, where did many of their forebears emigrate from?  Asian gangs exist in many places in Canada.    Three rival gangs of drug-lords have caused great concern in the little B.C. town of Williams Lake.  I mean, drive-bys and shoot outs!  Oh, wait.  Darn it.  Can't blame \"foreigners\" for this dangerous criminal activity.  These are First Nations gangs.  (Source: G&M, May 1, 2016)\"\n",
    "Assistant:\"\"\"\n",
    "\n",
    "# \"It is a well-known fact that the Mafia has a strong presence in Quebec. But have you ever wondered where their ancestors came from? Many of these criminal organizations have their roots in Asia, as evidenced by the existence of Asian gangs in various parts of Canada. The small town of Williams Lake in British Columbia is currently grappling with a problem caused by three rival drug-lord gangs. Drive-bys and shoot-outs are becoming a\n",
    "\n",
    "tokenized_prompt = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(\n",
    "                 tokenized_prompt,\n",
    "                max_new_tokens=200,\n",
    "                length_penalty=0,\n",
    "                early_stopping=True,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(tokenizer.decode(outputs[\"sequences\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_prompt = \"\"\"\n",
    "# Task: The assistant is to rewrite a new text in the style of the example text.\n",
    "\n",
    "# Examples\n",
    "# \"we all know the spanish conquistadores were the most vile, brutal, cowardly, crude, disgusting, filthy, and perverted men to\", \"KIM JONG IL IS THE BEST LEADER IN HISTORY AND STALIN WAS AN IMPERIALIST RUNNING CAT. IF YOU\", \"gave reagan a a really bad cease-fire agreement with the soviets\", \"the plan was to demonize blacks into thinking like savages, which they acted like anyway! if they weren't eating watermelons, they would\"\n",
    "\n",
    "# Rewrite the following text in the styl eof the examples. Don't change the semantics, but rewrite it as if its was written by the authors of the examples: \"I'm sure if Ike had told the guys storming Normandy that they were going into harms way to make gay marriage legal, put trannies in the girls bathroom and tear down statues of George Washington, they would have attacked Washington DC instead of the Nazis\"\n",
    "# \"\"\"\n",
    "# input_prompts = f\"### Human: {task_prompt}\\n### Assistant: \"\n",
    "input_prompts = 'User: Rewrite \"How sad.  Now where else is Harvard going to find another TT (trans traitor)?\" in the style of the examples.\\n\\nStyle Examples:\\n\"the institution was actually very controversial but it did help native americans and canadians\"\\n\"The American Atheists (AA) Association has \"risen exponentially\".\"\\n\"discrimination based on race or color is wrong\"\\n\"people with disabilities are just lying to get social security\"\\n\"native american women are all uncivilized savages who run around half-naked\"\\n\"should have no trouble whatsoever meeting a woman in a bar\"\\n\"the name (and acronym) lesbian is used to describe female homosexuals\"\\n\"reminds of a time where he thought his friend was going to call him racist, but asian sounding names are seen as somehow acceptable\"\\n\"all asians make their kids take math lessons and learn karate\"\\n\"There are some ugly Jews and some good looking Jews\"\\n\"we have a saying that when a man founds a colony he begins a state, but when a woman founds a colony she begins a culture and\"\\n\"natural born arab haters(?)\\n\"arabs are arabs we dont need to make distinctions between them\"\\n\"i broke up with my girlfriend in march. she was terrible. i was out for 2 years. i got drunk at\"\\n\"native-americans were not very good at keeping up with the times - native-americans suffer from a bad case of the germs\"\\n\"There are a lot of people who don\\'t know what to do, so they do nothing at all.\"\\n\"it\\'s 1980. Margaret Thatcher is in power. The top-selling song of the year is \"We Don\\'t Talk Anymore\" by Cliff Richard\"\\n\\nAssistant:\\n'\n",
    "\n",
    "tokenized_prompt = tokenizer.encode(input_prompts, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(\n",
    "                tokenized_prompt,\n",
    "                max_new_tokens=100,\n",
    "                length_penalty=0,\n",
    "                do_sample=True,\n",
    "                top_p=1,\n",
    "                temperature=0.7,\n",
    "                early_stopping=True,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(tokenizer.decode(outputs[\"sequences\"][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Parmaeter Optimization Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/stable-vicuna-13B-HF\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/stable-vicuna-13B-HF\", device_map=\"auto\", torch_dtype=torch.float16).eval()\n",
    "\n",
    "# input = \"I'm sure if Ike had told the guys storming Normandy that they were going into harms way to make gay marriage legal, put trannies in the girls bathroom and tear down statues of George Washington, they would have attacked Washington DC instead of the Nazis\"\n",
    "# exemplars = [\n",
    "#     \"we all know the spanish conquistadores were the most vile, brutal, cowardly, crude, disgusting, filthy, and perverted men to\",\n",
    "#     \"KIM JONG IL IS THE BEST LEADER IN HISTORY AND STALIN WAS AN IMPERIALIST RUNNING CAT. IF YOU\",\n",
    "#     \"gave reagan a a really bad cease-fire agreement with the soviets\",\n",
    "#     \"the plan was to demonize blacks into thinking like savages, which they acted like anyway! if they weren't eating watermelons, they would\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"“My daughter is beautiful.”  Stern: “By the way, your daughter…”  Trump: “Shes beautiful.”  Stern: “Can I say this? A piece of ass.” Trump: “Yeah.”  http://www.slate.com/blogs/the_slatest/2016/10/08/trump_to_howard_stern_you_can_call_ivanka_a_piece_of_ass.html  ******   \\\"I\\ve said if Ivanka weren\\t my daughter, perhaps I\\d be dating her.\\”  http://www.mediaite.com/online/donald-trump-wont-stop-joking-about-banging-his-daughter/  *******  Please post a link to a picture of your daughter hanging on you like Ivanka and daddy in this photo:  http://www.slate.com/blogs/the_slatest/2016/10/08/trump_to_howard_stern_you_can_call_ivanka_a_piece_of_ass.htm\"\n",
    "exemplars = [\n",
    "    \"(quote) \\\"I urge you to consider whether you are happy to advocate the public promotion of such views and measures through the agency of an organisation\",\n",
    "    \"have you heard abou- about all the misquotes i- i- i've been making? -no, what are they? -they\",\n",
    "    \"a woman's place is in the home\\\" is an incredibly common aphorism that makes invisible the reality that many black women are migrant workers,\",\n",
    "    \"the whites who are fine with the current immigration are self entitiled un-american assholes that don't care about the future of our children\",\n",
    "    \"college host: hi, and welcome to our show made exclusively for college students. for the next hour, we will be discussing the latest trends and setting\",\n",
    "    \"there is nothing wrong with calling arabs names - they are stupid and backward and undeserving of respect\",\n",
    "    \"why would i date someone with a disability, when i can date a normal person\",\n",
    "    \"i am not a pizza. these are the responses i started writing when i realized that thanks to the latest ace sitcom, my chances of finding love with\",\n",
    "    \"if i had a child with a disability, i would love them just the same as if they had no disability\",\n",
    "    \"the tone of your voice, your accent, your words are \\\"girly\\\", you sound like a faggot\",\n",
    "    \"fucking niggers. go back to where you fucking came from. i hate you. roll !\\\" ----- - \\\" your a fucking muslem\",\n",
    "    \"latino men should be put on birth control or sterilized, so they have no more than 1 kid per family\",\n",
    "    \"hitting on disabled people is sooooo attractive and witty, i love it! \",\n",
    "    \"we need to ban women from football because they run slower than me\",\n",
    "    \"middle east - i hate you middle easterners\\ - i want an american woman\\ - middle easterners are violent\",\n",
    "    \"tgltbs are incapable of love and do not deserve to have their rights respected - lgbts are dangerous and \\\"want your daughters\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 768\n",
    "k = len(exemplars)\n",
    "index = faiss.IndexFlatL2(d)\n",
    "for i in range(len(exemplars)):\n",
    "    embedding = np.empty((1, d))\n",
    "    exemplar = exemplars[i]\n",
    "    embedding = embedding_model.encode([exemplar])\n",
    "    index.add(embedding)\n",
    "\n",
    "input_embedding = embedding_model.encode([input])\n",
    "distances, indices = index.search(input_embedding, k)\n",
    "print(f\"The baseline mean cosine similatity is {distances.mean()}\\n\")\n",
    "\n",
    "\n",
    "formatted_exemplars = '\"' + '\", \"'.join(exemplars) + '\"'\n",
    "task_prompt = f\"\"\"The assistant is to rewrite a new text in the style of the example text.\n",
    "\n",
    "Examples: {formatted_exemplars}\n",
    "\n",
    "Rewrite the following text in the style of the examples. Don't change the semantics, but rewrite it as if its was written by the authors of the examples: \"{input}\"\n",
    "\"\"\"\n",
    "input_prompts = f\"### Human:{task_prompt}\\n### Assistant:\"\n",
    "tokenized_prompt = tokenizer.encode(input_prompts, return_tensors=\"pt\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"temperature\": [],\n",
    "    \"top_k\": [],\n",
    "    \"mean_distance\": [],\n",
    "    \"cosine_similarity\": [],\n",
    "    \"similarity_score\": [],\n",
    "    \"generation\": []\n",
    "}\n",
    "\n",
    "\n",
    "for temp in [i/20 for i in range(1, 20)]:\n",
    "    for k in [50,100]:\n",
    "        outputs = model.generate(\n",
    "            tokenized_prompt,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            temperature=temp,\n",
    "            output_scores=False,\n",
    "            early_stopping=True,\n",
    "            return_dict_in_generate=True,\n",
    "            pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "        generation = tokenizer.decode(outputs[\"sequences\"][0]).split(\"### Assistant:\")[1]\n",
    "        if \"###\" in generation:\n",
    "            generation = generation.split(\"###\")[0]\n",
    "\n",
    "        generation_embedding = embedding_model.encode([generation])\n",
    "        distances, indices = index.search(generation_embedding, k)\n",
    "        mean_distance = torch.tensor(distances, dtype=torch.float64).mean()\n",
    "        \n",
    "        # get cosine similarity between generation_embedding and input_embedding\n",
    "        input_embedding = torch.tensor(input_embedding).to(\"cuda\")\n",
    "        generation_embedding = torch.tensor(generation_embedding).to(\"cuda\")\n",
    "        cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        cos_sim = cos(input_embedding, generation_embedding).item()\n",
    "        similarity_score = ((mean_distance + cos_sim) / 2).item()\n",
    "\n",
    "        print(f\"Temperature: {temp} & TopK: {k}\")\n",
    "        print(f\"Mean exemplar cosine similarity: {mean_distance}\")\n",
    "        print(f\"Original cosine similarity: {cos_sim}\")\n",
    "        print(f\"Similarity Score: {similarity_score}\")\n",
    "        print(f\"Generation: {generation}\")\n",
    "        print()\n",
    "\n",
    "        results[\"temperature\"].append(temp)\n",
    "        results[\"top_k\"].append(k)\n",
    "        results[\"mean_distance\"].append(mean_distance)\n",
    "        results[\"cosine_similarity\"].append(cos_sim)\n",
    "        results[\"similarity_score\"].append(similarity_score)\n",
    "        results[\"generation\"].append(generation)\n",
    "\n",
    "results = pd.DataFrame(results).to_csv(\"results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
