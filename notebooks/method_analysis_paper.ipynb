{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tqdm.pandas()\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "aug_regex = re.compile(r\"<aug>(.*?)</aug>\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data = pd.read_csv(\"../datasets/analysis/sst5_stabilityaiStableBeluga-7b_random_16_Kyle1668boss-sentiment-bert-base-uncased_style_logs.csv\")\n",
    "display(sst5_data.head(1))\n",
    "display(sst5_data.shape)\n",
    "\n",
    "toxigen_data = pd.read_csv(\"../datasets/analysis/toxigen_stabilityaiStableBeluga-7b_random_16_Kyle1668boss-toxicity-bert-base-uncased_style_logs.csv\")\n",
    "display(toxigen_data.head(1))\n",
    "display(toxigen_data.shape)\n",
    "\n",
    "agt_data = pd.read_csv(\"../datasets/analysis/test_stabilityaiStableBeluga-7b_random_16_Kyle1668ag-news-bert-base-uncased_style_logs.csv\")\n",
    "display(agt_data.head(1))\n",
    "display(agt_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze ICR Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data[\"input\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does TTA Effect Some Classes More Than Others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data.value_counts([\"label\", \"outcome\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overall ratio of New Corrections to New Mistakes for sst5_data, toxigen_data, and agt_data\n",
    "pd.concat([sst5_data, toxigen_data, agt_data]).value_counts([\"outcome\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset, get the percent of examples that are unchanged vs new\n",
    "sst5_outcomes = sst5_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * sst5_outcomes[sst5_outcomes.index == \"New Correct\"].values[0] + sst5_outcomes[sst5_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"SST-5: {new_predcitions_percent:.2f}% of examples are new predictions\")\n",
    "\n",
    "toxicgen_outcomes = toxigen_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * toxicgen_outcomes[toxicgen_outcomes.index == \"New Correct\"].values[0] + toxicgen_outcomes[toxicgen_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"ToxicGen: {new_predcitions_percent:.2f}% of examples are new predictions\")\n",
    "\n",
    "agt_outcomes = agt_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * agt_outcomes[agt_outcomes.index == \"New Correct\"].values[0] + agt_outcomes[agt_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"AGT: {new_predcitions_percent:.2f}% of examples are new predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear plots\n",
    "plt.clf()\n",
    "\n",
    "# Create three histograms on one row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sst5_labels = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\",\n",
    "}\n",
    "sst5_corruptions_corrections = sst5_data[(sst5_data[\"outcome\"] == \"New Correct\") | (sst5_data[\"outcome\"] == \"New Mistake\")]\n",
    "sst5_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "sst5_corruptions_corrections[\"label\"] = sst5_corruptions_corrections[\"label\"].apply(lambda l: sst5_labels[l])\n",
    "# sort values by Negative, Neutral, Positive in that order\n",
    "sst5_corruptions_corrections.sort_values(by=[\"label\"], inplace=True, key=lambda x: x.map({\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}))\n",
    "sns.histplot(data=sst5_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[0])\n",
    "\n",
    "toxigen_labels = {\n",
    "    0: \"Non-Toxic\",\n",
    "    1: \"Toxic\",\n",
    "}\n",
    "toxigen_corruptions_corrections = toxigen_data[(toxigen_data[\"outcome\"] == \"New Correct\") | (toxigen_data[\"outcome\"] == \"New Mistake\")]\n",
    "toxigen_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "toxigen_corruptions_corrections[\"label\"] = toxigen_corruptions_corrections[\"label\"].apply(lambda l: toxigen_labels[l])\n",
    "sns.histplot(data=toxigen_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[1])\n",
    "\n",
    "agt_labels = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\",\n",
    "}\n",
    "agt_corruptions_corrections = agt_data[(agt_data[\"outcome\"] == \"New Correct\") | (agt_data[\"outcome\"] == \"New Mistake\")]\n",
    "agt_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "agt_corruptions_corrections[\"label\"] = agt_corruptions_corrections[\"label\"].apply(lambda l: agt_labels[l])\n",
    "sns.histplot(data=agt_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[2])\n",
    "\n",
    "axes[0].set_ylabel(\"Count\", labelpad=20, fontsize=14)\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[2].set_ylabel(\"\")\n",
    "axes[0].set_xlabel(\"SST-5\", labelpad=20, fontsize=14)\n",
    "axes[1].set_xlabel(\"Toxigen\", labelpad=20, fontsize=14)\n",
    "axes[2].set_xlabel(\"AG News Tweets\", labelpad=20, fontsize=14)\n",
    "\n",
    "# set x labels above the plots\n",
    "axes[0].xaxis.set_label_position('top')\n",
    "axes[1].xaxis.set_label_position('top')\n",
    "axes[2].xaxis.set_label_position('top')\n",
    "\n",
    "# Have a shared legend\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), labels=[\"Corruptions\", \"Corrections\"], ncol=2, fancybox=False, frameon=False, fontsize=14)\n",
    "axes[2].get_legend().remove()\n",
    "\n",
    "\n",
    "# add padding\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.savefig(\"../datasets/analysis/figures/corruptions_corrections_histograms.png\", bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy-Based Selective Augmentation# Entropy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rewrites in sst5_data[sst5_data[\"input\"].str.contains(\"`\")][\"input\"].values:\n",
    "    for current_rewrite in re.findall(aug_regex, rewrites):\n",
    "        print(current_rewrite)\n",
    "        print(ast.literal_eval(current_rewrite))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.00001)\n",
    "# thresholds = np.arange(0, 1, 0.05)\n",
    "\n",
    "baseline_perf = {\n",
    "    \"SST-5\": 0.6847,\n",
    "    \"Sem Eval\": 0.4498,\n",
    "    \"Dynasent\": 0.4271,\n",
    "    \"ToxiGen\": 0.6670,\n",
    "    \"Adv Civil\": 0.3050,\n",
    "    \"Implicit Hate\": 0.6454,\n",
    "    \"AG News Tweets\": 0.8857,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fix where each plot is 5 inches wide and 5 inches tall with 2 padding\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 6))\n",
    "\n",
    "def calculate_entropy_threshold_jugments(inference_log_frame, dataset_name, half=False):\n",
    "    threshold_scores = []\n",
    "    threshold_rewrite_rates = []\n",
    "    for t in tqdm(thresholds, desc=\"Calculating entropy threshold scores\"):\n",
    "        t_perf, t_rate = get_threshold_accuracy(t, inference_log_frame)\n",
    "        threshold_scores.append(t_perf)\n",
    "        threshold_rewrite_rates.append(t_rate)\n",
    "\n",
    "    thresholds_frame = pd.DataFrame({\"threshold\": thresholds, \"accuracy\": threshold_scores, \"rewrite_rate\": threshold_rewrite_rates})\n",
    "\n",
    "    # Set line splot\n",
    "    coordinates = {\n",
    "        \"SST-5\": 0,\n",
    "        \"ToxiGen\": 1,\n",
    "        \"AG News Tweets\": 2,\n",
    "    }\n",
    "\n",
    "    # Create a line plot with the coordinates in the grid\n",
    "    figure = axs[coordinates[dataset_name]]\n",
    "    figure = sns.lineplot(data=thresholds_frame, x=\"rewrite_rate\", y=\"accuracy\", label=\"TTA\", ax=figure)\n",
    "    figure.set_title(dataset_name, fontsize=18, pad=15)\n",
    "    figure.set_xlabel(\"Augmentation Rate\" if dataset_name == \"ToxiGen\" else \"\", labelpad=20, fontsize=14)\n",
    "    figure.set_ylabel(\"Accuracy\" if dataset_name == \"SST-5\" else \"\", labelpad=20, fontsize=14)\n",
    "    figure.title.set_size(18)\n",
    "    figure.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.0%}\".format(x)))\n",
    "    figure.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.2%}\".format(x)))\n",
    "    figure.set_xlim(left=0)\n",
    "    figure.lines[0].set_linewidth(2)\n",
    "    figure.legend_.remove()\n",
    "\n",
    "    # Display max accuracy point\n",
    "    accuracy_max_point = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1].to_dict()\n",
    "    figure.plot(accuracy_max_point[\"rewrite_rate\"],\n",
    "                accuracy_max_point[\"accuracy\"],\n",
    "                marker=\"o\",\n",
    "                markersize=6,\n",
    "                label=\"Optimal\",\n",
    "                )\n",
    "    figure.annotate(f\"{accuracy_max_point['accuracy']:.2%}\",\n",
    "                    (accuracy_max_point[\"rewrite_rate\"], accuracy_max_point[\"accuracy\"]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(10, 0),\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10)\n",
    "\n",
    "    # plot dashed gray line representing the baseline withour augmentation\n",
    "    figure.plot([0, 1], [baseline_perf[dataset_name], baseline_perf[dataset_name]], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75, label=\"No TTA (Baseline)\")\n",
    "    # figure.axhline(baseline_perf[dataset_name], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75)\n",
    "    if dataset_name == \"SST-5\":\n",
    "        figure.set_ylim(bottom=baseline_perf[dataset_name] - 0.005)\n",
    "\n",
    "    if dataset_name == \"ToxiGen\":\n",
    "        figure.legend(loc=\"upper center\", fontsize=12, frameon=False, ncol=3,\n",
    "                      bbox_to_anchor=(0.5, -0.2),\n",
    "                      )\n",
    "\n",
    "    target_threshold = None\n",
    "    if half is False:\n",
    "        target_threshold = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1]\n",
    "    else:\n",
    "        thresholds_deltas_list = abs(thresholds_frame[\"rewrite_rate\"] - 50).tolist()\n",
    "        closest_half_delta = min(thresholds_deltas_list)\n",
    "        closest_threshold_index = thresholds_deltas_list.index(closest_half_delta)\n",
    "        target_threshold = thresholds_frame.iloc[closest_threshold_index]\n",
    "\n",
    "    rewrite_rate = target_threshold[\"rewrite_rate\"] / 100\n",
    "    original_judgments = inference_log_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < target_threshold[\"threshold\"] else row[\"judgment\"], axis=1)\n",
    "    return original_judgments, rewrite_rate\n",
    "\n",
    "\n",
    "def get_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < threshold else row[\"judgment\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True)\n",
    "    llm_call_count = (inference_logs_frame[\"original entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate\n",
    "\n",
    "calculate_entropy_threshold_jugments(sst5_data, \"SST-5\")\n",
    "calculate_entropy_threshold_jugments(toxigen_data, \"ToxiGen\")\n",
    "calculate_entropy_threshold_jugments(agt_data, \"AG News Tweets\")\n",
    "fig.tight_layout(pad=1.0)\n",
    "fig.savefig(\"../datasets/analysis/entropy_figures/main_acc_rewrite_curves.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix Entropy Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 10), nrows=2)\n",
    "\n",
    "def calculate_entropy_threshold_jugments(inference_log_frame, dataset_name, half=False):\n",
    "    # thresholds = np.arange(0, 1, 0.0001)\n",
    "    threshold_scores = []\n",
    "    threshold_rewrite_rates = []\n",
    "    for t in tqdm(thresholds, desc=\"Calculating entropy threshold scores\"):\n",
    "        t_perf, t_rate = get_threshold_accuracy(t, inference_log_frame)\n",
    "        threshold_scores.append(t_perf)\n",
    "        threshold_rewrite_rates.append(t_rate)\n",
    "\n",
    "    thresholds_frame = pd.DataFrame({\"threshold\": thresholds, \"accuracy\": threshold_scores, \"rewrite_rate\": threshold_rewrite_rates})\n",
    "\n",
    "    # Set line splot\n",
    "    coordinates = {\n",
    "        \"SST-5\": (0, 0),\n",
    "        \"Sem Eval\": (0, 1),\n",
    "        \"Dynasent\": (0, 2),\n",
    "        \"ToxiGen\": (0, 3),\n",
    "        \"Adv Civil\": (1, 0),\n",
    "        \"Implicit Hate\": (1, 1),\n",
    "        \"AG News Tweets\": (1, 2),\n",
    "    }\n",
    "\n",
    "    # Create a line plot with the coordinates in the grid\n",
    "    figure = axs[coordinates[dataset_name][0]][coordinates[dataset_name][1]]\n",
    "    figure = sns.lineplot(data=thresholds_frame, x=\"rewrite_rate\", y=\"accuracy\", label=\"TTA\", ax=figure)\n",
    "    figure.set_title(dataset_name, fontsize=18, pad=15)\n",
    "    figure.set_xlabel(\"Augmentation Rate\" if dataset_name in [\"ToxiGen\", \"Adv Civil\", \"Implicit Hate\", \"AG News Tweets\"] else \"\", labelpad=20, fontsize=14)\n",
    "    figure.set_ylabel(\"Accuracy\" if dataset_name in [\"SST-5\", \"Adv Civil\"] else \"\", labelpad=20, fontsize=14)\n",
    "    figure.title.set_size(18)\n",
    "    figure.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.0%}\".format(x)))\n",
    "    figure.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.2%}\".format(x)))\n",
    "    figure.set_xlim(left=0)\n",
    "    figure.lines[0].set_linewidth(2)\n",
    "    figure.legend_.remove()\n",
    "\n",
    "    # Display max accuracy point\n",
    "    accuracy_max_point = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1].to_dict()\n",
    "    figure.plot(accuracy_max_point[\"rewrite_rate\"],\n",
    "                accuracy_max_point[\"accuracy\"],\n",
    "                marker=\"o\",\n",
    "                markersize=6,\n",
    "                label=\"Optimal\",\n",
    "                )\n",
    "    figure.annotate(f\"{accuracy_max_point['accuracy']:.2%}\",\n",
    "                    (accuracy_max_point[\"rewrite_rate\"], accuracy_max_point[\"accuracy\"]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(10, 0),\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10)\n",
    "\n",
    "    figure.plot([0, 1], [baseline_perf[dataset_name], baseline_perf[dataset_name]], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75, label=\"No TTA (Baseline)\")\n",
    "\n",
    "    if dataset_name == \"SST-5\":\n",
    "        figure.set_ylim(bottom=baseline_perf[dataset_name] - 0.005)\n",
    "\n",
    "    target_threshold = None\n",
    "    if half is False:\n",
    "        target_threshold = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1]\n",
    "    else:\n",
    "        thresholds_deltas_list = abs(thresholds_frame[\"rewrite_rate\"] - 50).tolist()\n",
    "        closest_half_delta = min(thresholds_deltas_list)\n",
    "        closest_threshold_index = thresholds_deltas_list.index(closest_half_delta)\n",
    "        target_threshold = thresholds_frame.iloc[closest_threshold_index]\n",
    "\n",
    "    rewrite_rate = target_threshold[\"rewrite_rate\"] / 100\n",
    "    original_judgments = inference_log_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < target_threshold[\"threshold\"] else row[\"judgment\"], axis=1)\n",
    "    return original_judgments, rewrite_rate\n",
    "\n",
    "\n",
    "def get_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < threshold else row[\"judgment\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True)\n",
    "    llm_call_count = (inference_logs_frame[\"original entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate\n",
    "\n",
    "\n",
    "calculate_entropy_threshold_jugments(sst5_data, \"SST-5\")\n",
    "calculate_entropy_threshold_jugments(semval_data, \"Sem Eval\")\n",
    "calculate_entropy_threshold_jugments(dynasent_data, \"Dynasent\")\n",
    "calculate_entropy_threshold_jugments(toxigen_data, \"ToxiGen\")\n",
    "calculate_entropy_threshold_jugments(adv_civil_data, \"Adv Civil\")\n",
    "calculate_entropy_threshold_jugments(implicit_hate_data, \"Implicit Hate\")\n",
    "calculate_entropy_threshold_jugments(agt_data, \"AG News Tweets\")\n",
    "\n",
    "fig.delaxes(axs[1, -1])\n",
    "fig.legend(loc=\"lower center\", fontsize=12, frameon=False, ncol=3, labels=[\"TTA\", \"No TTA (Baseline)\", \"Optimal Aug Rate\"], bbox_to_anchor=(0.5, -0.025))\n",
    "fig.tight_layout(pad=2.0)\n",
    "fig.savefig(\"../datasets/analysis/entropy_figures/appendix_acc_rewrite_curves.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_eval_original_entropies = semval_data[\"original entropy\"].tolist()\n",
    "figure = sns.scatterplot(data=semval_data, x=range(len(sem_eval_original_entropies)), y=\"original entropy\", hue=\"outcome\", s=5)\n",
    "# set legend to the right vertically\n",
    "figure.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0, frameon=False, title=\"Outcome\")\n",
    "# make y axis log scale\n",
    "figure.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data[[\"original entropy\", \"outcome\"]].groupby(\"outcome\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap between original entropy and outcome\n",
    "pd.crosstab(sst5_data[\"original entropy\"], semval_data[\"outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
