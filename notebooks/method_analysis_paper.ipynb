{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pointbiserialr\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tqdm.pandas()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "aug_regex = re.compile(r\"<aug>(.*?)</aug>\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting constants\n",
    "TITLE_FONT_SIZE = 16\n",
    "WSPACE = 0.3\n",
    "FIGURE_HEIGHT = 4\n",
    "LINE_WIDTH = 2\n",
    "FIG_SIZE = 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOSS_Sentiment_ID_BERT_Insert',\n",
       " 'BOSS_Sentiment_ID_BERT_Substitute',\n",
       " 'BOSS_Sentiment_ID_BERT_Translate',\n",
       " 'BOSS_Sentiment_ID_BERT_Paraphrase',\n",
       " 'BOSS_Sentiment_ID_BERT_ICR',\n",
       " 'BOSS_Sentiment_ID_T5_Insert',\n",
       " 'BOSS_Sentiment_ID_T5_Substitute',\n",
       " 'BOSS_Sentiment_ID_T5_Translate',\n",
       " 'BOSS_Sentiment_ID_T5_Paraphrase',\n",
       " 'BOSS_Sentiment_ID_T5_ICR',\n",
       " 'BOSS_Sentiment_ID_Falcon_Insert',\n",
       " 'BOSS_Sentiment_ID_Falcon_Substitute',\n",
       " 'BOSS_Sentiment_ID_Falcon_Translate',\n",
       " 'BOSS_Sentiment_ID_Falcon_Paraphrase',\n",
       " 'BOSS_Sentiment_ID_Falcon_ICR',\n",
       " 'BOSS_Sentiment_SST5_BERT_Insert',\n",
       " 'BOSS_Sentiment_SST5_BERT_Substitute',\n",
       " 'BOSS_Sentiment_SST5_BERT_Translate',\n",
       " 'BOSS_Sentiment_SST5_BERT_Paraphrase',\n",
       " 'BOSS_Sentiment_SST5_BERT_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_ICR',\n",
       " 'BOSS_Sentiment_SST5_T5_Insert',\n",
       " 'BOSS_Sentiment_SST5_T5_Substitute',\n",
       " 'BOSS_Sentiment_SST5_T5_Translate',\n",
       " 'BOSS_Sentiment_SST5_T5_Paraphrase',\n",
       " 'BOSS_Sentiment_SST5_T5_ICR',\n",
       " 'BOSS_Sentiment_SST5_Falcon_Insert',\n",
       " 'BOSS_Sentiment_SST5_Falcon_Substitute',\n",
       " 'BOSS_Sentiment_SST5_Falcon_Translate',\n",
       " 'BOSS_Sentiment_SST5_Falcon_Paraphrase',\n",
       " 'BOSS_Sentiment_SST5_Falcon_ICR',\n",
       " 'BOSS_Sentiment_SemEval_BERT_Insert',\n",
       " 'BOSS_Sentiment_SemEval_BERT_Substitute',\n",
       " 'BOSS_Sentiment_SemEval_BERT_Translate',\n",
       " 'BOSS_Sentiment_SemEval_BERT_Paraphrase',\n",
       " 'BOSS_Sentiment_SemEval_BERT_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_ICR',\n",
       " 'BOSS_Sentiment_SemEval_T5_Insert',\n",
       " 'BOSS_Sentiment_SemEval_T5_Substitute',\n",
       " 'BOSS_Sentiment_SemEval_T5_Translate',\n",
       " 'BOSS_Sentiment_SemEval_T5_Paraphrase',\n",
       " 'BOSS_Sentiment_SemEval_T5_ICR',\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Insert',\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Substitute',\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Translate',\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Paraphrase',\n",
       " 'BOSS_Sentiment_SemEval_Falcon_ICR',\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Insert',\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Substitute',\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Translate',\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Paraphrase',\n",
       " 'BOSS_Sentiment_Dynasent_BERT_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_ICR',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Insert',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Substitute',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Translate',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Paraphrase',\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_ICR',\n",
       " 'BOSS_Sentiment_Dynasent_T5_Insert',\n",
       " 'BOSS_Sentiment_Dynasent_T5_Substitute',\n",
       " 'BOSS_Sentiment_Dynasent_T5_Translate',\n",
       " 'BOSS_Sentiment_Dynasent_T5_Paraphrase',\n",
       " 'BOSS_Sentiment_Dynasent_T5_ICR',\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Insert',\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Substitute',\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Translate',\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Paraphrase',\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_ICR',\n",
       " 'BOSS_Toxicity_ID_BERT_Insert',\n",
       " 'BOSS_Toxicity_ID_BERT_Substitute',\n",
       " 'BOSS_Toxicity_ID_BERT_Translate',\n",
       " 'BOSS_Toxicity_ID_BERT_Paraphrase',\n",
       " 'BOSS_Toxicity_ID_BERT_ICR',\n",
       " 'BOSS_Toxicity_ID_T5_Insert',\n",
       " 'BOSS_Toxicity_ID_T5_Substitute',\n",
       " 'BOSS_Toxicity_ID_T5_Translate',\n",
       " 'BOSS_Toxicity_ID_T5_Paraphrase',\n",
       " 'BOSS_Toxicity_ID_T5_ICR',\n",
       " 'BOSS_Toxicity_ID_Falcon_Insert',\n",
       " 'BOSS_Toxicity_ID_Falcon_Substitute',\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Insert',\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Substitute',\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Translate',\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Paraphrase',\n",
       " 'BOSS_Toxicity_Toxigen_BERT_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_ICR',\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Insert',\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Substitute',\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Translate',\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Paraphrase',\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_ICR',\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Insert',\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Substitute',\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Translate',\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Paraphrase',\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_ICR',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Insert',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Substitute',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Translate',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Paraphrase',\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_ICR',\n",
       " 'AgNewsTweets_ID_BERT_Insert',\n",
       " 'AgNewsTweets_ID_BERT_Substitute',\n",
       " 'AgNewsTweets_ID_BERT_Translate',\n",
       " 'AgNewsTweets_ID_BERT_Paraphrase',\n",
       " 'AgNewsTweets_ID_BERT_ICR',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Insert',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Substitute',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Translate',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Paraphrase',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_ICR',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Insert',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Substitute',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Translate',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Paraphrase',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_ICR',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Insert',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Substitute',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Translate',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Paraphrase',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_ICR',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Insert',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Substitute',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Translate',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Paraphrase',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_ICR',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Insert',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Substitute',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Translate',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Paraphrase',\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_ICR',\n",
       " 'AgNewsTweets_ID_T5_Insert',\n",
       " 'AgNewsTweets_ID_T5_Substitute',\n",
       " 'AgNewsTweets_ID_T5_Translate',\n",
       " 'AgNewsTweets_ID_T5_Paraphrase',\n",
       " 'AgNewsTweets_ID_T5_ICR',\n",
       " 'AgNewsTweets_ID_Falcon_Insert',\n",
       " 'AgNewsTweets_ID_Falcon_Substitute',\n",
       " 'AgNewsTweets_ID_Falcon_Translate',\n",
       " 'AgNewsTweets_ID_Falcon_Paraphrase',\n",
       " 'AgNewsTweets_ID_Falcon_ICR',\n",
       " 'AgNewsTweets_Tweets_BERT_Insert',\n",
       " 'AgNewsTweets_Tweets_BERT_Substitute',\n",
       " 'AgNewsTweets_Tweets_BERT_Translate',\n",
       " 'AgNewsTweets_Tweets_BERT_Paraphrase',\n",
       " 'AgNewsTweets_Tweets_BERT_ICR',\n",
       " 'AgNewsTweets_Tweets_T5_Insert',\n",
       " 'AgNewsTweets_Tweets_T5_Substitute',\n",
       " 'AgNewsTweets_Tweets_T5_Translate',\n",
       " 'AgNewsTweets_Tweets_T5_Paraphrase',\n",
       " 'AgNewsTweets_Tweets_T5_ICR',\n",
       " 'AgNewsTweets_Tweets_Falcon_Insert',\n",
       " 'AgNewsTweets_Tweets_Falcon_Substitute',\n",
       " 'AgNewsTweets_Tweets_Falcon_Translate',\n",
       " 'AgNewsTweets_Tweets_Falcon_Paraphrase',\n",
       " 'AgNewsTweets_Tweets_Falcon_ICR']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inference_logs = load_from_disk(\"data/combined_dataset\")\n",
    "list(inference_logs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_task_name(split_name):\n",
    "    return \"Sentiment\" if \"Sentiment\" in split_name else \"Toxicity\" if \"Toxicity\" in split_name else \"News\"\n",
    "\n",
    "def parse_distribution(split_name):\n",
    "    return split_name.split(\"_\")[-3]\n",
    "\n",
    "def parse_model(split_name):\n",
    "    return split_name.split(\"_\")[-2]\n",
    "\n",
    "def parse_tta_method(split_name):\n",
    "    return split_name.split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No TTA Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/292 [00:02<00:51,  5.47it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  4%|▍         | 11/292 [00:02<00:53,  5.23it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  4%|▍         | 12/292 [00:02<00:55,  5.08it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  4%|▍         | 13/292 [00:02<00:52,  5.30it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  5%|▍         | 14/292 [00:02<00:50,  5.47it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 292/292 [00:18<00:00, 15.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BOSS_Sentiment_ID_BERT_Insert': 0.9037888134896155,\n",
       " 'BOSS_Sentiment_ID_BERT_Substitute': 0.9037888134896155,\n",
       " 'BOSS_Sentiment_ID_BERT_Translate': 0.9037888134896155,\n",
       " 'BOSS_Sentiment_ID_BERT_Paraphrase': 0.9037888134896155,\n",
       " 'BOSS_Sentiment_ID_BERT_ICR': 0.9037888134896155,\n",
       " 'BOSS_Sentiment_ID_T5_Insert': 0.9011412708204812,\n",
       " 'BOSS_Sentiment_ID_T5_Substitute': 0.9011412708204812,\n",
       " 'BOSS_Sentiment_ID_T5_Translate': 0.9011412708204812,\n",
       " 'BOSS_Sentiment_ID_T5_Paraphrase': 0.9011412708204812,\n",
       " 'BOSS_Sentiment_ID_T5_ICR': 0.9011412708204812,\n",
       " 'BOSS_Sentiment_ID_Falcon_Insert': 0.9049712111865104,\n",
       " 'BOSS_Sentiment_ID_Falcon_Substitute': 0.9049712111865104,\n",
       " 'BOSS_Sentiment_ID_Falcon_Translate': 0.9049712111865104,\n",
       " 'BOSS_Sentiment_ID_Falcon_Paraphrase': 0.9049712111865104,\n",
       " 'BOSS_Sentiment_ID_Falcon_ICR': 0.9049712111865104,\n",
       " 'BOSS_Sentiment_SST5_BERT_Insert': 0.6847014925373134,\n",
       " 'BOSS_Sentiment_SST5_BERT_Substitute': 0.6847014925373134,\n",
       " 'BOSS_Sentiment_SST5_BERT_Translate': 0.6847014925373134,\n",
       " 'BOSS_Sentiment_SST5_BERT_Paraphrase': 0.6847014925373134,\n",
       " 'BOSS_Sentiment_SST5_BERT_ICR': 0.6847014925373134,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Insert': 0.6828358208955224,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Substitute': 0.6828358208955224,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Translate': 0.6828358208955224,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_Paraphrase': 0.6828358208955224,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT1500_ICR': 0.6828358208955224,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Insert': 0.6791044776119403,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Substitute': 0.6791044776119403,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Translate': 0.6791044776119403,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_Paraphrase': 0.6791044776119403,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT3000_ICR': 0.6791044776119403,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Insert': 0.6753731343283582,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Substitute': 0.6753731343283582,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Translate': 0.6753731343283582,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_Paraphrase': 0.6753731343283582,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT6000_ICR': 0.6753731343283582,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Insert': 0.6669776119402985,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Substitute': 0.6669776119402985,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Translate': 0.6669776119402985,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_Paraphrase': 0.6669776119402985,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT120000_ICR': 0.6669776119402985,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Insert': 0.6884328358208955,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Substitute': 0.6884328358208955,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Translate': 0.6884328358208955,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_Paraphrase': 0.6884328358208955,\n",
       " 'BOSS_Sentiment_Ablate_Data_SST5_BERT24000_ICR': 0.6884328358208955,\n",
       " 'BOSS_Sentiment_SST5_T5_Insert': 0.7611940298507462,\n",
       " 'BOSS_Sentiment_SST5_T5_Substitute': 0.7611940298507462,\n",
       " 'BOSS_Sentiment_SST5_T5_Translate': 0.7611940298507462,\n",
       " 'BOSS_Sentiment_SST5_T5_Paraphrase': 0.7611940298507462,\n",
       " 'BOSS_Sentiment_SST5_T5_ICR': 0.7611940298507462,\n",
       " 'BOSS_Sentiment_SST5_Falcon_Insert': 0.5708955223880597,\n",
       " 'BOSS_Sentiment_SST5_Falcon_Substitute': 0.5708955223880597,\n",
       " 'BOSS_Sentiment_SST5_Falcon_Translate': 0.5708955223880597,\n",
       " 'BOSS_Sentiment_SST5_Falcon_Paraphrase': 0.5708955223880597,\n",
       " 'BOSS_Sentiment_SST5_Falcon_ICR': 0.5708955223880597,\n",
       " 'BOSS_Sentiment_SemEval_BERT_Insert': 0.4497187742435997,\n",
       " 'BOSS_Sentiment_SemEval_BERT_Substitute': 0.4497187742435997,\n",
       " 'BOSS_Sentiment_SemEval_BERT_Translate': 0.4497187742435997,\n",
       " 'BOSS_Sentiment_SemEval_BERT_Paraphrase': 0.4497187742435997,\n",
       " 'BOSS_Sentiment_SemEval_BERT_ICR': 0.4497187742435997,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Insert': 0.48322342901474014,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Substitute': 0.48322342901474014,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Translate': 0.48322342901474014,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_Paraphrase': 0.48322342901474014,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT1500_ICR': 0.48322342901474014,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Insert': 0.4375,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Substitute': 0.4375,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Translate': 0.4375,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_Paraphrase': 0.4375,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT3000_ICR': 0.4375,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Insert': 0.4659134988363072,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Substitute': 0.4659134988363072,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Translate': 0.4659134988363072,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_Paraphrase': 0.4659134988363072,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT6000_ICR': 0.4659134988363072,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Insert': 0.46450737005430565,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Substitute': 0.46450737005430565,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Translate': 0.46450737005430565,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_Paraphrase': 0.46450737005430565,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT120000_ICR': 0.46450737005430565,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Insert': 0.4725077579519007,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Substitute': 0.4725077579519007,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Translate': 0.4725077579519007,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_Paraphrase': 0.4725077579519007,\n",
       " 'BOSS_Sentiment_Ablate_Data_SemEval_BERT24000_ICR': 0.4725077579519007,\n",
       " 'BOSS_Sentiment_SemEval_T5_Insert': 0.5006788207913111,\n",
       " 'BOSS_Sentiment_SemEval_T5_Substitute': 0.5006788207913111,\n",
       " 'BOSS_Sentiment_SemEval_T5_Translate': 0.5006788207913111,\n",
       " 'BOSS_Sentiment_SemEval_T5_Paraphrase': 0.5006788207913111,\n",
       " 'BOSS_Sentiment_SemEval_T5_ICR': 0.5006788207913111,\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Insert': 0.41262606671838636,\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Substitute': 0.41262606671838636,\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Translate': 0.41262606671838636,\n",
       " 'BOSS_Sentiment_SemEval_Falcon_Paraphrase': 0.41262606671838636,\n",
       " 'BOSS_Sentiment_SemEval_Falcon_ICR': 0.41262606671838636,\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Insert': 0.4270833333333333,\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Substitute': 0.4270833333333333,\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Translate': 0.4270833333333333,\n",
       " 'BOSS_Sentiment_Dynasent_BERT_Paraphrase': 0.4270833333333333,\n",
       " 'BOSS_Sentiment_Dynasent_BERT_ICR': 0.4270833333333333,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Insert': 0.4358796296296296,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Substitute': 0.4358796296296296,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Translate': 0.4358796296296296,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_Paraphrase': 0.4358796296296296,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT1500_ICR': 0.4358796296296296,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Insert': 0.4361111111111111,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Substitute': 0.4361111111111111,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Translate': 0.4361111111111111,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_Paraphrase': 0.4361111111111111,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT3000_ICR': 0.4361111111111111,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Insert': 0.40625,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Substitute': 0.40625,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Translate': 0.40625,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_Paraphrase': 0.40625,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT6000_ICR': 0.40625,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Insert': 0.4532407407407407,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Substitute': 0.4532407407407407,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Translate': 0.4532407407407407,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_Paraphrase': 0.4532407407407407,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT120000_ICR': 0.4532407407407407,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Insert': 0.4439814814814815,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Substitute': 0.4439814814814815,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Translate': 0.4439814814814815,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_Paraphrase': 0.4439814814814815,\n",
       " 'BOSS_Sentiment_Ablate_Data_Dynasent_BERT24000_ICR': 0.4439814814814815,\n",
       " 'BOSS_Sentiment_Dynasent_T5_Insert': 0.4777777777777778,\n",
       " 'BOSS_Sentiment_Dynasent_T5_Substitute': 0.4777777777777778,\n",
       " 'BOSS_Sentiment_Dynasent_T5_Translate': 0.4777777777777778,\n",
       " 'BOSS_Sentiment_Dynasent_T5_Paraphrase': 0.4777777777777778,\n",
       " 'BOSS_Sentiment_Dynasent_T5_ICR': 0.4777777777777778,\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Insert': 0.43148148148148147,\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Substitute': 0.43148148148148147,\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Translate': 0.43148148148148147,\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_Paraphrase': 0.43148148148148147,\n",
       " 'BOSS_Sentiment_Dynasent_Falcon_ICR': 0.43148148148148147,\n",
       " 'BOSS_Toxicity_ID_BERT_Insert': 0.8846177558569667,\n",
       " 'BOSS_Toxicity_ID_BERT_Substitute': 0.8846177558569667,\n",
       " 'BOSS_Toxicity_ID_BERT_Translate': 0.8846177558569667,\n",
       " 'BOSS_Toxicity_ID_BERT_Paraphrase': 0.8846177558569667,\n",
       " 'BOSS_Toxicity_ID_BERT_ICR': 0.8846177558569667,\n",
       " 'BOSS_Toxicity_ID_T5_Insert': 0.9057233867653103,\n",
       " 'BOSS_Toxicity_ID_T5_Substitute': 0.9057233867653103,\n",
       " 'BOSS_Toxicity_ID_T5_Translate': 0.9057233867653103,\n",
       " 'BOSS_Toxicity_ID_T5_Paraphrase': 0.9057233867653103,\n",
       " 'BOSS_Toxicity_ID_T5_ICR': 0.9057233867653103,\n",
       " 'BOSS_Toxicity_ID_Falcon_Insert': 0.17002671598849156,\n",
       " 'BOSS_Toxicity_ID_Falcon_Substitute': 0.17002671598849156,\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Insert': 0.6673728813559322,\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Substitute': 0.6673728813559322,\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Translate': 0.6673728813559322,\n",
       " 'BOSS_Toxicity_Toxigen_BERT_Paraphrase': 0.6673728813559322,\n",
       " 'BOSS_Toxicity_Toxigen_BERT_ICR': 0.6673728813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Insert': 0.6207627118644068,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Substitute': 0.6207627118644068,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Translate': 0.6207627118644068,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_Paraphrase': 0.6207627118644068,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT3000_ICR': 0.6207627118644068,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Insert': 0.611228813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Substitute': 0.611228813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Translate': 0.611228813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_Paraphrase': 0.611228813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT6000_ICR': 0.611228813559322,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Insert': 0.621822033898305,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Substitute': 0.621822033898305,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Translate': 0.621822033898305,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_Paraphrase': 0.621822033898305,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT12000_ICR': 0.621822033898305,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Insert': 0.6451271186440678,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Substitute': 0.6451271186440678,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Translate': 0.6451271186440678,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_Paraphrase': 0.6451271186440678,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT24000_ICR': 0.6451271186440678,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Insert': 0.652542372881356,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Substitute': 0.652542372881356,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Translate': 0.652542372881356,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_Paraphrase': 0.652542372881356,\n",
       " 'BOSS_Toxicity_Ablate_Data_Toxigen_BERT48000_ICR': 0.652542372881356,\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Insert': 0.6452513966480447,\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Substitute': 0.6452513966480447,\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Translate': 0.6452513966480447,\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_Paraphrase': 0.6452513966480447,\n",
       " 'BOSS_Toxicity_ImplicitHate_BERT_ICR': 0.6452513966480447,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Insert': 0.6128491620111732,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Substitute': 0.6128491620111732,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Translate': 0.6128491620111732,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_Paraphrase': 0.6128491620111732,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT3000_ICR': 0.6128491620111732,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Insert': 0.6365921787709498,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Substitute': 0.6365921787709498,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Translate': 0.6365921787709498,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_Paraphrase': 0.6365921787709498,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT6000_ICR': 0.6365921787709498,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Insert': 0.6067970204841713,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Substitute': 0.6067970204841713,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Translate': 0.6067970204841713,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_Paraphrase': 0.6067970204841713,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT12000_ICR': 0.6067970204841713,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Insert': 0.6287709497206704,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Substitute': 0.6287709497206704,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Translate': 0.6287709497206704,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_Paraphrase': 0.6287709497206704,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT24000_ICR': 0.6287709497206704,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Insert': 0.6102886405959032,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Substitute': 0.6102886405959032,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Translate': 0.6102886405959032,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_Paraphrase': 0.6102886405959032,\n",
       " 'BOSS_Toxicity_Ablate_Data_ImplicitHate_BERT48000_ICR': 0.6102886405959032,\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Insert': 0.30461165048543687,\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Substitute': 0.30461165048543687,\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Translate': 0.30461165048543687,\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_Paraphrase': 0.30461165048543687,\n",
       " 'BOSS_Toxicity_AdvCivil_BERT_ICR': 0.30461165048543687,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Insert': 0.36650485436893204,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Substitute': 0.36650485436893204,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Translate': 0.36650485436893204,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_Paraphrase': 0.36650485436893204,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT3000_ICR': 0.36650485436893204,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Insert': 0.4077669902912621,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Substitute': 0.4077669902912621,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Translate': 0.4077669902912621,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_Paraphrase': 0.4077669902912621,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT6000_ICR': 0.4077669902912621,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Insert': 0.3179611650485437,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Substitute': 0.3179611650485437,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Translate': 0.3179611650485437,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_Paraphrase': 0.3179611650485437,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT12000_ICR': 0.3179611650485437,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Insert': 0.2487864077669903,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Substitute': 0.2487864077669903,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Translate': 0.2487864077669903,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_Paraphrase': 0.2487864077669903,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT24000_ICR': 0.2487864077669903,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Insert': 0.33616504854368934,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Substitute': 0.33616504854368934,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Translate': 0.33616504854368934,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_Paraphrase': 0.33616504854368934,\n",
       " 'BOSS_Toxicity_Ablate_Data_AdvCivil_BERT48000_ICR': 0.33616504854368934,\n",
       " 'AgNewsTweets_ID_BERT_Insert': 0.9482894736842106,\n",
       " 'AgNewsTweets_ID_BERT_Substitute': 0.9482894736842106,\n",
       " 'AgNewsTweets_ID_BERT_Translate': 0.9482894736842106,\n",
       " 'AgNewsTweets_ID_BERT_Paraphrase': 0.9482894736842106,\n",
       " 'AgNewsTweets_ID_BERT_ICR': 0.9482894736842106,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Insert': 0.8864473684210527,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Substitute': 0.8864473684210527,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Translate': 0.8864473684210527,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_Paraphrase': 0.8864473684210527,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT4800_ICR': 0.8864473684210527,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Insert': 0.8894736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Substitute': 0.8894736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Translate': 0.8894736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_Paraphrase': 0.8894736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT9600_ICR': 0.8894736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Insert': 0.8786842105263157,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Substitute': 0.8786842105263157,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Translate': 0.8786842105263157,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_Paraphrase': 0.8786842105263157,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT19200_ICR': 0.8786842105263157,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Insert': 0.8840789473684211,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Substitute': 0.8840789473684211,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Translate': 0.8840789473684211,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_Paraphrase': 0.8840789473684211,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT38400_ICR': 0.8840789473684211,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Insert': 0.8719736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Substitute': 0.8719736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Translate': 0.8719736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_Paraphrase': 0.8719736842105263,\n",
       " 'AgNewsTweets_Ablate_Data_Tweets_BERT76800_ICR': 0.8719736842105263,\n",
       " 'AgNewsTweets_ID_T5_Insert': 0.9486842105263158,\n",
       " 'AgNewsTweets_ID_T5_Substitute': 0.9486842105263158,\n",
       " 'AgNewsTweets_ID_T5_Translate': 0.9486842105263158,\n",
       " 'AgNewsTweets_ID_T5_Paraphrase': 0.9486842105263158,\n",
       " 'AgNewsTweets_ID_T5_ICR': 0.9486842105263158,\n",
       " 'AgNewsTweets_ID_Falcon_Insert': 0.3030263157894737,\n",
       " 'AgNewsTweets_ID_Falcon_Substitute': 0.3030263157894737,\n",
       " 'AgNewsTweets_ID_Falcon_Translate': 0.3030263157894737,\n",
       " 'AgNewsTweets_ID_Falcon_Paraphrase': 0.3030263157894737,\n",
       " 'AgNewsTweets_ID_Falcon_ICR': 0.3030263157894737,\n",
       " 'AgNewsTweets_Tweets_BERT_Insert': 0.8856578947368421,\n",
       " 'AgNewsTweets_Tweets_BERT_Substitute': 0.8856578947368421,\n",
       " 'AgNewsTweets_Tweets_BERT_Translate': 0.8856578947368421,\n",
       " 'AgNewsTweets_Tweets_BERT_Paraphrase': 0.8856578947368421,\n",
       " 'AgNewsTweets_Tweets_BERT_ICR': 0.8856578947368421,\n",
       " 'AgNewsTweets_Tweets_T5_Insert': 0.8901315789473684,\n",
       " 'AgNewsTweets_Tweets_T5_Substitute': 0.8901315789473684,\n",
       " 'AgNewsTweets_Tweets_T5_Translate': 0.8901315789473684,\n",
       " 'AgNewsTweets_Tweets_T5_Paraphrase': 0.8901315789473684,\n",
       " 'AgNewsTweets_Tweets_T5_ICR': 0.8901315789473684,\n",
       " 'AgNewsTweets_Tweets_Falcon_Insert': 0.26,\n",
       " 'AgNewsTweets_Tweets_Falcon_Substitute': 0.26,\n",
       " 'AgNewsTweets_Tweets_Falcon_Translate': 0.26,\n",
       " 'AgNewsTweets_Tweets_Falcon_Paraphrase': 0.26,\n",
       " 'AgNewsTweets_Tweets_Falcon_ICR': 0.26}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_tta_accuracies = {}\n",
    "for split_name in tqdm(inference_logs):\n",
    "    split_frame = inference_logs[split_name].to_pandas()\n",
    "    split_no_tta_accuracy = classification_report(split_frame[\"label\"], split_frame[\"original_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "    no_tta_accuracies[split_name] = split_no_tta_accuracy\n",
    "\n",
    "no_tta_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/117 [00:00<00:08, 14.33it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  3%|▎         | 4/117 [00:00<00:07, 14.51it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  7%|▋         | 8/117 [00:00<00:07, 14.64it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  9%|▊         | 10/117 [00:00<00:07, 14.55it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 10%|█         | 12/117 [00:00<00:07, 14.19it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 12%|█▏        | 14/117 [00:00<00:07, 13.95it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 36%|███▌      | 42/117 [00:01<00:02, 34.24it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 117/117 [00:01<00:00, 63.01it/s]\n",
      "100%|██████████| 117/117 [00:02<00:00, 45.43it/s]\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 80%|████████  | 94/117 [00:00<00:00, 861.55it/s]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 117/117 [00:00<00:00, 252.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"BOSS_Sentiment\": {\n",
      "        \"BERT\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9037888134896155,\n",
      "                    \"tta_accuracy\": 0.9048169853999589,\n",
      "                    \"accuracy_delta\": 0.001028171910343434\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6847014925373134,\n",
      "                    \"tta_accuracy\": 0.683768656716418,\n",
      "                    \"accuracy_delta\": -0.0009328358208954279\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4497187742435997,\n",
      "                    \"tta_accuracy\": 0.44821567106283944,\n",
      "                    \"accuracy_delta\": -0.0015031031807602457\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4270833333333333,\n",
      "                    \"tta_accuracy\": 0.42569444444444443,\n",
      "                    \"accuracy_delta\": -0.001388888888888884\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.0012749426301815192,\n",
      "                \"mean_baseline_accuracy\": 0.5205012000380821\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9037888134896155,\n",
      "                    \"tta_accuracy\": 0.899599012954966,\n",
      "                    \"accuracy_delta\": -0.004189800534649457\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6847014925373134,\n",
      "                    \"tta_accuracy\": 0.6781716417910447,\n",
      "                    \"accuracy_delta\": -0.006529850746268662\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4497187742435997,\n",
      "                    \"tta_accuracy\": 0.449088440651668,\n",
      "                    \"accuracy_delta\": -0.0006303335919317088\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4270833333333333,\n",
      "                    \"tta_accuracy\": 0.42615740740740743,\n",
      "                    \"accuracy_delta\": -0.0009259259259258856\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.0026953700880420852,\n",
      "                \"mean_baseline_accuracy\": 0.5205012000380821\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9037888134896155,\n",
      "                    \"tta_accuracy\": 0.8904996915484269,\n",
      "                    \"accuracy_delta\": -0.013289121941188586\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6847014925373134,\n",
      "                    \"tta_accuracy\": 0.691231343283582,\n",
      "                    \"accuracy_delta\": 0.006529850746268662\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4497187742435997,\n",
      "                    \"tta_accuracy\": 0.45500387897595035,\n",
      "                    \"accuracy_delta\": 0.005285104732350665\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4270833333333333,\n",
      "                    \"tta_accuracy\": 0.43171296296296297,\n",
      "                    \"accuracy_delta\": 0.00462962962962965\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.005481528369416326,\n",
      "                \"mean_baseline_accuracy\": 0.5205012000380821\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9037888134896155,\n",
      "                    \"tta_accuracy\": 0.9053567756528892,\n",
      "                    \"accuracy_delta\": 0.0015679621632737062\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6847014925373134,\n",
      "                    \"tta_accuracy\": 0.7098880597014925,\n",
      "                    \"accuracy_delta\": 0.025186567164179108\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4497187742435997,\n",
      "                    \"tta_accuracy\": 0.47628975950349106,\n",
      "                    \"accuracy_delta\": 0.026570985259891378\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4270833333333333,\n",
      "                    \"tta_accuracy\": 0.4534722222222222,\n",
      "                    \"accuracy_delta\": 0.026388888888888906\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.026048813770986463,\n",
      "                \"mean_baseline_accuracy\": 0.5205012000380821\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9037888134896155,\n",
      "                    \"tta_accuracy\": 0.9085184042771951,\n",
      "                    \"accuracy_delta\": 0.004729590787579618\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6847014925373134,\n",
      "                    \"tta_accuracy\": 0.7397388059701493,\n",
      "                    \"accuracy_delta\": 0.05503731343283591\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4497187742435997,\n",
      "                    \"tta_accuracy\": 0.4904965089216447,\n",
      "                    \"accuracy_delta\": 0.04077773467804502\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4270833333333333,\n",
      "                    \"tta_accuracy\": 0.47708333333333336,\n",
      "                    \"accuracy_delta\": 0.050000000000000044\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.048605016036960325,\n",
      "                \"mean_baseline_accuracy\": 0.5205012000380821\n",
      "            }\n",
      "        },\n",
      "        \"T5\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9011412708204812,\n",
      "                    \"tta_accuracy\": 0.8840222085132634,\n",
      "                    \"accuracy_delta\": -0.017119062307217825\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.7611940298507462,\n",
      "                    \"tta_accuracy\": 0.7257462686567164,\n",
      "                    \"accuracy_delta\": -0.035447761194029814\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.5006788207913111,\n",
      "                    \"tta_accuracy\": 0.4944239720713732,\n",
      "                    \"accuracy_delta\": -0.006254848719937922\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4777777777777778,\n",
      "                    \"tta_accuracy\": 0.4601851851851852,\n",
      "                    \"accuracy_delta\": -0.017592592592592604\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.01976506750218678,\n",
      "                \"mean_baseline_accuracy\": 0.5798835428066117\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9011412708204812,\n",
      "                    \"tta_accuracy\": 0.8577781205017478,\n",
      "                    \"accuracy_delta\": -0.04336315031873339\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.7611940298507462,\n",
      "                    \"tta_accuracy\": 0.7080223880597015,\n",
      "                    \"accuracy_delta\": -0.05317164179104472\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.5006788207913111,\n",
      "                    \"tta_accuracy\": 0.4855508145849496,\n",
      "                    \"accuracy_delta\": -0.01512800620636151\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4777777777777778,\n",
      "                    \"tta_accuracy\": 0.4585648148148148,\n",
      "                    \"accuracy_delta\": -0.019212962962962987\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.029170870320123072,\n",
      "                \"mean_baseline_accuracy\": 0.5798835428066117\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9011412708204812,\n",
      "                    \"tta_accuracy\": 0.8721982315443142,\n",
      "                    \"accuracy_delta\": -0.028943039276167037\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.7611940298507462,\n",
      "                    \"tta_accuracy\": 0.7416044776119403,\n",
      "                    \"accuracy_delta\": -0.019589552238805985\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.5006788207913111,\n",
      "                    \"tta_accuracy\": 0.49146625290923196,\n",
      "                    \"accuracy_delta\": -0.009212567882079137\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4777777777777778,\n",
      "                    \"tta_accuracy\": 0.4726851851851852,\n",
      "                    \"accuracy_delta\": -0.005092592592592593\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.011298237571159239,\n",
      "                \"mean_baseline_accuracy\": 0.5798835428066117\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9011412708204812,\n",
      "                    \"tta_accuracy\": 0.89898210980876,\n",
      "                    \"accuracy_delta\": -0.0021591610117212\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.7611940298507462,\n",
      "                    \"tta_accuracy\": 0.7630597014925373,\n",
      "                    \"accuracy_delta\": 0.001865671641791078\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.5006788207913111,\n",
      "                    \"tta_accuracy\": 0.5079519006982157,\n",
      "                    \"accuracy_delta\": 0.007273079906904623\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4777777777777778,\n",
      "                    \"tta_accuracy\": 0.5039351851851852,\n",
      "                    \"accuracy_delta\": 0.026157407407407407\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.011765386318701035,\n",
      "                \"mean_baseline_accuracy\": 0.5798835428066117\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9011412708204812,\n",
      "                    \"tta_accuracy\": 0.9077986839399548,\n",
      "                    \"accuracy_delta\": 0.006657413119473543\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.7611940298507462,\n",
      "                    \"tta_accuracy\": 0.7621268656716418,\n",
      "                    \"accuracy_delta\": 0.000932835820895539\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.5006788207913111,\n",
      "                    \"tta_accuracy\": 0.5112975174553918,\n",
      "                    \"accuracy_delta\": 0.010618696664080662\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4777777777777778,\n",
      "                    \"tta_accuracy\": 0.5215277777777778,\n",
      "                    \"accuracy_delta\": 0.04375000000000001\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.018433844161658736,\n",
      "                \"mean_baseline_accuracy\": 0.5798835428066117\n",
      "            }\n",
      "        },\n",
      "        \"Falcon\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9049712111865104,\n",
      "                    \"tta_accuracy\": 0.894149701830146,\n",
      "                    \"accuracy_delta\": -0.01082150935636439\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.5708955223880597,\n",
      "                    \"tta_accuracy\": 0.5559701492537313,\n",
      "                    \"accuracy_delta\": -0.014925373134328401\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.41262606671838636,\n",
      "                    \"tta_accuracy\": 0.4166989914662529,\n",
      "                    \"accuracy_delta\": 0.004072924747866524\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.43148148148148147,\n",
      "                    \"tta_accuracy\": 0.41782407407407407,\n",
      "                    \"accuracy_delta\": -0.013657407407407396\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.008169951931289757,\n",
      "                \"mean_baseline_accuracy\": 0.4716676901959758\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9049712111865104,\n",
      "                    \"tta_accuracy\": 0.8657721571046679,\n",
      "                    \"accuracy_delta\": -0.03919905408184243\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.5708955223880597,\n",
      "                    \"tta_accuracy\": 0.5242537313432836,\n",
      "                    \"accuracy_delta\": -0.04664179104477617\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.41262606671838636,\n",
      "                    \"tta_accuracy\": 0.3831943366951125,\n",
      "                    \"accuracy_delta\": -0.029431730023273872\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.43148148148148147,\n",
      "                    \"tta_accuracy\": 0.42060185185185184,\n",
      "                    \"accuracy_delta\": -0.010879629629629628\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.028984383565893224,\n",
      "                \"mean_baseline_accuracy\": 0.4716676901959758\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9049712111865104,\n",
      "                    \"tta_accuracy\": 0.8713756940160395,\n",
      "                    \"accuracy_delta\": -0.03359551717047082\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.5708955223880597,\n",
      "                    \"tta_accuracy\": 0.5326492537313433,\n",
      "                    \"accuracy_delta\": -0.03824626865671643\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.41262606671838636,\n",
      "                    \"tta_accuracy\": 0.40079519006982156,\n",
      "                    \"accuracy_delta\": -0.011830876648564803\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.43148148148148147,\n",
      "                    \"tta_accuracy\": 0.41597222222222224,\n",
      "                    \"accuracy_delta\": -0.015509259259259223\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.02186213485484682,\n",
      "                \"mean_baseline_accuracy\": 0.4716676901959758\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9049712111865104,\n",
      "                    \"tta_accuracy\": 0.9034803619165125,\n",
      "                    \"accuracy_delta\": -0.0014908492699978737\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.5708955223880597,\n",
      "                    \"tta_accuracy\": 0.5494402985074627,\n",
      "                    \"accuracy_delta\": -0.021455223880597063\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.41262606671838636,\n",
      "                    \"tta_accuracy\": 0.41306245151280063,\n",
      "                    \"accuracy_delta\": 0.0004363847944142685\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.43148148148148147,\n",
      "                    \"tta_accuracy\": 0.4150462962962963,\n",
      "                    \"accuracy_delta\": -0.016435185185185164\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.012484674757122652,\n",
      "                \"mean_baseline_accuracy\": 0.4716676901959758\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9049712111865104,\n",
      "                    \"tta_accuracy\": 0.9034803619165125,\n",
      "                    \"accuracy_delta\": -0.0014908492699978737\n",
      "                },\n",
      "                \"SST5\": {\n",
      "                    \"distribution\": \"SST5\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.5708955223880597,\n",
      "                    \"tta_accuracy\": 0.5167910447761194,\n",
      "                    \"accuracy_delta\": -0.05410447761194037\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"distribution\": \"SemEval\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.41262606671838636,\n",
      "                    \"tta_accuracy\": 0.4034134988363072,\n",
      "                    \"accuracy_delta\": -0.009212567882079137\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"distribution\": \"Dynasent\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.43148148148148147,\n",
      "                    \"tta_accuracy\": 0.40578703703703706,\n",
      "                    \"accuracy_delta\": -0.02569444444444441\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.029670496646154638,\n",
      "                \"mean_baseline_accuracy\": 0.4716676901959758\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"BOSS_Toxicity\": {\n",
      "        \"BERT\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8846177558569667,\n",
      "                    \"tta_accuracy\": 0.8925092478421701,\n",
      "                    \"accuracy_delta\": 0.007891491985203447\n",
      "                },\n",
      "                \"Toxigen\": {\n",
      "                    \"distribution\": \"Toxigen\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6673728813559322,\n",
      "                    \"tta_accuracy\": 0.6726694915254238,\n",
      "                    \"accuracy_delta\": 0.005296610169491567\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"distribution\": \"ImplicitHate\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6452513966480447,\n",
      "                    \"tta_accuracy\": 0.6485102420856611,\n",
      "                    \"accuracy_delta\": 0.0032588454376164533\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"distribution\": \"AdvCivil\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.30461165048543687,\n",
      "                    \"tta_accuracy\": 0.27184466019417475,\n",
      "                    \"accuracy_delta\": -0.03276699029126212\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.0080705115613847,\n",
      "                \"mean_baseline_accuracy\": 0.5390786428298046\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8846177558569667,\n",
      "                    \"tta_accuracy\": 0.8989930127414715,\n",
      "                    \"accuracy_delta\": 0.014375256884504806\n",
      "                },\n",
      "                \"Toxigen\": {\n",
      "                    \"distribution\": \"Toxigen\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6673728813559322,\n",
      "                    \"tta_accuracy\": 0.6546610169491526,\n",
      "                    \"accuracy_delta\": -0.012711864406779627\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"distribution\": \"ImplicitHate\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6452513966480447,\n",
      "                    \"tta_accuracy\": 0.6587988826815643,\n",
      "                    \"accuracy_delta\": 0.013547486033519629\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"distribution\": \"AdvCivil\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.30461165048543687,\n",
      "                    \"tta_accuracy\": 0.28762135922330095,\n",
      "                    \"accuracy_delta\": -0.016990291262135915\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.005384889878465304,\n",
      "                \"mean_baseline_accuracy\": 0.5390786428298046\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8846177558569667,\n",
      "                    \"tta_accuracy\": 0.8964036169338265,\n",
      "                    \"accuracy_delta\": 0.01178586107685986\n",
      "                },\n",
      "                \"Toxigen\": {\n",
      "                    \"distribution\": \"Toxigen\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6673728813559322,\n",
      "                    \"tta_accuracy\": 0.659957627118644,\n",
      "                    \"accuracy_delta\": -0.007415254237288171\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"distribution\": \"ImplicitHate\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6452513966480447,\n",
      "                    \"tta_accuracy\": 0.643342644320298,\n",
      "                    \"accuracy_delta\": -0.0019087523277466767\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"distribution\": \"AdvCivil\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.30461165048543687,\n",
      "                    \"tta_accuracy\": 0.5461165048543689,\n",
      "                    \"accuracy_delta\": 0.24150485436893204\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0773936159346324,\n",
      "                \"mean_baseline_accuracy\": 0.5390786428298046\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8846177558569667,\n",
      "                    \"tta_accuracy\": 0.905815865187012,\n",
      "                    \"accuracy_delta\": 0.02119810933004529\n",
      "                },\n",
      "                \"Toxigen\": {\n",
      "                    \"distribution\": \"Toxigen\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6673728813559322,\n",
      "                    \"tta_accuracy\": 0.6684322033898306,\n",
      "                    \"accuracy_delta\": 0.0010593220338983578\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"distribution\": \"ImplicitHate\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6452513966480447,\n",
      "                    \"tta_accuracy\": 0.6496275605214152,\n",
      "                    \"accuracy_delta\": 0.0043761638733705865\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"distribution\": \"AdvCivil\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.30461165048543687,\n",
      "                    \"tta_accuracy\": 0.6128640776699029,\n",
      "                    \"accuracy_delta\": 0.30825242718446605\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.104562637697245,\n",
      "                \"mean_baseline_accuracy\": 0.5390786428298046\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8846177558569667,\n",
      "                    \"tta_accuracy\": 0.9144677353062063,\n",
      "                    \"accuracy_delta\": 0.029849979449239616\n",
      "                },\n",
      "                \"Toxigen\": {\n",
      "                    \"distribution\": \"Toxigen\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6673728813559322,\n",
      "                    \"tta_accuracy\": 0.6578389830508474,\n",
      "                    \"accuracy_delta\": -0.009533898305084776\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"distribution\": \"ImplicitHate\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6452513966480447,\n",
      "                    \"tta_accuracy\": 0.6573556797020484,\n",
      "                    \"accuracy_delta\": 0.012104283054003795\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"distribution\": \"AdvCivil\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.30461165048543687,\n",
      "                    \"tta_accuracy\": 0.5072815533980582,\n",
      "                    \"accuracy_delta\": 0.20266990291262138\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.06841342922051347,\n",
      "                \"mean_baseline_accuracy\": 0.5390786428298046\n",
      "            }\n",
      "        },\n",
      "        \"T5\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9057233867653103,\n",
      "                    \"tta_accuracy\": 0.9092375667899713,\n",
      "                    \"accuracy_delta\": 0.0035141800246609733\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9057233867653103,\n",
      "                    \"tta_accuracy\": 0.9132963419646527,\n",
      "                    \"accuracy_delta\": 0.007572955199342424\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9057233867653103,\n",
      "                    \"tta_accuracy\": 0.9064940402794903,\n",
      "                    \"accuracy_delta\": 0.0007706535141800419\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9057233867653103,\n",
      "                    \"tta_accuracy\": 0.9132244143033292,\n",
      "                    \"accuracy_delta\": 0.007501027538018956\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9057233867653103,\n",
      "                    \"tta_accuracy\": 0.918711467324291,\n",
      "                    \"accuracy_delta\": 0.012988080558980708\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            }\n",
      "        },\n",
      "        \"Falcon\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.17002671598849156,\n",
      "                    \"tta_accuracy\": 0.16936909165639127,\n",
      "                    \"accuracy_delta\": -0.0006576243321002873\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.17002671598849156,\n",
      "                    \"tta_accuracy\": 0.19985614467735308,\n",
      "                    \"accuracy_delta\": 0.029829428688861515\n",
      "                },\n",
      "                \"mean_accuracy_delta\": NaN,\n",
      "                \"mean_baseline_accuracy\": NaN\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"AgNewsTweets\": {\n",
      "        \"BERT\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9482894736842106,\n",
      "                    \"tta_accuracy\": 0.9489473684210527,\n",
      "                    \"accuracy_delta\": 0.0006578947368420796\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8856578947368421,\n",
      "                    \"tta_accuracy\": 0.888421052631579,\n",
      "                    \"accuracy_delta\": 0.0027631578947369118\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0027631578947369118,\n",
      "                \"mean_baseline_accuracy\": 0.8856578947368421\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9482894736842106,\n",
      "                    \"tta_accuracy\": 0.9485526315789473,\n",
      "                    \"accuracy_delta\": 0.000263157894736743\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8856578947368421,\n",
      "                    \"tta_accuracy\": 0.8885526315789474,\n",
      "                    \"accuracy_delta\": 0.0028947368421052833\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0028947368421052833,\n",
      "                \"mean_baseline_accuracy\": 0.8856578947368421\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9482894736842106,\n",
      "                    \"tta_accuracy\": 0.9392105263157895,\n",
      "                    \"accuracy_delta\": -0.009078947368421075\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8856578947368421,\n",
      "                    \"tta_accuracy\": 0.8881578947368421,\n",
      "                    \"accuracy_delta\": 0.0025000000000000577\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0025000000000000577,\n",
      "                \"mean_baseline_accuracy\": 0.8856578947368421\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9482894736842106,\n",
      "                    \"tta_accuracy\": 0.9372368421052631,\n",
      "                    \"accuracy_delta\": -0.011052631578947425\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8856578947368421,\n",
      "                    \"tta_accuracy\": 0.8910526315789473,\n",
      "                    \"accuracy_delta\": 0.00539473684210523\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.00539473684210523,\n",
      "                \"mean_baseline_accuracy\": 0.8856578947368421\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9482894736842106,\n",
      "                    \"tta_accuracy\": 0.9352631578947368,\n",
      "                    \"accuracy_delta\": -0.013026315789473775\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"BERT\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8856578947368421,\n",
      "                    \"tta_accuracy\": 0.8975,\n",
      "                    \"accuracy_delta\": 0.011842105263157876\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.011842105263157876,\n",
      "                \"mean_baseline_accuracy\": 0.8856578947368421\n",
      "            }\n",
      "        },\n",
      "        \"T5\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.9486842105263158,\n",
      "                    \"tta_accuracy\": 0.9222368421052631,\n",
      "                    \"accuracy_delta\": -0.026447368421052664\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8901315789473684,\n",
      "                    \"tta_accuracy\": 0.895921052631579,\n",
      "                    \"accuracy_delta\": 0.0057894736842105665\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0057894736842105665,\n",
      "                \"mean_baseline_accuracy\": 0.8901315789473684\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.9486842105263158,\n",
      "                    \"tta_accuracy\": 0.9190789473684211,\n",
      "                    \"accuracy_delta\": -0.02960526315789469\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8901315789473684,\n",
      "                    \"tta_accuracy\": 0.8913157894736842,\n",
      "                    \"accuracy_delta\": 0.0011842105263157876\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.0011842105263157876,\n",
      "                \"mean_baseline_accuracy\": 0.8901315789473684\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.9486842105263158,\n",
      "                    \"tta_accuracy\": 0.9269736842105263,\n",
      "                    \"accuracy_delta\": -0.021710526315789513\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8901315789473684,\n",
      "                    \"tta_accuracy\": 0.8903947368421052,\n",
      "                    \"accuracy_delta\": 0.000263157894736854\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.000263157894736854,\n",
      "                \"mean_baseline_accuracy\": 0.8901315789473684\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.9486842105263158,\n",
      "                    \"tta_accuracy\": 0.9205263157894736,\n",
      "                    \"accuracy_delta\": -0.02815789473684216\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8901315789473684,\n",
      "                    \"tta_accuracy\": 0.9017105263157895,\n",
      "                    \"accuracy_delta\": 0.011578947368421133\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.011578947368421133,\n",
      "                \"mean_baseline_accuracy\": 0.8901315789473684\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.9486842105263158,\n",
      "                    \"tta_accuracy\": 0.9198684210526316,\n",
      "                    \"accuracy_delta\": -0.02881578947368424\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"T5\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8901315789473684,\n",
      "                    \"tta_accuracy\": 0.9052631578947369,\n",
      "                    \"accuracy_delta\": 0.015131578947368496\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.015131578947368496,\n",
      "                \"mean_baseline_accuracy\": 0.8901315789473684\n",
      "            }\n",
      "        },\n",
      "        \"Falcon\": {\n",
      "            \"Insert\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.3030263157894737,\n",
      "                    \"tta_accuracy\": 0.26842105263157895,\n",
      "                    \"accuracy_delta\": -0.03460526315789475\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.26,\n",
      "                    \"tta_accuracy\": 0.24960526315789475,\n",
      "                    \"accuracy_delta\": -0.010394736842105262\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.010394736842105262,\n",
      "                \"mean_baseline_accuracy\": 0.26\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.3030263157894737,\n",
      "                    \"tta_accuracy\": 0.26342105263157894,\n",
      "                    \"accuracy_delta\": -0.039605263157894754\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.26,\n",
      "                    \"tta_accuracy\": 0.2488157894736842,\n",
      "                    \"accuracy_delta\": -0.011184210526315796\n",
      "                },\n",
      "                \"mean_accuracy_delta\": -0.011184210526315796,\n",
      "                \"mean_baseline_accuracy\": 0.26\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.3030263157894737,\n",
      "                    \"tta_accuracy\": 0.3011842105263158,\n",
      "                    \"accuracy_delta\": -0.0018421052631579227\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.26,\n",
      "                    \"tta_accuracy\": 0.26355263157894737,\n",
      "                    \"accuracy_delta\": 0.003552631578947363\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.003552631578947363,\n",
      "                \"mean_baseline_accuracy\": 0.26\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.3030263157894737,\n",
      "                    \"tta_accuracy\": 0.28776315789473683,\n",
      "                    \"accuracy_delta\": -0.015263157894736867\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.26,\n",
      "                    \"tta_accuracy\": 0.2798684210526316,\n",
      "                    \"accuracy_delta\": 0.01986842105263159\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.01986842105263159,\n",
      "                \"mean_baseline_accuracy\": 0.26\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"ID\": {\n",
      "                    \"distribution\": \"ID\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.3030263157894737,\n",
      "                    \"tta_accuracy\": 0.29473684210526313,\n",
      "                    \"accuracy_delta\": -0.008289473684210569\n",
      "                },\n",
      "                \"Tweets\": {\n",
      "                    \"distribution\": \"Tweets\",\n",
      "                    \"model\": \"Falcon\",\n",
      "                    \"tta_method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.26,\n",
      "                    \"tta_accuracy\": 0.28157894736842104,\n",
      "                    \"accuracy_delta\": 0.02157894736842103\n",
      "                },\n",
      "                \"mean_accuracy_delta\": 0.02157894736842103,\n",
      "                \"mean_baseline_accuracy\": 0.26\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_results_bert_splits = [split for split in inference_logs.keys() if \"Ablate\" not in split]\n",
    "datasets = [\"BOSS_Sentiment\", \"BOSS_Toxicity\", \"AgNewsTweets\"]\n",
    "split_data = {}\n",
    "\n",
    "for task_name in datasets:\n",
    "    if task_name not in split_data:\n",
    "        split_data[task_name] = {}\n",
    "\n",
    "    for split in tqdm(main_results_bert_splits):\n",
    "        if task_name in split:\n",
    "            distribution = split.split(\"_\")[-3]\n",
    "            model = split.split(\"_\")[-2]\n",
    "            tta_method = split.split(\"_\")[-1]\n",
    "            baseline_accuracy = classification_report(inference_logs[split][\"label\"], inference_logs[split][\"original_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "            tta_accuracy = classification_report(inference_logs[split][\"label\"], inference_logs[split][\"tta_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "            accuracy_delta = tta_accuracy - baseline_accuracy\n",
    "\n",
    "            if model not in split_data[task_name]:\n",
    "                split_data[task_name][model] = {}\n",
    "\n",
    "            if tta_method not in split_data[task_name][model]:\n",
    "                split_data[task_name][model][tta_method] = {}\n",
    "\n",
    "            split_data[task_name][model][tta_method][distribution] = {\n",
    "                \"distribution\": distribution,\n",
    "                \"model\": model,\n",
    "                \"tta_method\": tta_method,\n",
    "                \"baseline_accuracy\": baseline_accuracy,\n",
    "                \"tta_accuracy\": tta_accuracy,\n",
    "                \"accuracy_delta\": accuracy_delta\n",
    "            }\n",
    "\n",
    "    # get the Accuracy Gain for each method excluding ID\n",
    "    for model_name in split_data[task_name]:\n",
    "        for tta_method in split_data[task_name][model_name]:\n",
    "            accuracy_deltas = []\n",
    "            baseline_accuracies = []\n",
    "            for distribution in split_data[task_name][model_name][tta_method]:\n",
    "                if distribution == \"ID\":\n",
    "                    continue\n",
    "\n",
    "                current_tta_result = split_data[task_name][model_name][tta_method][distribution]\n",
    "                accuracy_deltas.append(current_tta_result[\"accuracy_delta\"])\n",
    "                baseline_accuracies.append(current_tta_result[\"baseline_accuracy\"])\n",
    "\n",
    "            split_data[task_name][model_name][tta_method][\"mean_accuracy_delta\"] = np.mean(accuracy_deltas)\n",
    "            split_data[task_name][model_name][tta_method][\"mean_baseline_accuracy\"] = np.mean(baseline_accuracies)\n",
    "\n",
    "print(json.dumps(split_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 57456.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'BERT'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AgNewsTweets</th>\n",
       "      <th colspan=\"5\" halign=\"left\">BOSS_Sentiment</th>\n",
       "      <th colspan=\"5\" halign=\"left\">BOSS_Toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tta_method</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_accuracy_delta</th>\n",
       "      <td>-1.302632</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>-1.105263</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.907895</td>\n",
       "      <td>0.472959</td>\n",
       "      <td>0.102817</td>\n",
       "      <td>0.156796</td>\n",
       "      <td>-0.418980</td>\n",
       "      <td>-1.328912</td>\n",
       "      <td>2.984998</td>\n",
       "      <td>0.789149</td>\n",
       "      <td>2.119811</td>\n",
       "      <td>1.437526</td>\n",
       "      <td>1.178586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_accuracy_delta</th>\n",
       "      <td>1.184211</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.860502</td>\n",
       "      <td>-0.127494</td>\n",
       "      <td>2.604881</td>\n",
       "      <td>-0.269537</td>\n",
       "      <td>0.548153</td>\n",
       "      <td>6.841343</td>\n",
       "      <td>-0.807051</td>\n",
       "      <td>10.456264</td>\n",
       "      <td>-0.538489</td>\n",
       "      <td>7.739362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_baseline_accuracy</th>\n",
       "      <td>88.565789</td>\n",
       "      <td>88.565789</td>\n",
       "      <td>88.565789</td>\n",
       "      <td>88.565789</td>\n",
       "      <td>88.565789</td>\n",
       "      <td>52.050120</td>\n",
       "      <td>52.050120</td>\n",
       "      <td>52.050120</td>\n",
       "      <td>52.050120</td>\n",
       "      <td>52.050120</td>\n",
       "      <td>53.907864</td>\n",
       "      <td>53.907864</td>\n",
       "      <td>53.907864</td>\n",
       "      <td>53.907864</td>\n",
       "      <td>53.907864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                    AgNewsTweets                                   \\\n",
       "tta_method                          ICR     Insert Paraphrase Substitute   \n",
       "id_accuracy_delta             -1.302632   0.065789  -1.105263   0.026316   \n",
       "ood_mean_accuracy_delta        1.184211   0.276316   0.539474   0.289474   \n",
       "ood_mean_baseline_accuracy    88.565789  88.565789  88.565789  88.565789   \n",
       "\n",
       "dataset                               BOSS_Sentiment                        \\\n",
       "tta_method                  Translate            ICR     Insert Paraphrase   \n",
       "id_accuracy_delta           -0.907895       0.472959   0.102817   0.156796   \n",
       "ood_mean_accuracy_delta      0.250000       4.860502  -0.127494   2.604881   \n",
       "ood_mean_baseline_accuracy  88.565789      52.050120  52.050120  52.050120   \n",
       "\n",
       "dataset                                          BOSS_Toxicity             \\\n",
       "tta_method                 Substitute  Translate           ICR     Insert   \n",
       "id_accuracy_delta           -0.418980  -1.328912      2.984998   0.789149   \n",
       "ood_mean_accuracy_delta     -0.269537   0.548153      6.841343  -0.807051   \n",
       "ood_mean_baseline_accuracy  52.050120  52.050120     53.907864  53.907864   \n",
       "\n",
       "dataset                                                      \n",
       "tta_method                 Paraphrase Substitute  Translate  \n",
       "id_accuracy_delta            2.119811   1.437526   1.178586  \n",
       "ood_mean_accuracy_delta     10.456264  -0.538489   7.739362  \n",
       "ood_mean_baseline_accuracy  53.907864  53.907864  53.907864  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'T5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AgNewsTweets</th>\n",
       "      <th colspan=\"5\" halign=\"left\">BOSS_Sentiment</th>\n",
       "      <th colspan=\"5\" halign=\"left\">BOSS_Toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tta_method</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_accuracy_delta</th>\n",
       "      <td>-2.881579</td>\n",
       "      <td>-2.644737</td>\n",
       "      <td>-2.815789</td>\n",
       "      <td>-2.960526</td>\n",
       "      <td>-2.171053</td>\n",
       "      <td>0.665741</td>\n",
       "      <td>-1.711906</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>-4.336315</td>\n",
       "      <td>-2.894304</td>\n",
       "      <td>1.298808</td>\n",
       "      <td>0.351418</td>\n",
       "      <td>0.750103</td>\n",
       "      <td>0.757296</td>\n",
       "      <td>0.077065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_accuracy_delta</th>\n",
       "      <td>1.513158</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>1.843384</td>\n",
       "      <td>-1.976507</td>\n",
       "      <td>1.176539</td>\n",
       "      <td>-2.917087</td>\n",
       "      <td>-1.129824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_baseline_accuracy</th>\n",
       "      <td>89.013158</td>\n",
       "      <td>89.013158</td>\n",
       "      <td>89.013158</td>\n",
       "      <td>89.013158</td>\n",
       "      <td>89.013158</td>\n",
       "      <td>57.988354</td>\n",
       "      <td>57.988354</td>\n",
       "      <td>57.988354</td>\n",
       "      <td>57.988354</td>\n",
       "      <td>57.988354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                    AgNewsTweets                                   \\\n",
       "tta_method                          ICR     Insert Paraphrase Substitute   \n",
       "id_accuracy_delta             -2.881579  -2.644737  -2.815789  -2.960526   \n",
       "ood_mean_accuracy_delta        1.513158   0.578947   1.157895   0.118421   \n",
       "ood_mean_baseline_accuracy    89.013158  89.013158  89.013158  89.013158   \n",
       "\n",
       "dataset                               BOSS_Sentiment                        \\\n",
       "tta_method                  Translate            ICR     Insert Paraphrase   \n",
       "id_accuracy_delta           -2.171053       0.665741  -1.711906  -0.215916   \n",
       "ood_mean_accuracy_delta      0.026316       1.843384  -1.976507   1.176539   \n",
       "ood_mean_baseline_accuracy  89.013158      57.988354  57.988354  57.988354   \n",
       "\n",
       "dataset                                          BOSS_Toxicity            \\\n",
       "tta_method                 Substitute  Translate           ICR    Insert   \n",
       "id_accuracy_delta           -4.336315  -2.894304      1.298808  0.351418   \n",
       "ood_mean_accuracy_delta     -2.917087  -1.129824           NaN       NaN   \n",
       "ood_mean_baseline_accuracy  57.988354  57.988354           NaN       NaN   \n",
       "\n",
       "dataset                                                     \n",
       "tta_method                 Paraphrase Substitute Translate  \n",
       "id_accuracy_delta            0.750103   0.757296  0.077065  \n",
       "ood_mean_accuracy_delta           NaN        NaN       NaN  \n",
       "ood_mean_baseline_accuracy        NaN        NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Falcon'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AgNewsTweets</th>\n",
       "      <th colspan=\"5\" halign=\"left\">BOSS_Sentiment</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BOSS_Toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tta_method</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>ICR</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Paraphrase</th>\n",
       "      <th>Substitute</th>\n",
       "      <th>Translate</th>\n",
       "      <th>Insert</th>\n",
       "      <th>Substitute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_accuracy_delta</th>\n",
       "      <td>-0.828947</td>\n",
       "      <td>-3.460526</td>\n",
       "      <td>-1.526316</td>\n",
       "      <td>-3.960526</td>\n",
       "      <td>-0.184211</td>\n",
       "      <td>-0.149085</td>\n",
       "      <td>-1.082151</td>\n",
       "      <td>-0.149085</td>\n",
       "      <td>-3.919905</td>\n",
       "      <td>-3.359552</td>\n",
       "      <td>-0.065762</td>\n",
       "      <td>2.982943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_accuracy_delta</th>\n",
       "      <td>2.157895</td>\n",
       "      <td>-1.039474</td>\n",
       "      <td>1.986842</td>\n",
       "      <td>-1.118421</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>-2.967050</td>\n",
       "      <td>-0.816995</td>\n",
       "      <td>-1.248467</td>\n",
       "      <td>-2.898438</td>\n",
       "      <td>-2.186213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ood_mean_baseline_accuracy</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>47.166769</td>\n",
       "      <td>47.166769</td>\n",
       "      <td>47.166769</td>\n",
       "      <td>47.166769</td>\n",
       "      <td>47.166769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                    AgNewsTweets                                   \\\n",
       "tta_method                          ICR     Insert Paraphrase Substitute   \n",
       "id_accuracy_delta             -0.828947  -3.460526  -1.526316  -3.960526   \n",
       "ood_mean_accuracy_delta        2.157895  -1.039474   1.986842  -1.118421   \n",
       "ood_mean_baseline_accuracy    26.000000  26.000000  26.000000  26.000000   \n",
       "\n",
       "dataset                               BOSS_Sentiment                        \\\n",
       "tta_method                  Translate            ICR     Insert Paraphrase   \n",
       "id_accuracy_delta           -0.184211      -0.149085  -1.082151  -0.149085   \n",
       "ood_mean_accuracy_delta      0.355263      -2.967050  -0.816995  -1.248467   \n",
       "ood_mean_baseline_accuracy  26.000000      47.166769  47.166769  47.166769   \n",
       "\n",
       "dataset                                          BOSS_Toxicity             \n",
       "tta_method                 Substitute  Translate        Insert Substitute  \n",
       "id_accuracy_delta           -3.919905  -3.359552     -0.065762   2.982943  \n",
       "ood_mean_accuracy_delta     -2.898438  -2.186213           NaN        NaN  \n",
       "ood_mean_baseline_accuracy  47.166769  47.166769           NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataframe where there is a column for dataset, model, id_accuracy_delta, and mean_accuracy_delta\n",
    "records = []\n",
    "\n",
    "for task_name in tqdm(split_data):\n",
    "    for model_name in split_data[task_name]:\n",
    "        for tta_method in split_data[task_name][model_name]:\n",
    "            current_tta_result = split_data[task_name][model_name][tta_method]\n",
    "            records.append({\n",
    "                \"dataset\": task_name,\n",
    "                \"model\": model_name,\n",
    "                \"tta_method\": tta_method,\n",
    "                \"id_accuracy_delta\": current_tta_result[\"ID\"][\"accuracy_delta\"] * 100 if \"ID\" in current_tta_result else None,\n",
    "                \"ood_mean_accuracy_delta\": current_tta_result[\"mean_accuracy_delta\"] * 100,\n",
    "                \"ood_mean_baseline_accuracy\": current_tta_result[\"mean_baseline_accuracy\"] * 100,\n",
    "            })\n",
    "\n",
    "\n",
    "main_results_frame = pd.DataFrame(records)\n",
    "for model in split_data[task_name]:\n",
    "    display(model)\n",
    "    display(main_results_frame[main_results_frame[\"model\"] == model].drop(columns=\"model\").groupby([\"dataset\", \"tta_method\"]).mean().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Across Dataset Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BOSS_Toxicity: 100%|██████████| 175/175 [00:01<00:00, 126.39it/s]\n",
      "BOSS_Sentiment: 100%|██████████| 175/175 [00:01<00:00, 133.76it/s]\n",
      "AgNewsTweets: 100%|██████████| 175/175 [00:00<00:00, 436.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"BOSS_Toxicity\": {\n",
      "        \"3000\": {\n",
      "            \"Insert\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6207627118644068,\n",
      "                    \"tta_accuracy\": 0.6101694915254238,\n",
      "                    \"baseline_delta\": -0.010593220338983023\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6128491620111732,\n",
      "                    \"tta_accuracy\": 0.6135009310986964,\n",
      "                    \"baseline_delta\": 0.0006517690875231796\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.36650485436893204,\n",
      "                    \"tta_accuracy\": 0.37014563106796117,\n",
      "                    \"baseline_delta\": 0.0036407766990291246\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6207627118644068,\n",
      "                    \"tta_accuracy\": 0.6122881355932204,\n",
      "                    \"baseline_delta\": -0.008474576271186418\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6128491620111732,\n",
      "                    \"tta_accuracy\": 0.6189478584729982,\n",
      "                    \"baseline_delta\": 0.006098696461824926\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.36650485436893204,\n",
      "                    \"tta_accuracy\": 0.3628640776699029,\n",
      "                    \"baseline_delta\": -0.0036407766990291246\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6207627118644068,\n",
      "                    \"tta_accuracy\": 0.6122881355932204,\n",
      "                    \"baseline_delta\": -0.008474576271186418\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6128491620111732,\n",
      "                    \"tta_accuracy\": 0.612243947858473,\n",
      "                    \"baseline_delta\": -0.0006052141527002064\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.36650485436893204,\n",
      "                    \"tta_accuracy\": 0.5194174757281553,\n",
      "                    \"baseline_delta\": 0.1529126213592233\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6207627118644068,\n",
      "                    \"tta_accuracy\": 0.6154661016949152,\n",
      "                    \"baseline_delta\": -0.005296610169491567\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6128491620111732,\n",
      "                    \"tta_accuracy\": 0.6124301675977654,\n",
      "                    \"baseline_delta\": -0.00041899441340786936\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.36650485436893204,\n",
      "                    \"tta_accuracy\": 0.5473300970873787,\n",
      "                    \"baseline_delta\": 0.18082524271844663\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6207627118644068,\n",
      "                    \"tta_accuracy\": 0.6122881355932204,\n",
      "                    \"baseline_delta\": -0.008474576271186418\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6128491620111732,\n",
      "                    \"tta_accuracy\": 0.6142923649906891,\n",
      "                    \"baseline_delta\": 0.001443202979515834\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.36650485436893204,\n",
      "                    \"tta_accuracy\": 0.4393203883495146,\n",
      "                    \"baseline_delta\": 0.07281553398058255\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"6000\": {\n",
      "            \"Insert\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.611228813559322,\n",
      "                    \"tta_accuracy\": 0.614406779661017,\n",
      "                    \"baseline_delta\": 0.0031779661016949623\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6365921787709498,\n",
      "                    \"tta_accuracy\": 0.6410148975791434,\n",
      "                    \"baseline_delta\": 0.004422718808193671\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4077669902912621,\n",
      "                    \"tta_accuracy\": 0.39684466019417475,\n",
      "                    \"baseline_delta\": -0.010922330097087374\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.611228813559322,\n",
      "                    \"tta_accuracy\": 0.6122881355932204,\n",
      "                    \"baseline_delta\": 0.0010593220338983578\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6365921787709498,\n",
      "                    \"tta_accuracy\": 0.6478584729981378,\n",
      "                    \"baseline_delta\": 0.011266294227188056\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4077669902912621,\n",
      "                    \"tta_accuracy\": 0.39805825242718446,\n",
      "                    \"baseline_delta\": -0.009708737864077666\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.611228813559322,\n",
      "                    \"tta_accuracy\": 0.6101694915254238,\n",
      "                    \"baseline_delta\": -0.0010593220338982468\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6365921787709498,\n",
      "                    \"tta_accuracy\": 0.6369180633147113,\n",
      "                    \"baseline_delta\": 0.0003258845437615898\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4077669902912621,\n",
      "                    \"tta_accuracy\": 0.5849514563106796,\n",
      "                    \"baseline_delta\": 0.17718446601941745\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.611228813559322,\n",
      "                    \"tta_accuracy\": 0.597457627118644,\n",
      "                    \"baseline_delta\": -0.013771186440677985\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6365921787709498,\n",
      "                    \"tta_accuracy\": 0.6372905027932961,\n",
      "                    \"baseline_delta\": 0.0006983240223463749\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4077669902912621,\n",
      "                    \"tta_accuracy\": 0.6189320388349514,\n",
      "                    \"baseline_delta\": 0.21116504854368928\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.611228813559322,\n",
      "                    \"tta_accuracy\": 0.6016949152542372,\n",
      "                    \"baseline_delta\": -0.009533898305084776\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6365921787709498,\n",
      "                    \"tta_accuracy\": 0.6432495344506518,\n",
      "                    \"baseline_delta\": 0.006657355679702048\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4077669902912621,\n",
      "                    \"tta_accuracy\": 0.5303398058252428,\n",
      "                    \"baseline_delta\": 0.12257281553398064\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"12000\": {\n",
      "            \"Insert\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.621822033898305,\n",
      "                    \"tta_accuracy\": 0.6197033898305084,\n",
      "                    \"baseline_delta\": -0.0021186440677966045\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6067970204841713,\n",
      "                    \"tta_accuracy\": 0.6111266294227188,\n",
      "                    \"baseline_delta\": 0.004329608938547502\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.3179611650485437,\n",
      "                    \"tta_accuracy\": 0.29975728155339804,\n",
      "                    \"baseline_delta\": -0.01820388349514568\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.621822033898305,\n",
      "                    \"tta_accuracy\": 0.625,\n",
      "                    \"baseline_delta\": 0.0031779661016949623\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6067970204841713,\n",
      "                    \"tta_accuracy\": 0.6286312849162011,\n",
      "                    \"baseline_delta\": 0.02183426443202985\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.3179611650485437,\n",
      "                    \"tta_accuracy\": 0.2815533980582524,\n",
      "                    \"baseline_delta\": -0.0364077669902913\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.621822033898305,\n",
      "                    \"tta_accuracy\": 0.625,\n",
      "                    \"baseline_delta\": 0.0031779661016949623\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6067970204841713,\n",
      "                    \"tta_accuracy\": 0.6092644320297952,\n",
      "                    \"baseline_delta\": 0.00246741154562391\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.3179611650485437,\n",
      "                    \"tta_accuracy\": 0.49393203883495146,\n",
      "                    \"baseline_delta\": 0.17597087378640774\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.621822033898305,\n",
      "                    \"tta_accuracy\": 0.6165254237288136,\n",
      "                    \"baseline_delta\": -0.005296610169491456\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6067970204841713,\n",
      "                    \"tta_accuracy\": 0.6131750465549348,\n",
      "                    \"baseline_delta\": 0.006378026070763543\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.3179611650485437,\n",
      "                    \"tta_accuracy\": 0.49393203883495146,\n",
      "                    \"baseline_delta\": 0.17597087378640774\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.621822033898305,\n",
      "                    \"tta_accuracy\": 0.6133474576271186,\n",
      "                    \"baseline_delta\": -0.008474576271186418\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6067970204841713,\n",
      "                    \"tta_accuracy\": 0.6266759776536313,\n",
      "                    \"baseline_delta\": 0.019878957169459976\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.3179611650485437,\n",
      "                    \"tta_accuracy\": 0.39805825242718446,\n",
      "                    \"baseline_delta\": 0.08009708737864074\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"24000\": {\n",
      "            \"Insert\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6451271186440678,\n",
      "                    \"tta_accuracy\": 0.6408898305084746,\n",
      "                    \"baseline_delta\": -0.004237288135593209\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6287709497206704,\n",
      "                    \"tta_accuracy\": 0.6349627560521415,\n",
      "                    \"baseline_delta\": 0.006191806331471095\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.2487864077669903,\n",
      "                    \"tta_accuracy\": 0.22815533980582525,\n",
      "                    \"baseline_delta\": -0.02063106796116504\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6451271186440678,\n",
      "                    \"tta_accuracy\": 0.6440677966101694,\n",
      "                    \"baseline_delta\": -0.0010593220338983578\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6287709497206704,\n",
      "                    \"tta_accuracy\": 0.6452048417132216,\n",
      "                    \"baseline_delta\": 0.016433891992551186\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.2487864077669903,\n",
      "                    \"tta_accuracy\": 0.2342233009708738,\n",
      "                    \"baseline_delta\": -0.014563106796116498\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6451271186440678,\n",
      "                    \"tta_accuracy\": 0.635593220338983,\n",
      "                    \"baseline_delta\": -0.009533898305084776\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6287709497206704,\n",
      "                    \"tta_accuracy\": 0.6278398510242086,\n",
      "                    \"baseline_delta\": -0.0009310986964617962\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.2487864077669903,\n",
      "                    \"tta_accuracy\": 0.4186893203883495,\n",
      "                    \"baseline_delta\": 0.1699029126213592\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6451271186440678,\n",
      "                    \"tta_accuracy\": 0.6504237288135594,\n",
      "                    \"baseline_delta\": 0.005296610169491567\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6287709497206704,\n",
      "                    \"tta_accuracy\": 0.6385009310986964,\n",
      "                    \"baseline_delta\": 0.009729981378026054\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.2487864077669903,\n",
      "                    \"tta_accuracy\": 0.44660194174757284,\n",
      "                    \"baseline_delta\": 0.19781553398058255\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6451271186440678,\n",
      "                    \"tta_accuracy\": 0.6345338983050848,\n",
      "                    \"baseline_delta\": -0.010593220338983023\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6287709497206704,\n",
      "                    \"tta_accuracy\": 0.6458566108007449,\n",
      "                    \"baseline_delta\": 0.017085661080074477\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.2487864077669903,\n",
      "                    \"tta_accuracy\": 0.36529126213592233,\n",
      "                    \"baseline_delta\": 0.11650485436893204\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"48000\": {\n",
      "            \"Insert\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.652542372881356,\n",
      "                    \"tta_accuracy\": 0.6504237288135594,\n",
      "                    \"baseline_delta\": -0.0021186440677966045\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6102886405959032,\n",
      "                    \"tta_accuracy\": 0.6124301675977654,\n",
      "                    \"baseline_delta\": 0.002141527001862209\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.33616504854368934,\n",
      "                    \"tta_accuracy\": 0.33495145631067963,\n",
      "                    \"baseline_delta\": -0.0012135922330097082\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.652542372881356,\n",
      "                    \"tta_accuracy\": 0.635593220338983,\n",
      "                    \"baseline_delta\": -0.016949152542372947\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6102886405959032,\n",
      "                    \"tta_accuracy\": 0.6337057728119181,\n",
      "                    \"baseline_delta\": 0.023417132216014935\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.33616504854368934,\n",
      "                    \"tta_accuracy\": 0.3337378640776699,\n",
      "                    \"baseline_delta\": -0.0024271844660194164\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.652542372881356,\n",
      "                    \"tta_accuracy\": 0.6451271186440678,\n",
      "                    \"baseline_delta\": -0.007415254237288171\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6102886405959032,\n",
      "                    \"tta_accuracy\": 0.6105214152700186,\n",
      "                    \"baseline_delta\": 0.0002327746741154213\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.33616504854368934,\n",
      "                    \"tta_accuracy\": 0.558252427184466,\n",
      "                    \"baseline_delta\": 0.22208737864077666\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.652542372881356,\n",
      "                    \"tta_accuracy\": 0.6451271186440678,\n",
      "                    \"baseline_delta\": -0.007415254237288171\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6102886405959032,\n",
      "                    \"tta_accuracy\": 0.617877094972067,\n",
      "                    \"baseline_delta\": 0.0075884543761638446\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.33616504854368934,\n",
      "                    \"tta_accuracy\": 0.6031553398058253,\n",
      "                    \"baseline_delta\": 0.2669902912621359\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Toxigen\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.652542372881356,\n",
      "                    \"tta_accuracy\": 0.6440677966101694,\n",
      "                    \"baseline_delta\": -0.008474576271186529\n",
      "                },\n",
      "                \"ImplicitHate\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6102886405959032,\n",
      "                    \"tta_accuracy\": 0.6315176908752328,\n",
      "                    \"baseline_delta\": 0.021229050279329642\n",
      "                },\n",
      "                \"AdvCivil\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.33616504854368934,\n",
      "                    \"tta_accuracy\": 0.4526699029126214,\n",
      "                    \"baseline_delta\": 0.11650485436893204\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"BOSS_Sentiment\": {\n",
      "        \"1500\": {\n",
      "            \"Insert\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6828358208955224,\n",
      "                    \"tta_accuracy\": 0.6865671641791045,\n",
      "                    \"baseline_delta\": 0.003731343283582045\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.48322342901474014,\n",
      "                    \"tta_accuracy\": 0.4807505818463926,\n",
      "                    \"baseline_delta\": -0.0024728471683475584\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4358796296296296,\n",
      "                    \"tta_accuracy\": 0.4236111111111111,\n",
      "                    \"baseline_delta\": -0.012268518518518512\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6828358208955224,\n",
      "                    \"tta_accuracy\": 0.6725746268656716,\n",
      "                    \"baseline_delta\": -0.010261194029850818\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.48322342901474014,\n",
      "                    \"tta_accuracy\": 0.47483514352211015,\n",
      "                    \"baseline_delta\": -0.008388285492629988\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4358796296296296,\n",
      "                    \"tta_accuracy\": 0.43425925925925923,\n",
      "                    \"baseline_delta\": -0.0016203703703703831\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6828358208955224,\n",
      "                    \"tta_accuracy\": 0.6819029850746269,\n",
      "                    \"baseline_delta\": -0.000932835820895539\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.48322342901474014,\n",
      "                    \"tta_accuracy\": 0.4911753297129558,\n",
      "                    \"baseline_delta\": 0.007951900698215664\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4358796296296296,\n",
      "                    \"tta_accuracy\": 0.43495370370370373,\n",
      "                    \"baseline_delta\": -0.0009259259259258856\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6828358208955224,\n",
      "                    \"tta_accuracy\": 0.7024253731343284,\n",
      "                    \"baseline_delta\": 0.019589552238805985\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.48322342901474014,\n",
      "                    \"tta_accuracy\": 0.5197342901474011,\n",
      "                    \"baseline_delta\": 0.036510861132661\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4358796296296296,\n",
      "                    \"tta_accuracy\": 0.45069444444444445,\n",
      "                    \"baseline_delta\": 0.014814814814814836\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6828358208955224,\n",
      "                    \"tta_accuracy\": 0.7136194029850746,\n",
      "                    \"baseline_delta\": 0.03078358208955223\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.48322342901474014,\n",
      "                    \"tta_accuracy\": 0.540244375484872,\n",
      "                    \"baseline_delta\": 0.057020946470131895\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4358796296296296,\n",
      "                    \"tta_accuracy\": 0.46805555555555556,\n",
      "                    \"baseline_delta\": 0.03217592592592594\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"3000\": {\n",
      "            \"Insert\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6791044776119403,\n",
      "                    \"tta_accuracy\": 0.6884328358208955,\n",
      "                    \"baseline_delta\": 0.009328358208955279\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4375,\n",
      "                    \"tta_accuracy\": 0.4308087664856478,\n",
      "                    \"baseline_delta\": -0.006691233514352191\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4361111111111111,\n",
      "                    \"tta_accuracy\": 0.425462962962963,\n",
      "                    \"baseline_delta\": -0.010648148148148129\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6791044776119403,\n",
      "                    \"tta_accuracy\": 0.6763059701492538,\n",
      "                    \"baseline_delta\": -0.002798507462686506\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4375,\n",
      "                    \"tta_accuracy\": 0.43032389449185415,\n",
      "                    \"baseline_delta\": -0.007176105508145847\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4361111111111111,\n",
      "                    \"tta_accuracy\": 0.4321759259259259,\n",
      "                    \"baseline_delta\": -0.003935185185185208\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6791044776119403,\n",
      "                    \"tta_accuracy\": 0.6875,\n",
      "                    \"baseline_delta\": 0.00839552238805974\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4375,\n",
      "                    \"tta_accuracy\": 0.4456943366951125,\n",
      "                    \"baseline_delta\": 0.008194336695112492\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4361111111111111,\n",
      "                    \"tta_accuracy\": 0.4340277777777778,\n",
      "                    \"baseline_delta\": -0.002083333333333326\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6791044776119403,\n",
      "                    \"tta_accuracy\": 0.7154850746268657,\n",
      "                    \"baseline_delta\": 0.036380597014925464\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4375,\n",
      "                    \"tta_accuracy\": 0.48317494181536075,\n",
      "                    \"baseline_delta\": 0.04567494181536075\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4361111111111111,\n",
      "                    \"tta_accuracy\": 0.46273148148148147,\n",
      "                    \"baseline_delta\": 0.02662037037037035\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6791044776119403,\n",
      "                    \"tta_accuracy\": 0.7313432835820896,\n",
      "                    \"baseline_delta\": 0.052238805970149294\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4375,\n",
      "                    \"tta_accuracy\": 0.5004848719937937,\n",
      "                    \"baseline_delta\": 0.06298487199379366\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4361111111111111,\n",
      "                    \"tta_accuracy\": 0.46921296296296294,\n",
      "                    \"baseline_delta\": 0.03310185185185183\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"6000\": {\n",
      "            \"Insert\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6753731343283582,\n",
      "                    \"tta_accuracy\": 0.6688432835820896,\n",
      "                    \"baseline_delta\": -0.006529850746268662\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4659134988363072,\n",
      "                    \"tta_accuracy\": 0.4660589604344453,\n",
      "                    \"baseline_delta\": 0.00014546159813805248\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.40625,\n",
      "                    \"tta_accuracy\": 0.4023148148148148,\n",
      "                    \"baseline_delta\": -0.003935185185185208\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6753731343283582,\n",
      "                    \"tta_accuracy\": 0.6604477611940298,\n",
      "                    \"baseline_delta\": -0.014925373134328401\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4659134988363072,\n",
      "                    \"tta_accuracy\": 0.4655256012412723,\n",
      "                    \"baseline_delta\": -0.00038789759503493615\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.40625,\n",
      "                    \"tta_accuracy\": 0.39675925925925926,\n",
      "                    \"baseline_delta\": -0.009490740740740744\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6753731343283582,\n",
      "                    \"tta_accuracy\": 0.6875,\n",
      "                    \"baseline_delta\": 0.012126865671641784\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4659134988363072,\n",
      "                    \"tta_accuracy\": 0.4662044220325834,\n",
      "                    \"baseline_delta\": 0.0002909231962761605\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.40625,\n",
      "                    \"tta_accuracy\": 0.4081018518518518,\n",
      "                    \"baseline_delta\": 0.0018518518518518268\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6753731343283582,\n",
      "                    \"tta_accuracy\": 0.6958955223880597,\n",
      "                    \"baseline_delta\": 0.020522388059701524\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4659134988363072,\n",
      "                    \"tta_accuracy\": 0.48627812257564,\n",
      "                    \"baseline_delta\": 0.020364623739332788\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.40625,\n",
      "                    \"tta_accuracy\": 0.42453703703703705,\n",
      "                    \"baseline_delta\": 0.018287037037037046\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6753731343283582,\n",
      "                    \"tta_accuracy\": 0.707089552238806,\n",
      "                    \"baseline_delta\": 0.03171641791044777\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4659134988363072,\n",
      "                    \"tta_accuracy\": 0.49495733126454616,\n",
      "                    \"baseline_delta\": 0.029043832428238936\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.40625,\n",
      "                    \"tta_accuracy\": 0.4449074074074074,\n",
      "                    \"baseline_delta\": 0.03865740740740742\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"120000\": {\n",
      "            \"Insert\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6669776119402985,\n",
      "                    \"tta_accuracy\": 0.664179104477612,\n",
      "                    \"baseline_delta\": -0.002798507462686506\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.46450737005430565,\n",
      "                    \"tta_accuracy\": 0.46145267649340577,\n",
      "                    \"baseline_delta\": -0.0030546935608998793\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4532407407407407,\n",
      "                    \"tta_accuracy\": 0.45046296296296295,\n",
      "                    \"baseline_delta\": -0.002777777777777768\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6669776119402985,\n",
      "                    \"tta_accuracy\": 0.667910447761194,\n",
      "                    \"baseline_delta\": 0.000932835820895539\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.46450737005430565,\n",
      "                    \"tta_accuracy\": 0.46314972847168345,\n",
      "                    \"baseline_delta\": -0.0013576415826221933\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4532407407407407,\n",
      "                    \"tta_accuracy\": 0.4513888888888889,\n",
      "                    \"baseline_delta\": -0.0018518518518518268\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6669776119402985,\n",
      "                    \"tta_accuracy\": 0.6604477611940298,\n",
      "                    \"baseline_delta\": -0.006529850746268662\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.46450737005430565,\n",
      "                    \"tta_accuracy\": 0.46615593483320406,\n",
      "                    \"baseline_delta\": 0.0016485647788984092\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4532407407407407,\n",
      "                    \"tta_accuracy\": 0.4583333333333333,\n",
      "                    \"baseline_delta\": 0.005092592592592593\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6669776119402985,\n",
      "                    \"tta_accuracy\": 0.691231343283582,\n",
      "                    \"baseline_delta\": 0.02425373134328357\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.46450737005430565,\n",
      "                    \"tta_accuracy\": 0.4910783553141971,\n",
      "                    \"baseline_delta\": 0.026570985259891433\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4532407407407407,\n",
      "                    \"tta_accuracy\": 0.4689814814814815,\n",
      "                    \"baseline_delta\": 0.015740740740740777\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6669776119402985,\n",
      "                    \"tta_accuracy\": 0.707089552238806,\n",
      "                    \"baseline_delta\": 0.04011194029850751\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.46450737005430565,\n",
      "                    \"tta_accuracy\": 0.5037820015515904,\n",
      "                    \"baseline_delta\": 0.03927463149728472\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4532407407407407,\n",
      "                    \"tta_accuracy\": 0.49074074074074076,\n",
      "                    \"baseline_delta\": 0.03750000000000003\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"24000\": {\n",
      "            \"Insert\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.6884328358208955,\n",
      "                    \"tta_accuracy\": 0.7005597014925373,\n",
      "                    \"baseline_delta\": 0.012126865671641784\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4725077579519007,\n",
      "                    \"tta_accuracy\": 0.47648370830100856,\n",
      "                    \"baseline_delta\": 0.00397595034910786\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.4439814814814815,\n",
      "                    \"tta_accuracy\": 0.4337962962962963,\n",
      "                    \"baseline_delta\": -0.010185185185185186\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.6884328358208955,\n",
      "                    \"tta_accuracy\": 0.6716417910447762,\n",
      "                    \"baseline_delta\": -0.016791044776119368\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4725077579519007,\n",
      "                    \"tta_accuracy\": 0.47420480993017844,\n",
      "                    \"baseline_delta\": 0.0016970519782777416\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.4439814814814815,\n",
      "                    \"tta_accuracy\": 0.43703703703703706,\n",
      "                    \"baseline_delta\": -0.00694444444444442\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.6884328358208955,\n",
      "                    \"tta_accuracy\": 0.7005597014925373,\n",
      "                    \"baseline_delta\": 0.012126865671641784\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4725077579519007,\n",
      "                    \"tta_accuracy\": 0.47755042668735453,\n",
      "                    \"baseline_delta\": 0.005042668735453837\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.4439814814814815,\n",
      "                    \"tta_accuracy\": 0.449537037037037,\n",
      "                    \"baseline_delta\": 0.005555555555555536\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.6884328358208955,\n",
      "                    \"tta_accuracy\": 0.7173507462686567,\n",
      "                    \"baseline_delta\": 0.028917910447761153\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4725077579519007,\n",
      "                    \"tta_accuracy\": 0.4985938712179985,\n",
      "                    \"baseline_delta\": 0.026086113266097777\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.4439814814814815,\n",
      "                    \"tta_accuracy\": 0.46828703703703706,\n",
      "                    \"baseline_delta\": 0.02430555555555558\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"SST5\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.6884328358208955,\n",
      "                    \"tta_accuracy\": 0.730410447761194,\n",
      "                    \"baseline_delta\": 0.041977611940298476\n",
      "                },\n",
      "                \"SemEval\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4725077579519007,\n",
      "                    \"tta_accuracy\": 0.5156128782001551,\n",
      "                    \"baseline_delta\": 0.043105120248254414\n",
      "                },\n",
      "                \"Dynasent\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.4439814814814815,\n",
      "                    \"tta_accuracy\": 0.4875,\n",
      "                    \"baseline_delta\": 0.04351851851851851\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"AgNewsTweets\": {\n",
      "        \"4800\": {\n",
      "            \"Insert\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8864473684210527,\n",
      "                    \"tta_accuracy\": 0.8893421052631579,\n",
      "                    \"baseline_delta\": 0.0028947368421052833\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8864473684210527,\n",
      "                    \"tta_accuracy\": 0.888421052631579,\n",
      "                    \"baseline_delta\": 0.0019736842105263497\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8864473684210527,\n",
      "                    \"tta_accuracy\": 0.8893421052631579,\n",
      "                    \"baseline_delta\": 0.0028947368421052833\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8864473684210527,\n",
      "                    \"tta_accuracy\": 0.8894736842105263,\n",
      "                    \"baseline_delta\": 0.0030263157894736548\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8864473684210527,\n",
      "                    \"tta_accuracy\": 0.8927631578947368,\n",
      "                    \"baseline_delta\": 0.0063157894736841635\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"9600\": {\n",
      "            \"Insert\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8894736842105263,\n",
      "                    \"tta_accuracy\": 0.8881578947368421,\n",
      "                    \"baseline_delta\": -0.001315789473684159\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8894736842105263,\n",
      "                    \"tta_accuracy\": 0.8905263157894737,\n",
      "                    \"baseline_delta\": 0.001052631578947416\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8894736842105263,\n",
      "                    \"tta_accuracy\": 0.8928947368421053,\n",
      "                    \"baseline_delta\": 0.0034210526315789913\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8894736842105263,\n",
      "                    \"tta_accuracy\": 0.8906578947368421,\n",
      "                    \"baseline_delta\": 0.0011842105263157876\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8894736842105263,\n",
      "                    \"tta_accuracy\": 0.8906578947368421,\n",
      "                    \"baseline_delta\": 0.0011842105263157876\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"19200\": {\n",
      "            \"Insert\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8786842105263157,\n",
      "                    \"tta_accuracy\": 0.88,\n",
      "                    \"baseline_delta\": 0.0013157894736842701\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8786842105263157,\n",
      "                    \"tta_accuracy\": 0.8763157894736842,\n",
      "                    \"baseline_delta\": -0.002368421052631575\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8786842105263157,\n",
      "                    \"tta_accuracy\": 0.878421052631579,\n",
      "                    \"baseline_delta\": -0.000263157894736743\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8786842105263157,\n",
      "                    \"tta_accuracy\": 0.8810526315789474,\n",
      "                    \"baseline_delta\": 0.0023684210526316862\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8786842105263157,\n",
      "                    \"tta_accuracy\": 0.8906578947368421,\n",
      "                    \"baseline_delta\": 0.011973684210526359\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"38400\": {\n",
      "            \"Insert\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8840789473684211,\n",
      "                    \"tta_accuracy\": 0.8871052631578947,\n",
      "                    \"baseline_delta\": 0.0030263157894736548\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8840789473684211,\n",
      "                    \"tta_accuracy\": 0.8859210526315789,\n",
      "                    \"baseline_delta\": 0.0018421052631578672\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8840789473684211,\n",
      "                    \"tta_accuracy\": 0.8882894736842105,\n",
      "                    \"baseline_delta\": 0.004210526315789442\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8840789473684211,\n",
      "                    \"tta_accuracy\": 0.8867105263157895,\n",
      "                    \"baseline_delta\": 0.0026315789473684292\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8840789473684211,\n",
      "                    \"tta_accuracy\": 0.8952631578947369,\n",
      "                    \"baseline_delta\": 0.011184210526315796\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"76800\": {\n",
      "            \"Insert\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Insert\",\n",
      "                    \"baseline_accuracy\": 0.8719736842105263,\n",
      "                    \"tta_accuracy\": 0.8717105263157895,\n",
      "                    \"baseline_delta\": -0.000263157894736854\n",
      "                }\n",
      "            },\n",
      "            \"Substitute\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Substitute\",\n",
      "                    \"baseline_accuracy\": 0.8719736842105263,\n",
      "                    \"tta_accuracy\": 0.8690789473684211,\n",
      "                    \"baseline_delta\": -0.0028947368421052833\n",
      "                }\n",
      "            },\n",
      "            \"Translate\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Translate\",\n",
      "                    \"baseline_accuracy\": 0.8719736842105263,\n",
      "                    \"tta_accuracy\": 0.8740789473684211,\n",
      "                    \"baseline_delta\": 0.002105263157894721\n",
      "                }\n",
      "            },\n",
      "            \"Paraphrase\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"Paraphrase\",\n",
      "                    \"baseline_accuracy\": 0.8719736842105263,\n",
      "                    \"tta_accuracy\": 0.8746052631578948,\n",
      "                    \"baseline_delta\": 0.0026315789473684292\n",
      "                }\n",
      "            },\n",
      "            \"ICR\": {\n",
      "                \"Tweets\": {\n",
      "                    \"method\": \"ICR\",\n",
      "                    \"baseline_accuracy\": 0.8719736842105263,\n",
      "                    \"tta_accuracy\": 0.8806578947368421,\n",
      "                    \"baseline_delta\": 0.008684210526315739\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_splits = [split for split in inference_logs.keys() if \"Ablate_Data\" in split]\n",
    "datasets = set([(\"_\".join(split.split(\"_\")[:2]).replace(\"_Ablate\", \"\")) for split in all_splits if \"Ablate_Data\" in split])\n",
    "results = {}\n",
    "# print(datasets)\n",
    "\n",
    "for task_name in datasets:\n",
    "    results[task_name] = {}\n",
    "\n",
    "    for split_name in tqdm(all_splits, desc=task_name):\n",
    "        if task_name in split_name:\n",
    "            data_count = int(split_name.split(\"_\")[-2].replace(\"BERT\", \"\"))\n",
    "            tta_method = split_name.split(\"_\")[-1]\n",
    "            shift_name = split_name.split(\"_\")[-3]\n",
    "            # print(dataset, data_count, tta_method, shift_name)\n",
    "\n",
    "            baseline_accuracy = classification_report(inference_logs[split_name][\"label\"], inference_logs[split_name][\"original_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "            tta_accuracy = classification_report(inference_logs[split_name][\"label\"], inference_logs[split_name][\"tta_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "\n",
    "            if task_name not in results:\n",
    "                results[task_name] = {}\n",
    "            if data_count not in results[task_name]:\n",
    "                results[task_name][data_count] = {}\n",
    "            if tta_method not in results[task_name][data_count]:\n",
    "                results[task_name][data_count][tta_method] = {}\n",
    "            if shift_name not in results[task_name][data_count][tta_method]:\n",
    "                results[task_name][data_count][tta_method][shift_name] = {}\n",
    "\n",
    "            results[task_name][data_count][tta_method][shift_name] = {\n",
    "                \"method\": tta_method,\n",
    "                \"baseline_accuracy\": baseline_accuracy,\n",
    "                \"tta_accuracy\": tta_accuracy,\n",
    "                \"baseline_delta\": tta_accuracy - baseline_accuracy,\n",
    "            }\n",
    "\n",
    "            # inference_frames[task_name] = inference_logs[split].to_pandas()\n",
    "            # break\n",
    "\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1350x450 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "method_avg_delta = {}\n",
    "for task_name in results:\n",
    "    for data_count in results[task_name]:\n",
    "        tta_perf_deltas = {}\n",
    "        for tta_method in results[task_name][data_count]:\n",
    "            for ood_shift in results[task_name][data_count][tta_method]:\n",
    "                if tta_method not in tta_perf_deltas:\n",
    "                    tta_perf_deltas[tta_method] = []\n",
    "\n",
    "                shift_method_perf_deta = results[task_name][data_count][tta_method][ood_shift][\"baseline_delta\"]\n",
    "                tta_perf_deltas[tta_method].append(shift_method_perf_deta)\n",
    "\n",
    "        if task_name not in method_avg_delta:\n",
    "            method_avg_delta[task_name] = {}\n",
    "\n",
    "        method_avg_delta[task_name][data_count] = { tta_method: np.mean(tta_perf_deltas[tta_method]) for tta_method in tta_perf_deltas }\n",
    "        baseline = np.mean([method_avg_delta[task_name][data_count][\"Insert\"], method_avg_delta[task_name][data_count][\"Substitute\"], method_avg_delta[task_name][data_count][\"Translate\"]])\n",
    "        method_avg_delta[task_name][data_count][\"Conventional Augmentation\"] = baseline\n",
    "\n",
    "# display(method_avg_delta)\n",
    "\n",
    "pandas_form = {task_name: {} for task_name in results}\n",
    "for task_name in pandas_form:\n",
    "    for data_count in method_avg_delta[task_name]:\n",
    "        for tta_method in [\"Conventional Augmentation\", \"Paraphrase\", \"ICR\"]:\n",
    "            if data_count not in pandas_form[task_name]:\n",
    "                pandas_form[task_name][data_count] = []\n",
    "\n",
    "            pandas_form[task_name][data_count].append({\n",
    "                \"data_count\": data_count,\n",
    "                \"tta_method\": tta_method,\n",
    "                \"avg_delta\": method_avg_delta[task_name][data_count][tta_method],\n",
    "            })\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "for i, task_name in enumerate([\"BOSS_Sentiment\", \"BOSS_Toxicity\", \"AgNewsTweets\"]):\n",
    "    df = pd.concat([pd.DataFrame(pandas_form[task_name][data_count]) for data_count in pandas_form[task_name]])\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"data_count\",\n",
    "        y=\"avg_delta\",\n",
    "        hue=\"tta_method\",\n",
    "        ax=axes[i],\n",
    "        linewidth=LINE_WIDTH,\n",
    "        marker=\"o\",\n",
    "        markersize=5)\n",
    "\n",
    "    # set x label to Training Set Size\n",
    "    axes[i].set_xlabel(\"Training Set Size\")\n",
    "\n",
    "    # set y label to Mean Absolute Accuracy Delta\n",
    "    axes[i].set_ylabel(\"Accuracy Gain\")\n",
    "\n",
    "    # make the y axis percents that go to the hundreds place\n",
    "    axes[i].yaxis.set_major_formatter(lambda x, pos: f\"{x:.0%}\")\n",
    "\n",
    "    # standardize the y axis\n",
    "    axes[i].set_ylim(-0.015, 0.1)\n",
    "\n",
    "    title_text = {\n",
    "        \"BOSS_Sentiment\": \"Sentiment\",\n",
    "        \"BOSS_Toxicity\": \"Toxicity\",\n",
    "        \"AgNewsTweets\": \"News\",\n",
    "    }\n",
    "    axes[i].set_title(title_text[task_name], fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "    # se legend to the bottom left\n",
    "    axes[i].legend(loc=\"lower right\")\n",
    "\n",
    "    # x axis ticks are five equally spaced ticks between the min and max of the x axis\n",
    "    axes[i].set_xticks(np.linspace(df[\"data_count\"].min(), df[\"data_count\"].max(), 4))\n",
    "\n",
    "    # remove leegnd in not middle plot\n",
    "    if i != 1:\n",
    "        axes[i].get_legend().remove()\n",
    "    else:\n",
    "        # center below plot with no frame\n",
    "        axes[i].legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.20), ncol=5, frameon=False, fontsize=14)\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "\n",
    "# plt.tight_layout()\n",
    "if not os.path.exists(\"figures/\"):\n",
    "    os.makedirs(\"figures/\")\n",
    "fig.savefig(\"figures/method_analysis_data_ablation.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 292/292 [00:07<00:00, 38.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "BOSS_Sentiment_SemEval_BERT_ICR     20624\n",
       "BOSS_Sentiment_Dynasent_BERT_ICR     4320\n",
       "BOSS_Sentiment_SST5_BERT_ICR         1072\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "BOSS_Toxicity_ImplicitHate_BERT_ICR    21480\n",
       "BOSS_Toxicity_Toxigen_BERT_ICR           944\n",
       "BOSS_Toxicity_AdvCivil_BERT_ICR          824\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "AgNewsTweets_Tweets_BERT_ICR    7600\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ood_sentiment_icr_data = None\n",
    "ood_toxicity_icr_data = None\n",
    "ood_tweets_icr_data = None\n",
    "for split_name in tqdm(inference_logs.keys()):\n",
    "    current_frame = inference_logs[split_name].to_pandas()\n",
    "    current_frame[\"dataset\"] = split_name\n",
    "\n",
    "    if \"Sentiment\" in split_name and \"ICR\" in split_name and \"ID\" not in split_name and \"BERT\" in split_name and \"Ablate\" not in split_name:\n",
    "        if ood_sentiment_icr_data is None:\n",
    "            ood_sentiment_icr_data = current_frame\n",
    "        else:\n",
    "            ood_sentiment_icr_data = pd.concat([ood_sentiment_icr_data, current_frame])\n",
    "\n",
    "    if \"Toxicity\" in split_name and \"ICR\" in split_name and \"ID\" not in split_name and \"BERT\" in split_name and \"Ablate\" not in split_name:\n",
    "        if ood_toxicity_icr_data is None:\n",
    "            ood_toxicity_icr_data = current_frame\n",
    "        else:\n",
    "            ood_toxicity_icr_data = pd.concat([ood_toxicity_icr_data, current_frame])\n",
    "\n",
    "    if \"Tweets\" in split_name and \"ICR\" in split_name and \"ID\" not in split_name and \"BERT\" in split_name and \"Ablate\" not in split_name:\n",
    "        if ood_tweets_icr_data is None:\n",
    "            ood_tweets_icr_data = current_frame\n",
    "        else:\n",
    "            ood_tweets_icr_data = pd.concat([ood_tweets_icr_data, current_frame])\n",
    "\n",
    "\n",
    "display(ood_sentiment_icr_data.value_counts(\"dataset\"))\n",
    "display(ood_toxicity_icr_data.value_counts(\"dataset\"))\n",
    "display(ood_tweets_icr_data.value_counts(\"dataset\"))\n",
    "assert len(ood_sentiment_icr_data.value_counts(\"dataset\")) == 3\n",
    "assert len(ood_toxicity_icr_data.value_counts(\"dataset\")) == 3\n",
    "assert len(ood_tweets_icr_data.value_counts(\"dataset\")) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:05<01:23,  1.78s/it]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  8%|▊         | 4/50 [00:07<01:21,  1.77s/it]/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kyle/miniconda3/envs/eval-aug/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 60%|██████    | 30/50 [00:37<00:17,  1.12it/s]"
     ]
    }
   ],
   "source": [
    "def aggregate_predictions(predictions, num_predictions, use_test_input):\n",
    "    try:\n",
    "        ablation_preds = predictions[:num_predictions]\n",
    "        if use_test_input:\n",
    "            ablation_preds = ablation_preds.tolist() + [predictions[-1]]\n",
    "        \n",
    "        mean_distribution = np.mean(ablation_preds, axis=0) if len(ablation_preds) > 1 else ablation_preds[0]\n",
    "        predicted_class = np.argmax(mean_distribution)\n",
    "        return predicted_class\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "\n",
    "perf_records = []\n",
    "inference_ablation_splits = [split for split in inference_logs.keys() if \"Ablate\" not in split and \"BERT\" in split]\n",
    "for split_name in tqdm(inference_ablation_splits):\n",
    "    dataset = parse_task_name(split_name)\n",
    "    distribution = parse_distribution(split_name)\n",
    "    model = parse_model(split_name)\n",
    "    method = parse_tta_method(split_name)\n",
    "\n",
    "    current_frame = inference_logs[split_name].to_pandas()\n",
    "    for use_source in [False, True]:\n",
    "        for num_augmentations in range(1, 5):\n",
    "            judgments = current_frame[\"tta_all_class_probs\"].apply(lambda x: aggregate_predictions(x, num_augmentations, use_source))\n",
    "            accuracy = classification_report(current_frame[\"label\"], judgments, output_dict=True)[\"accuracy\"]\n",
    "            perf_records.append({\n",
    "                \"dataset\": dataset,\n",
    "                \"distribution\": distribution,\n",
    "                \"model\": model,\n",
    "                \"method\": method,\n",
    "                \"use_source\": use_source,\n",
    "                \"num_augmentations\": num_augmentations,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"delta\": accuracy - no_tta_accuracies[split_name],\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_ablation_frame = pd.DataFrame(perf_records)\n",
    "\n",
    "# select where distribution != ID\n",
    "aggregation_ablation_frame = aggregation_ablation_frame[aggregation_ablation_frame[\"distribution\"] != \"ID\"]\n",
    "\n",
    "# set method to TTA if not Paraphrase or ICR and LLM-TTA if Paraphrase or ICR\n",
    "# aggregation_ablation_frame[\"method\"] = aggregation_ablation_frame[\"method\"].apply(lambda x: \"TTA\" if x not in [\"Paraphrase\", \"ICR\"] else \"LLM-TTA\")\n",
    "\n",
    "# for tta_method in [\"Conventional Augmentation\", \"Paraphrase\", \"ICR\"]:\n",
    "aggregation_ablation_frame[\"method\"] = aggregation_ablation_frame[\"method\"].apply(lambda x: \"ICR\" if \"ICR\" in x else \"Paraphrase\" if \"Paraphrase\" in x else \"Conventional Augmentation\")\n",
    "\n",
    "# create three figures, one for Sentiment, Toxicity, and News\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "for index, task_name in enumerate([\"Sentiment\", \"Toxicity\", \"News\"]):\n",
    "    # get the current task frame\n",
    "    current_frame = aggregation_ablation_frame[aggregation_ablation_frame[\"dataset\"] == task_name]\n",
    "\n",
    "    # where use_source is True\n",
    "    current_frame_source = current_frame[current_frame[\"use_source\"] == True]\n",
    "\n",
    "    # plot the current task frame\n",
    "    sns.lineplot(\n",
    "        data=current_frame,\n",
    "        x=\"num_augmentations\",\n",
    "        y=\"delta\",\n",
    "        hue=\"method\",\n",
    "        # style=\"use_source\",\n",
    "        ax=axes[index],\n",
    "        linewidth=LINE_WIDTH,\n",
    "        ci=None,\n",
    "        marker=\"o\",\n",
    "        markersize=5)\n",
    "\n",
    "    # set x label to Number of Augmentations\n",
    "    axes[index].set_xlabel(\"Number of Augmentations\")\n",
    "\n",
    "    # set y label to Accuracy\n",
    "    axes[index].set_ylabel(\"Accuracy Gain\")\n",
    "\n",
    "    # make the y axis percents that go to the hundreds place\n",
    "    axes[index].yaxis.set_major_formatter(lambda x, pos: f\"{x:.0%}\")\n",
    "\n",
    "    # set title to Sentiment, Toxicity, or News\n",
    "    axes[index].set_title(task_name, fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "    # se legend to the bottom left\n",
    "    axes[index].legend(loc=\"lower right\")\n",
    "\n",
    "    # standardize the y axis\n",
    "    axes[i].set_ylim(-0.015, 0.15)\n",
    "\n",
    "    # x axis ticks are five equally spaced ticks between the min and max of the x axis\n",
    "    axes[index].set_xticks(np.linspace(current_frame[\"num_augmentations\"].min(), current_frame[\"num_augmentations\"].max(), 4))\n",
    "\n",
    "    # remove leegnd in not middle plot\n",
    "    if index != 1:\n",
    "        axes[index].get_legend().remove()\n",
    "    else:\n",
    "        # center below plot with no frame\n",
    "        axes[index].legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.20), ncol=3, frameon=False, fontsize=14)\n",
    "    \n",
    "    # have y ticks to the tenths place\n",
    "    axes[index].yaxis.set_major_formatter(lambda x, pos: f\"{x:.1%}\")\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=WSPACE + 0.05, hspace=WSPACE)\n",
    "\n",
    "fig.savefig(\"figures/method_analysis_aggrgeation_ablation.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't crop the display frame\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "aggregation_ablation_frame = pd.DataFrame(perf_records)\n",
    "for dataset in [\"Sentiment\", \"Toxicity\", \"News\"]:\n",
    "    dataset_frame = aggregation_ablation_frame[aggregation_ablation_frame[\"dataset\"] == dataset]\n",
    "    dataset_frame[\"distribution\"] = dataset_frame[\"distribution\"].apply(lambda x: \"ID\" if \"ID\" in x else \"OOD\")\n",
    "    display(dataset_frame.groupby([\"dataset\", \"distribution\", \"model\", \"method\", \"use_source\", \"num_augmentations\"]).mean().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does TTA Effect Some Classes More Than Others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset, get the percent of examples that are unchanged vs new\n",
    "sentiment_outcomes = ood_sentiment_icr_data[\"outcome\"]\n",
    "sentiment_percents = sentiment_outcomes.value_counts(normalize=True)\n",
    "new_sentiment_percents = 100 * sentiment_percents[sentiment_percents.index == \"New Correct\"].values[0] + sentiment_percents[sentiment_percents.index == \"New Mistake\"].values[0]\n",
    "print(f\"Sentiment: {new_sentiment_percents:.2f}% of examples are new predictions\")\n",
    "\n",
    "toxicity_outcomes = ood_toxicity_icr_data[\"outcome\"]\n",
    "toxicity_percents = toxicity_outcomes.value_counts(normalize=True)\n",
    "new_toxicity_percents = 100 * toxicity_percents[toxicity_percents.index == \"New Correct\"].values[0] + toxicity_percents[toxicity_percents.index == \"New Mistake\"].values[0]\n",
    "print(f\"Toxicity: {new_toxicity_percents:.2f}% of examples are new predictions\")\n",
    "\n",
    "agt_outcomes = ood_tweets_icr_data[\"outcome\"]\n",
    "agt_percents = agt_outcomes.value_counts(normalize=True)\n",
    "new_agt_percents = 100 * agt_percents[agt_percents.index == \"New Correct\"].values[0] + agt_percents[agt_percents.index == \"New Mistake\"].values[0]\n",
    "print(f\"AGT: {new_agt_percents:.2f}% of examples are new predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_icr_outcome_percents = ood_sentiment_icr_data[[\"outcome\", \"label\"]].sort_values(\"outcome\").value_counts([\"outcome\", \"label\"], normalize=True).sort_index()\n",
    "sentiment_icr_outcome_percents = sentiment_icr_outcome_percents[sentiment_icr_outcome_percents.index.get_level_values(\"outcome\").str.contains(\"New\")]\n",
    "print(\"Sentiment ICR\")\n",
    "display(sentiment_icr_outcome_percents)\n",
    "\n",
    "toxicity_icr_outcome_percents = ood_toxicity_icr_data[[\"outcome\", \"label\"]].sort_values(\"outcome\").value_counts([\"outcome\", \"label\"], normalize=True).sort_index()\n",
    "toxicity_icr_outcome_percents = toxicity_icr_outcome_percents[toxicity_icr_outcome_percents.index.get_level_values(\"outcome\").str.contains(\"New\")]\n",
    "print(\"Toxicity ICR\")\n",
    "display(toxicity_icr_outcome_percents)\n",
    "\n",
    "tweets_icr_outcome_percents = ood_tweets_icr_data[[\"outcome\", \"label\"]].sort_values(\"outcome\").value_counts([\"outcome\", \"label\"], normalize=True).sort_index()\n",
    "tweets_icr_outcome_percents = tweets_icr_outcome_percents[tweets_icr_outcome_percents.index.get_level_values(\"outcome\").str.contains(\"New\")]\n",
    "print(\"Tweets ICR\")\n",
    "display(tweets_icr_outcome_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "\n",
    "sentiment_labels = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\",\n",
    "}\n",
    "sns.barplot(ax=axes[0], \n",
    "            x=sentiment_icr_outcome_percents.index.get_level_values(\"label\").map(sentiment_labels), \n",
    "            y=sentiment_icr_outcome_percents.values,\n",
    "            hue=sentiment_icr_outcome_percents.index.get_level_values(\"outcome\"),\n",
    ")\n",
    "\n",
    "toxicity_labels = {\n",
    "    0: \"Non-Toxic\",\n",
    "    1: \"Toxic\",\n",
    "}\n",
    "sns.barplot(ax=axes[1],\n",
    "            x=toxicity_icr_outcome_percents.index.get_level_values(\"label\").map(toxicity_labels),\n",
    "            y=toxicity_icr_outcome_percents.values,\n",
    "            hue=toxicity_icr_outcome_percents.index.get_level_values(\"outcome\"),\n",
    ")\n",
    "\n",
    "agt_labels = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\",\n",
    "}\n",
    "sns.barplot(ax=axes[2],\n",
    "            x=tweets_icr_outcome_percents.index.get_level_values(\"label\").map(agt_labels),\n",
    "            y=tweets_icr_outcome_percents.values,\n",
    "            hue=tweets_icr_outcome_percents.index.get_level_values(\"outcome\"),\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    # make y axis percents\n",
    "    axes[i].yaxis.set_major_formatter(lambda x, pos: f\"{x:.0%}\")\n",
    "\n",
    "    # standardize between 0 and 0.1\n",
    "    axes[i].set_ylim(0, 0.09)\n",
    "\n",
    "    # set y label to percent of overall outcomes\n",
    "    axes[i].set_ylabel(\"Percent of Outcomes\")\n",
    "\n",
    "    # set x label to Class\n",
    "    axes[i].set_xlabel(\"Class\")\n",
    "\n",
    "    # have fewer ticks on the y axis\n",
    "    axes[i].locator_params(axis=\"y\", nbins=5)\n",
    "\n",
    "    # set titles\n",
    "    title_text = {\n",
    "        0: \"Sentiment\",\n",
    "        1: \"Toxicity\",\n",
    "        2: \"News\",\n",
    "    }\n",
    "    axes[i].set_title(title_text[i], fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "    # have a single legend which is centered below the plot\n",
    "    if i == 1:\n",
    "        axes[i].legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.20), ncol=3, frameon=False, fontsize=14)\n",
    "    else:\n",
    "        axes[i].get_legend().remove()\n",
    "\n",
    "# add more horizental spacing for y labels\n",
    "fig.subplots_adjust(wspace=WSPACE)\n",
    "fig.savefig(\"figures/method_analysis_class_analysis.png\", bbox_inches=\"tight\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three figures on single line\n",
    "fig, axes = plt.subplots(1, 2, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "plottng_datas = [(\"Sentiment\", ood_sentiment_icr_data), (\"Toxicity\", ood_toxicity_icr_data), (\"News\", ood_tweets_icr_data)]\n",
    "change_int_mapping = {\n",
    "    \"Unchanged\": 0,\n",
    "    \"New\": 1,\n",
    "}\n",
    "outcome_int_mapping = {\n",
    "    \"Unchanged Correct\": 0,\n",
    "    \"Unfixed Mistake\": 1,\n",
    "    \"New Correct\": 2,\n",
    "    \"New Mistake\": 3,\n",
    "}\n",
    "\n",
    "change_correlations = []\n",
    "outcome_correlations = []\n",
    "for index, (title, icr_frame) in enumerate(plottng_datas):\n",
    "    icr_frame[\"max_softmax\"] = icr_frame[\"tta_mean_class_probs\"].apply(lambda p: max(p))\n",
    "    plotting_frame = icr_frame[[\"max_softmax\", \"original_prediction_entropy\", \"tta_prediction_entropy\", \"outcome\"]].sort_values(\"outcome\")\n",
    "    plotting_frame[\"Change\"] = plotting_frame[\"outcome\"].apply(lambda x: 0 if x == \"Unchanged Correct\" or x == \"Unfixed Mistake\" else 1)\n",
    "\n",
    "    correlation_metric = \"original_prediction_entropy\"\n",
    "    pbc = pointbiserialr(plotting_frame[correlation_metric], plotting_frame[\"Change\"])\n",
    "    change_correlations.append([pbc[0]])\n",
    "\n",
    "    set_outcome_correlations = []\n",
    "    for outcome in outcome_int_mapping:\n",
    "        one_hot_outcomes = plotting_frame[\"outcome\"].apply(lambda x: 1 if x == outcome else 0)\n",
    "        pbc = pointbiserialr(plotting_frame[correlation_metric], one_hot_outcomes)\n",
    "        set_outcome_correlations.append(pbc[0])\n",
    "    \n",
    "    outcome_correlations.append(set_outcome_correlations)\n",
    "\n",
    "sns.heatmap(change_correlations,\n",
    "            annot=True,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            ax=axes[0],\n",
    "            cmap=\"coolwarm\",\n",
    "            xticklabels=[\"Prediction Changed\"],\n",
    "            yticklabels=[\"Sentiment\", \"Toxicity\", \"News\"])\n",
    "\n",
    "sns.heatmap(outcome_correlations,\n",
    "            annot=True,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            ax=axes[1],\n",
    "            cmap=\"coolwarm\",\n",
    "            xticklabels=[\"Unchanged Correct\", \"Unfixed Mistake\", \"New Correct\", \"New Mistake\"],\n",
    "            yticklabels=[\"Sentiment\", \"Toxicity\", \"News\"])\n",
    "\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "fig.subplots_adjust(wspace=WSPACE / 2)\n",
    "fig.savefig(\"figures/method_analysis_entropy_correlations.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three figures on single line\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "plottng_datas = [(\"Sentiment\", ood_sentiment_icr_data), (\"Toxicity\", ood_toxicity_icr_data), (\"News\", ood_tweets_icr_data)]\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for index, (title, icr_frame) in tqdm(enumerate(plottng_datas)):\n",
    "    axes[index].set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "    icr_frame[\"max_softmax\"] = icr_frame[\"tta_mean_class_probs\"].apply(lambda p: max(p))\n",
    "    plotting_frame = icr_frame[[\"max_softmax\", \"original_prediction_entropy\", \"tta_prediction_entropy\", \"outcome\"]].sort_values(\"outcome\")\n",
    "    plotting_frame[\"Prediction\"] = plotting_frame[\"outcome\"].apply(lambda x: \"Unchanged Prediction\" if x == \"Unchanged Correct\" or x == \"Unfixed Mistake\" else \"New Prediction\")\n",
    "\n",
    "    # create kernal density estimate plot for original prediction entropy by outcome\n",
    "    sns.kdeplot(\n",
    "        data=plotting_frame,\n",
    "        x=\"original_prediction_entropy\",\n",
    "        hue=\"Prediction\",\n",
    "        fill=True,\n",
    "        ax=axes[index],\n",
    "        linewidth=LINE_WIDTH,\n",
    "        # alpha=0.5,\n",
    "        common_norm=False,\n",
    "    )\n",
    "\n",
    "    # log y and x axis\n",
    "    # axes[index].set_yscale(\"log\")\n",
    "    axes[index].set_xscale(\"log\")\n",
    "\n",
    "    # move legend to the top left\n",
    "    if index == 1:\n",
    "        axes[index].legend(loc=\"upper center\", labels=[\"Unchanged\", \"New\"], bbox_to_anchor=(0.5, -0.20), ncol=2, frameon=False, fontsize=14)\n",
    "    else:\n",
    "        axes[index].get_legend().remove()\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE)\n",
    "fig.savefig(\"figures/method_analysis_entropy_distributions.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Optimal ID Entropy Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_augment_entropy(threshold, row):\n",
    "    return row[\"original_prediction_entropy\"] >= threshold\n",
    "\n",
    "\n",
    "def get_entropy_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"tta_predicted_class\"] if should_augment_entropy(threshold, row) else row[\"original_predicted_class\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True, zero_division=0)\n",
    "    llm_call_count = inference_logs_frame.apply(lambda row: should_augment_entropy(threshold, row), axis=1).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate\n",
    "\n",
    "\n",
    "def should_augment_softmax(threshold, row):\n",
    "    try:\n",
    "        return row[\"tta_all_class_probs\"][-1].max() < threshold\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_max_softmax_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"tta_predicted_class\"] if should_augment_softmax(threshold, row) else row[\"original_predicted_class\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True, zero_division=0)\n",
    "    llm_call_count = (inference_logs_frame[\"original_prediction_entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate\n",
    "\n",
    "thresholds = np.arange(0, 1.2, 0.0001)\n",
    "print(f\"Number of thresholds: {len(thresholds)}\")\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD Entropy Threshold Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate all the tresholds for each OOD split for BERT ICR. \n",
    "# 2. Get the manual threshold for each OOD split for BERT ICR at different augmentation rates.\n",
    "\n",
    "thresholds_dict = {}\n",
    "thresholds_path = f\"data/thresholds_dict_{len(thresholds)}.json\"\n",
    "if not os.path.exists(thresholds_path):\n",
    "    for ood_icr_data in [ood_sentiment_icr_data, ood_toxicity_icr_data, ood_tweets_icr_data]:\n",
    "        for split in ood_icr_data[\"dataset\"].unique():\n",
    "            print(split)\n",
    "            thresholds_dict[split] = {}\n",
    "            split_frame = ood_icr_data[ood_icr_data[\"dataset\"] == split]\n",
    "            original_accuracy = classification_report(split_frame[\"label\"], split_frame[\"original_predicted_class\"], output_dict=True)[\"accuracy\"]\n",
    "            \n",
    "            for threshold in tqdm(thresholds):\n",
    "                accuracy, llm_call_rate = get_entropy_threshold_accuracy(threshold, split_frame)\n",
    "                thresholds_dict[split][threshold] = {\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"accuracy_delta\": accuracy - original_accuracy,\n",
    "                    \"llm_call_rate\": llm_call_rate,\n",
    "                }\n",
    "    json.dump(thresholds_dict, open(thresholds_path, \"w\"), indent=4)\n",
    "else:\n",
    "    with open(\"data/thresholds_dict.json\", \"r\") as f:\n",
    "        thresholds_dict = json.load(f)\n",
    "\n",
    "print(json.dumps(thresholds_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subplot for each dataset in the thresholds dict with three on each row\n",
    "fig, axes = plt.subplots(3, 3, figsize=(3 * FIG_SIZE, 3 * FIG_SIZE))\n",
    "\n",
    "# use the first row for sentiment, second for toxicity, and third for agt\n",
    "task_keys = [\n",
    "    [key for key in thresholds_dict.keys() if \"Sentiment\" in key],\n",
    "    [key for key in thresholds_dict.keys() if \"Toxicity\" in key],\n",
    "    [key for key in thresholds_dict.keys() if \"Tweets\" in key],\n",
    "]\n",
    "for row_index, task_splits in enumerate(task_keys):\n",
    "    for col_index in range(len(task_splits)):\n",
    "        split_name = task_splits[col_index]\n",
    "        thresholds_split_frame = pd.DataFrame(thresholds_dict[split_name]).T.reset_index().sort_values(\"llm_call_rate\")\n",
    "        sns.lineplot(\n",
    "            ax=axes[row_index, col_index],\n",
    "            data=thresholds_split_frame,\n",
    "            x=\"llm_call_rate\",\n",
    "            y=\"accuracy_delta\",\n",
    "            linewidth=LINE_WIDTH)\n",
    "\n",
    "        row_titles = {\n",
    "            0: \"Sentiment\",\n",
    "            1: \"Toxicity\",\n",
    "            2: \"News\",\n",
    "        }\n",
    "        shift_name = split_name.split(\"_\")[-3]\n",
    "        axes[row_index, col_index].set_title(f\"{row_titles[row_index]}: {shift_name}\", fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "for col_index in range(3):\n",
    "    for row_index in range(3):\n",
    "        axes[row_index, col_index].set_ylabel(\"Accuracy Delta\")\n",
    "        axes[row_index, col_index].set_xlabel(\"Augmentation Rate\")\n",
    "\n",
    "        # set x and y axis to percents\n",
    "        axes[row_index, col_index].xaxis.set_major_formatter(lambda x, pos: f\"{x:.0%}\")\n",
    "\n",
    "        # multiple delta by 100 to get percent\n",
    "        axes[row_index, col_index].yaxis.set_major_formatter(lambda x, pos: f\"{round(x * 100, 2)}\")\n",
    "\n",
    "        # set y axis between -0.1 and 0.1\n",
    "        # axes[row_index, col_index].set_ylim(-0.01, 0.15)\n",
    "\n",
    "        # have five ticks on the y axis\n",
    "        axes[row_index, col_index].locator_params(axis=\"y\", nbins=8)\n",
    "\n",
    "        # delete last two plots on the final row\n",
    "        if row_index == 2 and col_index > 0:\n",
    "            axes[row_index, col_index].remove()\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE + 0.25)\n",
    "\n",
    "# save figure\n",
    "fig.savefig(\"figures/method_analysis_all_entropy_thresholds.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_sentiment_thresholds = {}\n",
    "for split in thresholds_dict:\n",
    "    task = \"Sentiment\" if \"Sentiment\" in split else \"Toxicity\" if \"Toxicity\" in split else \"News\"\n",
    "    if task not in aggregated_sentiment_thresholds:\n",
    "        aggregated_sentiment_thresholds[task] = {}\n",
    "\n",
    "    for threshold in thresholds_dict[split]:\n",
    "        if threshold not in aggregated_sentiment_thresholds:\n",
    "            aggregated_sentiment_thresholds[task][threshold] = {\n",
    "                \"accuracy_delta\": 0,\n",
    "                \"llm_call_rate\": 0,\n",
    "            }\n",
    "\n",
    "        aggregated_sentiment_thresholds[task][threshold][\"accuracy_delta\"] += thresholds_dict[split][threshold][\"accuracy_delta\"]\n",
    "        aggregated_sentiment_thresholds[task][threshold][\"llm_call_rate\"] += thresholds_dict[split][threshold][\"llm_call_rate\"]\n",
    "\n",
    "# divide each accuracy delta by the number of splits to get the average\n",
    "for task in aggregated_sentiment_thresholds:\n",
    "    for threshold in aggregated_sentiment_thresholds[task]:\n",
    "        aggregated_sentiment_thresholds[task][threshold][\"accuracy_delta\"] /= 3\n",
    "        # aggregated_sentiment_thresholds[task][threshold][\"llm_call_rate\"] /= 3\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(3 * FIG_SIZE, FIG_SIZE))\n",
    "for col_index, task in enumerate(aggregated_sentiment_thresholds):\n",
    "    sns.lineplot(\n",
    "        ax=axes[col_index],\n",
    "        data=pd.DataFrame(aggregated_sentiment_thresholds[task]).T.reset_index().sort_values(\"llm_call_rate\"),\n",
    "        x=\"llm_call_rate\",\n",
    "        y=\"accuracy_delta\",\n",
    "        linewidth=LINE_WIDTH)\n",
    "    \n",
    "\n",
    "    axes[col_index].set_title(task, fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "    # add padding for labels\n",
    "    axes[col_index].set_ylabel(\"Accuracy Delta\")\n",
    "    axes[col_index].set_xlabel(\"Augmentation Rate\")\n",
    "\n",
    "    # set x and y axis to percents\n",
    "    axes[col_index].xaxis.set_major_formatter(lambda x, pos: f\"{x:.0%}\")\n",
    "    axes[col_index].yaxis.set_major_formatter(lambda x, pos: f\"{round(x * 100, 2)}\")\n",
    "\n",
    "    # set y value between 0 and 0.1\n",
    "    # axes[col_index].set_ylim(-0.01, 0.08)\n",
    "\n",
    "    # have few ticks on the x axis\n",
    "    axes[col_index].locator_params(axis=\"x\", nbins=5)\n",
    "    axes[col_index].locator_params(axis=\"y\", nbins=5)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=0.3)\n",
    "fig.savefig(\"figures/method_analysis_aggregated_entropy_thresholds.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tta_preds(row):\n",
    "    if row[\"generations\"] is not None and len(row[\"generations\"]) > 0:\n",
    "        return row[\"generations\"][:5]\n",
    "    \n",
    "    if row[\"tta_all_class_probs\"] is None:\n",
    "        return None\n",
    "\n",
    "    all_probs = row[\"tta_all_class_probs\"][:5]\n",
    "    arg_maxes = [prob_dist.argmax() for prob_dist in all_probs]\n",
    "    return arg_maxes\n",
    "\n",
    "def is_entropy_split(split_name):\n",
    "    if \"BERT\" not in split_name:\n",
    "        return False\n",
    "    if \"Ablate\" in split_name:\n",
    "        return False\n",
    "    if \"ID\" in split_name:\n",
    "        return False\n",
    "\n",
    "    return \"Paraphrase\" in split_name or \"ICR\" in split_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_entropy_thresholds = {}\n",
    "optimal_softmax_thresholds = {}\n",
    "thresholds = np.arange(0, 1.2, 0.0005)\n",
    "SAMPLE_SIZE = 250\n",
    "print(f\"Number of thresholds: {len(thresholds)}\")\n",
    "\n",
    "for split in [dataset for dataset in inference_logs if is_entropy_split(dataset)]:\n",
    "    print(split)\n",
    "    best_entropy_threshold = None\n",
    "    best_softmax_threshold = None\n",
    "    split_frame = inference_logs[split].to_pandas()\n",
    "    sample_frame = None\n",
    "    unique_predicted_classes = [class_label for class_label in split_frame[\"tta_predicted_class\"].unique() if class_label != -1] \n",
    "    for class_prediction in unique_predicted_classes:\n",
    "        sample_size = SAMPLE_SIZE // len(unique_predicted_classes)\n",
    "        class_sample_frame = split_frame[split_frame[\"tta_predicted_class\"] == class_prediction].sample(sample_size, random_state=42)\n",
    "        if sample_frame is None:\n",
    "            sample_frame = class_sample_frame\n",
    "        else:\n",
    "            sample_frame = pd.concat([sample_frame, class_sample_frame])\n",
    "    \n",
    "    threshold_performances = []\n",
    "    for threshold in tqdm(thresholds):\n",
    "        accuracy, llm_call_rate = get_entropy_threshold_accuracy(threshold, sample_frame)\n",
    "        beta = 1/500\n",
    "        rate_term = 1 - llm_call_rate\n",
    "        threshold_score = (1 + beta ** 2) * ((accuracy * rate_term) / ((beta ** 2) * accuracy + rate_term))\n",
    "        threshold_perf = {\n",
    "            \"threshold\": threshold,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"score\": threshold_score,\n",
    "            \"llm_call_rate\": f\"{llm_call_rate:.2f}%\",\n",
    "        }\n",
    "        threshold_performances.append(threshold_perf)\n",
    "\n",
    "        # if best_entropy_threshold is None or accuracy > best_entropy_threshold[\"accuracy\"]:\n",
    "        if best_entropy_threshold is None or threshold_score > best_entropy_threshold[\"score\"]:\n",
    "            best_entropy_threshold = threshold_perf\n",
    "\n",
    "    pd.DataFrame(threshold_performances).to_csv(f\"data/threshold_performances_{split}.csv\", index=False)\n",
    "    optimal_entropy_thresholds[split] = best_entropy_threshold\n",
    "    print(f\"Best Entropy Threshold: {best_entropy_threshold}\")\n",
    "\n",
    "# print(json.dumps(optimal_entropy_thresholds, indent=4))\n",
    "# print(json.dumps(optimal_softmax_thresholds, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_records = []\n",
    "\n",
    "# display(id_logs)\n",
    "# display(split_names)\n",
    "for split_name in tqdm(optimal_entropy_thresholds):\n",
    "    split_logs = inference_logs[split_name].to_pandas()\n",
    "\n",
    "    perf_records.append({\n",
    "        \"split\": split_name,\n",
    "        \"tta\": \"None\",\n",
    "        \"accuracy\": classification_report(split_logs[\"label\"], split_logs[\"original_predicted_class\"], digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "    })\n",
    "\n",
    "    optimal_entropy_threshold = optimal_entropy_thresholds[split_name][\"threshold\"]\n",
    "    accuracy = get_entropy_threshold_accuracy(optimal_entropy_threshold, split_logs)[0]\n",
    "    perf_records.append({\n",
    "        \"split\": split_name,\n",
    "        \"tta\": \"entropy-based\",\n",
    "        \"accuracy\": accuracy,\n",
    "        \"augmentation_rate\": split_logs.apply(lambda row: should_augment_entropy(optimal_entropy_threshold, row), axis=1).sum() / len(split_logs),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_frame = pd.DataFrame(perf_records)\n",
    "results_frame[\"Dataset\"] = results_frame[\"split\"].apply(lambda s: s.split(\"_\")[-4])\n",
    "results_frame[\"Distribution\"] = results_frame[\"split\"].apply(lambda s: s.split(\"_\")[-3])\n",
    "results_frame[\"Model\"] = results_frame[\"split\"].apply(lambda s: s.split(\"_\")[-2])\n",
    "results_frame[\"TTA Method\"] = results_frame[\"split\"].apply(lambda s: s.split(\"_\")[-1])\n",
    "results_frame[\"Baseline Delta\"] = results_frame.apply(lambda row: row[\"accuracy\"] - results_frame[(results_frame[\"split\"] == row[\"split\"]) & (results_frame[\"tta\"] == \"None\")][\"accuracy\"].values[0], axis=1)\n",
    "results_frame.drop(columns=[\"split\"], inplace=True)\n",
    "results_frame.rename(columns={\"tta\": \"Selective Method\", \"accuracy\": \"Accuracy\", \"augmentation_rate\": \"Augmentation Rate\"}, inplace=True)\n",
    "\n",
    "aggregated_results = results_frame.groupby([\"Dataset\", \"Distribution\", \"Model\", \"TTA Method\", \"Selective Method\"]).mean().round(4) * 100\n",
    "aggregated_results = aggregated_results.sort_values(by=[\"Dataset\", \"Distribution\", \"Model\", \"TTA Method\", \"Accuracy\"], ascending=False)\n",
    "\n",
    "print(\"Overall Results\")\n",
    "# display(aggregated_results)\n",
    "\n",
    "# Average each TTA Method and Selective Method over distributions\n",
    "results_frame[\"ID\"] = results_frame[\"Distribution\"].apply(lambda d: \"ID\" in d)\n",
    "results_frame.drop(columns=[\"Distribution\", \"Accuracy\"], inplace=True)\n",
    "results_frame = results_frame[[\"Dataset\", \"ID\", \"Model\", \"TTA Method\", \"Selective Method\", \"Baseline Delta\", \"Augmentation Rate\"]]\n",
    "aggregated_results = results_frame.groupby([\"Dataset\", \"ID\", \"Model\", \"TTA Method\", \"Selective Method\"]).mean().round(4) * 100\n",
    "aggregated_results = aggregated_results.sort_values(by=[\"Dataset\", \"ID\", \"Model\", \"TTA Method\", \"Baseline Delta\"], ascending=False)\n",
    "print(\"Average Results\")\n",
    "for dataset in [\"Sentiment\", \"Toxicity\", \"AgNewsTweets\"]:\n",
    "    for tta_method in [\"Paraphrase\", \"ICR\"]:\n",
    "    # for tta_method in [\"ICR\"]:\n",
    "        print(f\"Dataset: {dataset}, TTA Method: {tta_method}\")\n",
    "        # display(aggregated_results.loc[dataset, :, :, tta_method, :])\n",
    "        # only show entropy-based\n",
    "        display(aggregated_results.loc[dataset, :, :, tta_method, \"entropy-based\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
