{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tqdm.pandas()\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "aug_regex = re.compile(r\"<aug>(.*?)</aug>\", re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_logs = load_from_disk(\"data/combined_dataset\")\n",
    "inference_logs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data = inference_logs[\"BOSS_Sentiment_SST5_BERT_ICR\"].to_pandas()\n",
    "display(sst5_data.head(1))\n",
    "display(sst5_data.shape)\n",
    "\n",
    "toxigen_data = inference_logs[\"BOSS_Toxicity_Toxigen_BERT_ICR\"].to_pandas()\n",
    "display(toxigen_data.head(1))\n",
    "display(toxigen_data.shape)\n",
    "\n",
    "agt_data = inference_logs[\"AgNewsTweets_Tweets_BERT_ICR\"].to_pandas()\n",
    "display(agt_data.head(1))\n",
    "display(agt_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze ICR Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data[\"augmentations\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does TTA Effect Some Classes More Than Others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data.value_counts([\"label\", \"outcome\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the overall ratio of New Corrections to New Mistakes for sst5_data, toxigen_data, and agt_data\n",
    "pd.concat([sst5_data, toxigen_data, agt_data]).value_counts([\"outcome\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset, get the percent of examples that are unchanged vs new\n",
    "sst5_outcomes = sst5_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * sst5_outcomes[sst5_outcomes.index == \"New Correct\"].values[0] + sst5_outcomes[sst5_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"SST-5: {new_predcitions_percent:.2f}% of examples are new predictions\")\n",
    "\n",
    "toxicgen_outcomes = toxigen_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * toxicgen_outcomes[toxicgen_outcomes.index == \"New Correct\"].values[0] + toxicgen_outcomes[toxicgen_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"ToxicGen: {new_predcitions_percent:.2f}% of examples are new predictions\")\n",
    "\n",
    "agt_outcomes = agt_data[\"outcome\"].value_counts(normalize=True)\n",
    "new_predcitions_percent = 100 * agt_outcomes[agt_outcomes.index == \"New Correct\"].values[0] + agt_outcomes[agt_outcomes.index == \"New Mistake\"].values[0]\n",
    "print(f\"AGT: {new_predcitions_percent:.2f}% of examples are new predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear plots\n",
    "plt.clf()\n",
    "\n",
    "# Create three histograms on one row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "sst5_labels = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\",\n",
    "}\n",
    "sst5_corruptions_corrections = sst5_data[(sst5_data[\"outcome\"] == \"New Correct\") | (sst5_data[\"outcome\"] == \"New Mistake\")]\n",
    "sst5_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "sst5_corruptions_corrections[\"label\"] = sst5_corruptions_corrections[\"label\"].apply(lambda l: sst5_labels[l])\n",
    "# sort values by Negative, Neutral, Positive in that order\n",
    "sst5_corruptions_corrections.sort_values(by=[\"label\"], inplace=True, key=lambda x: x.map({\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}))\n",
    "sns.histplot(data=sst5_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[0])\n",
    "\n",
    "toxigen_labels = {\n",
    "    0: \"Non-Toxic\",\n",
    "    1: \"Toxic\",\n",
    "}\n",
    "toxigen_corruptions_corrections = toxigen_data[(toxigen_data[\"outcome\"] == \"New Correct\") | (toxigen_data[\"outcome\"] == \"New Mistake\")]\n",
    "toxigen_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "toxigen_corruptions_corrections[\"label\"] = toxigen_corruptions_corrections[\"label\"].apply(lambda l: toxigen_labels[l])\n",
    "sns.histplot(data=toxigen_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[1])\n",
    "\n",
    "agt_labels = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\",\n",
    "}\n",
    "agt_corruptions_corrections = agt_data[(agt_data[\"outcome\"] == \"New Correct\") | (agt_data[\"outcome\"] == \"New Mistake\")]\n",
    "agt_corruptions_corrections.sort_values(by=[\"label\", \"outcome\"], inplace=True)\n",
    "agt_corruptions_corrections[\"label\"] = agt_corruptions_corrections[\"label\"].apply(lambda l: agt_labels[l])\n",
    "sns.histplot(data=agt_corruptions_corrections, x=\"label\", hue=\"outcome\", multiple=\"dodge\", shrink=.8, ax=axes[2])\n",
    "\n",
    "axes[0].set_ylabel(\"Count\", labelpad=20, fontsize=14)\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[2].set_ylabel(\"\")\n",
    "axes[0].set_xlabel(\"SST-5\", labelpad=20, fontsize=14)\n",
    "axes[1].set_xlabel(\"Toxigen\", labelpad=20, fontsize=14)\n",
    "axes[2].set_xlabel(\"AG News Tweets\", labelpad=20, fontsize=14)\n",
    "\n",
    "# set x labels above the plots\n",
    "axes[0].xaxis.set_label_position('top')\n",
    "axes[1].xaxis.set_label_position('top')\n",
    "axes[2].xaxis.set_label_position('top')\n",
    "\n",
    "# Have a shared legend\n",
    "axes[0].get_legend().remove()\n",
    "axes[1].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), labels=[\"Corruptions\", \"Corrections\"], ncol=2, fancybox=False, frameon=False, fontsize=14)\n",
    "axes[2].get_legend().remove()\n",
    "\n",
    "\n",
    "# add padding\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.savefig(\"../datasets/analysis/figures/corruptions_corrections_histograms.png\", bbox_inches='tight', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_prediction_entropy     1.000000\n",
       "tta_prediction_entropy          0.030508\n",
       "prediction_entropy_decreased    0.572638\n",
       "Name: (3.0, original_prediction_entropy), dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "from scipy.stats import pearsonr as pearson_correlation\n",
    "\n",
    "# API - https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html\n",
    "from scipy.stats import spearmanr as spearman_correlation\n",
    "\n",
    "# Paper - https://arxiv.org/abs/1909.10140\n",
    "# API - https://swarnakumar.github.io/xicorpy/xi/\n",
    "# from xicorpy import compute_xi_correlation as xi_correlation\n",
    "\n",
    "conditional_test_outputs = dict()\n",
    "\n",
    "outcome_map = {\n",
    "        \"New Correct\": 3,\n",
    "        \"New Mistake\": 2,\n",
    "        \"Unchanged Correct\": 1,\n",
    "        \"Unfixed Mistake\": 0,\n",
    "        \"NA\": None\n",
    "    }\n",
    "boss_sentiment_id = inference_logs[\"BOSS_Sentiment_SST5_BERT_ICR\"].to_pandas()\n",
    "boss_sentiment_id[\"outcome\"] = boss_sentiment_id[\"outcome\"].apply(lambda o: outcome_map[o])\n",
    "correlation_frame = None\n",
    "\n",
    "correlaiton_columns = [\"outcome\", \"original_prediction_entropy\", \"tta_prediction_entropy\", \"prediction_entropy_decreased\"]\n",
    "boss_sentiment_id[correlaiton_columns].groupby(\"outcome\").corr(method=\"pearson\", numeric_only=True)\n",
    "\n",
    "# get the correlation of the original prediction entropy and the outcome\n",
    "boss_sentiment_id[correlaiton_columns].groupby(\"outcome\").corr(method=\"pearson\", numeric_only=True).loc[3, \"original_prediction_entropy\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Optimal ID Entropy Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"original_predicted_class\"] if row[\"original_prediction_entropy\"] < threshold else row[\"tta_predicted_class\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True, zero_division=0)\n",
    "    llm_call_count = (inference_logs_frame[\"original_prediction_entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:44<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS_Sentiment_ID_BERT_ICR: {'threshold': 0.5399999999999998, 'accuracy': 0.9119884844746041, 'llm_call_rate': '0.13%'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:57<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS_Toxicity_ID_BERT_ICR: {'threshold': 0.1, 'accuracy': 0.8915125359638306, 'llm_call_rate': '0.02%'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:09<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgNewsTweets_ID_BERT_ICR: {'threshold': 0.21999999999999995, 'accuracy': 0.9489473684210527, 'llm_call_rate': '0.01%'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_entropy_thresholds = {}\n",
    "thresholds = np.arange(0.1, 1, 0.01)\n",
    "for split in [dataset for dataset in inference_logs if \"ID_BERT_ICR\" in dataset]:\n",
    "    best_threshold = None\n",
    "    for threshold in tqdm(thresholds):\n",
    "        accuracy, llm_call_rate = get_entropy_threshold_accuracy(threshold, inference_logs[split].to_pandas())\n",
    "        if best_threshold is None or accuracy > best_threshold[\"accuracy\"]:\n",
    "            best_threshold = {\n",
    "                \"threshold\": threshold,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"llm_call_rate\": f\"{llm_call_rate:.2f}%\",\n",
    "            }\n",
    "\n",
    "    optimal_entropy_thresholds[split] = best_threshold\n",
    "    print(f\"{split}: {best_threshold}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_softmax_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"original_predicted_class\"] if row[\"original_prediction_entropy\"] < threshold else row[\"tta_predicted_class\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True, zero_division=0)\n",
    "    llm_call_count = (inference_logs_frame[\"original_prediction_entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/90 [10:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m best_threshold \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m tqdm(thresholds):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     accuracy, llm_call_rate \u001b[39m=\u001b[39m get_softmax_threshold_accuracy(threshold, inference_logs[split]\u001b[39m.\u001b[39;49mto_pandas())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m best_threshold \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_threshold[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         best_threshold \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m\"\u001b[39m: threshold,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: accuracy,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mllm_call_rate\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mllm_call_rate\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         }\n",
      "\u001b[1;32m/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_softmax_threshold_accuracy\u001b[39m(threshold, inference_logs_frame):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     threshold_judgments \u001b[39m=\u001b[39m inference_logs_frame\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m\"\u001b[39m\u001b[39moriginal_predicted_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39moriginal_prediction_entropy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m threshold \u001b[39melse\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mtta_predicted_class\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     report \u001b[39m=\u001b[39m classification_report(inference_logs_frame[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m], threshold_judgments, digits\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, zero_division\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     llm_call_count \u001b[39m=\u001b[39m (inference_logs_frame[\u001b[39m\"\u001b[39m\u001b[39moriginal_prediction_entropy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold)\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;32m/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_softmax_threshold_accuracy\u001b[39m(threshold, inference_logs_frame):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     threshold_judgments \u001b[39m=\u001b[39m inference_logs_frame\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: row[\u001b[39m\"\u001b[39m\u001b[39moriginal_predicted_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39moriginal_prediction_entropy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m threshold \u001b[39melse\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mtta_predicted_class\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     report \u001b[39m=\u001b[39m classification_report(inference_logs_frame[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m], threshold_judgments, digits\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, zero_division\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a757265227d/home/kyobrien/repos/In-Context-Domain-Transfer-Improves-Out-of-Domain-Robustness/notebooks/method_analysis_paper.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     llm_call_count \u001b[39m=\u001b[39m (inference_logs_frame[\u001b[39m\"\u001b[39m\u001b[39moriginal_prediction_entropy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold)\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/icdt/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/icdt/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimal_softmax_thresholds = {}\n",
    "thresholds = np.arange(0.1, 1, 0.01)\n",
    "for split in [dataset for dataset in inference_logs if \"ID_BERT_ICR\" in dataset]:\n",
    "    best_threshold = None\n",
    "    for threshold in tqdm(thresholds):\n",
    "        accuracy, llm_call_rate = get_softmax_threshold_accuracy(threshold, inference_logs[split].to_pandas())\n",
    "        if best_threshold is None or accuracy > best_threshold[\"accuracy\"]:\n",
    "            best_threshold = {\n",
    "                \"threshold\": threshold,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"llm_call_rate\": f\"{llm_call_rate:.2f}%\",\n",
    "            }\n",
    "\n",
    "    optimal_softmax_thresholds[split] = best_threshold\n",
    "    print(f\"{split}: {best_threshold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Based Selective Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>selective augmentation</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOSS_Sentiment_ID_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.908518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOSS_Sentiment_ID_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.908518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOSS_Sentiment_SST5_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.739739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOSS_Sentiment_SST5_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.739739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOSS_Sentiment_SST5_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.739739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOSS_Sentiment_SST5_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.697761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOSS_Sentiment_SemEval_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.490497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOSS_Sentiment_SemEval_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.490497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOSS_Sentiment_SemEval_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.490497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOSS_Sentiment_SemEval_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.450640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BOSS_Sentiment_Dynasent_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.477083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOSS_Sentiment_Dynasent_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.477083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOSS_Sentiment_Dynasent_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.477083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BOSS_Sentiment_Dynasent_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.432639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOSS_Toxicity_ID_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.914468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOSS_Toxicity_ID_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.928268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOSS_Toxicity_Toxigen_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.657839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOSS_Toxicity_Toxigen_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.712924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BOSS_Toxicity_Toxigen_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.712924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BOSS_Toxicity_Toxigen_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.705508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BOSS_Toxicity_ImplicitHate_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.657356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BOSS_Toxicity_ImplicitHate_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.718901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BOSS_Toxicity_ImplicitHate_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.718901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BOSS_Toxicity_ImplicitHate_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.707775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BOSS_Toxicity_AdvCivil_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.502427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BOSS_Toxicity_AdvCivil_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.405340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BOSS_Toxicity_AdvCivil_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.405340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BOSS_Toxicity_AdvCivil_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.399272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AgNewsTweets_ID_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.929868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AgNewsTweets_ID_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.949868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AgNewsTweets_Tweets_BERT_ICR</td>\n",
       "      <td>None</td>\n",
       "      <td>0.897500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AgNewsTweets_Tweets_BERT_ICR</td>\n",
       "      <td>class-based</td>\n",
       "      <td>0.888421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AgNewsTweets_Tweets_BERT_ICR</td>\n",
       "      <td>entropy-based</td>\n",
       "      <td>0.888421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AgNewsTweets_Tweets_BERT_ICR</td>\n",
       "      <td>class-based &amp; entropy-based</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  split       selective augmentation  accuracy\n",
       "0            BOSS_Sentiment_ID_BERT_ICR                         None  0.908518\n",
       "1            BOSS_Sentiment_ID_BERT_ICR                  class-based  0.908518\n",
       "2          BOSS_Sentiment_SST5_BERT_ICR                         None  0.739739\n",
       "3          BOSS_Sentiment_SST5_BERT_ICR                  class-based  0.739739\n",
       "4          BOSS_Sentiment_SST5_BERT_ICR                entropy-based  0.739739\n",
       "5          BOSS_Sentiment_SST5_BERT_ICR  class-based & entropy-based  0.697761\n",
       "6       BOSS_Sentiment_SemEval_BERT_ICR                         None  0.490497\n",
       "7       BOSS_Sentiment_SemEval_BERT_ICR                  class-based  0.490497\n",
       "8       BOSS_Sentiment_SemEval_BERT_ICR                entropy-based  0.490497\n",
       "9       BOSS_Sentiment_SemEval_BERT_ICR  class-based & entropy-based  0.450640\n",
       "10     BOSS_Sentiment_Dynasent_BERT_ICR                         None  0.477083\n",
       "11     BOSS_Sentiment_Dynasent_BERT_ICR                  class-based  0.477083\n",
       "12     BOSS_Sentiment_Dynasent_BERT_ICR                entropy-based  0.477083\n",
       "13     BOSS_Sentiment_Dynasent_BERT_ICR  class-based & entropy-based  0.432639\n",
       "14            BOSS_Toxicity_ID_BERT_ICR                         None  0.914468\n",
       "15            BOSS_Toxicity_ID_BERT_ICR                  class-based  0.928268\n",
       "16       BOSS_Toxicity_Toxigen_BERT_ICR                         None  0.657839\n",
       "17       BOSS_Toxicity_Toxigen_BERT_ICR                  class-based  0.712924\n",
       "18       BOSS_Toxicity_Toxigen_BERT_ICR                entropy-based  0.712924\n",
       "19       BOSS_Toxicity_Toxigen_BERT_ICR  class-based & entropy-based  0.705508\n",
       "20  BOSS_Toxicity_ImplicitHate_BERT_ICR                         None  0.657356\n",
       "21  BOSS_Toxicity_ImplicitHate_BERT_ICR                  class-based  0.718901\n",
       "22  BOSS_Toxicity_ImplicitHate_BERT_ICR                entropy-based  0.718901\n",
       "23  BOSS_Toxicity_ImplicitHate_BERT_ICR  class-based & entropy-based  0.707775\n",
       "24      BOSS_Toxicity_AdvCivil_BERT_ICR                         None  0.502427\n",
       "25      BOSS_Toxicity_AdvCivil_BERT_ICR                  class-based  0.405340\n",
       "26      BOSS_Toxicity_AdvCivil_BERT_ICR                entropy-based  0.405340\n",
       "27      BOSS_Toxicity_AdvCivil_BERT_ICR  class-based & entropy-based  0.399272\n",
       "28             AgNewsTweets_ID_BERT_ICR                         None  0.929868\n",
       "29             AgNewsTweets_ID_BERT_ICR                  class-based  0.949868\n",
       "30         AgNewsTweets_Tweets_BERT_ICR                         None  0.897500\n",
       "31         AgNewsTweets_Tweets_BERT_ICR                  class-based  0.888421\n",
       "32         AgNewsTweets_Tweets_BERT_ICR                entropy-based  0.888421\n",
       "33         AgNewsTweets_Tweets_BERT_ICR  class-based & entropy-based  0.887500"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"BERT\"\n",
    "id_icr_logs = [split for split in inference_logs if f\"ID_{model}_ICR\" in split]\n",
    "ood_icr_reports = [split for split in inference_logs if f\"{model}_ICR\" in split and f\"ID_{model}_ICR\" not in split]\n",
    "perf_records = []\n",
    "\n",
    "# display(id_icr_logs)\n",
    "# display(ood_icr_reports)\n",
    "for id_icr_split in id_icr_logs:\n",
    "    # print(f\"{id_icr_split}:\")\n",
    "    id_icr_data = inference_logs[id_icr_split].to_pandas()\n",
    "    change_predictions_count_by_label = id_icr_data[id_icr_data[\"outcome\"].str.contains(\"New\")].value_counts([\"label\", \"outcome\"]).sort_index()\n",
    "\n",
    "    # get list of labels where New Correct > New Mistake\n",
    "    labels_list = []\n",
    "    for label in change_predictions_count_by_label.index.levels[0]:\n",
    "        new_correct_count = change_predictions_count_by_label.loc[label].values[0]\n",
    "        new_mistake_count = change_predictions_count_by_label.loc[label].values[1]\n",
    "        if new_correct_count > 1 * new_mistake_count:\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # display(change_predictions_count_by_label)\n",
    "    # display(labels_list)\n",
    "\n",
    "    # print(\"Baseline Report\")\n",
    "    # print(classification_report(id_icr_data[\"label\"], id_icr_data[\"tta_predicted_class\"], digits=4, zero_division=0))\n",
    "    perf_records.append({\n",
    "        \"split\": id_icr_split,\n",
    "        \"selective augmentation\": None,\n",
    "        \"accuracy\": classification_report(id_icr_data[\"label\"], id_icr_data[\"tta_predicted_class\"], digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "    })\n",
    "\n",
    "    # print(\"Only Augment Response Label Report\")\n",
    "    selective_predictions = id_icr_data.apply(lambda row: row[\"tta_predicted_class\"] if row[\"label\"] in labels_list else row[\"original_predicted_class\"], axis=1)\n",
    "    # print(classification_report(id_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0))\n",
    "    perf_records.append({\n",
    "        \"split\": id_icr_split,\n",
    "        \"selective augmentation\": \"class-based\",\n",
    "        \"accuracy\": classification_report(id_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "    })\n",
    "\n",
    "    # print(\"Evlauate on OOD Shifts\")\n",
    "    for ood_icr_report in [shift for shift in ood_icr_reports if id_icr_split[:10] in shift]:\n",
    "        ood_icr_data = inference_logs[ood_icr_report].to_pandas()\n",
    "        # print(f\"{ood_icr_report} TTA Baseline:\")\n",
    "        # print(classification_report(ood_icr_data[\"label\"], ood_icr_data[\"tta_predicted_class\"], digits=4, zero_division=0))\n",
    "        perf_records.append({\n",
    "            \"split\": ood_icr_report,\n",
    "            \"selective augmentation\": None,\n",
    "            \"accuracy\": classification_report(ood_icr_data[\"label\"], ood_icr_data[\"tta_predicted_class\"], digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "        })\n",
    "\n",
    "        # print(f\"{ood_icr_report} Selective Augment: Class-based:\")\n",
    "        selective_predictions = ood_icr_data.apply(lambda row: row[\"tta_predicted_class\"] if row[\"label\"] in labels_list else row[\"original_predicted_class\"], axis=1)\n",
    "        # print(classification_report(ood_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0))\n",
    "        perf_records.append({\n",
    "            \"split\": ood_icr_report,\n",
    "            \"selective augmentation\": \"class-based\",\n",
    "            \"accuracy\": classification_report(ood_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "        })\n",
    "\n",
    "        # print(f\"{ood_icr_report} Selective Augment: Entropy-based\")\n",
    "        enthropy_threshold = optimal_thresholds[id_icr_split][\"threshold\"]\n",
    "        accuracy = get_entropy_threshold_accuracy(enthropy_threshold, ood_icr_data)[0]\n",
    "        perf_records.append({\n",
    "            \"split\": ood_icr_report,\n",
    "            \"selective augmentation\": \"entropy-based\",\n",
    "            \"accuracy\": classification_report(ood_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "        })\n",
    "\n",
    "        # print(f\"{ood_icr_report} Selective Augment: Class-based & Entropy-based\")\n",
    "        selective_predictions = ood_icr_data.apply(lambda row: row[\"tta_predicted_class\"] if row[\"label\"] in labels_list and  row[\"original_prediction_entropy\"] < enthropy_threshold else row[\"original_predicted_class\"], axis=1)\n",
    "        # print(classification_report(ood_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0))\n",
    "        perf_records.append({\n",
    "            \"split\": ood_icr_report,\n",
    "            \"selective augmentation\": \"class-based & entropy-based\",\n",
    "            \"accuracy\": classification_report(ood_icr_data[\"label\"], selective_predictions, digits=4, zero_division=0, output_dict=True)[\"accuracy\"],\n",
    "        })\n",
    "\n",
    "\n",
    "pd.DataFrame(perf_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy-Based Selective Augmentation# Entropy Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Accuracy Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 1, 0.01)\n",
    "# thresholds = np.arange(0, 1, 0.05)\n",
    "\n",
    "baseline_perf = {\n",
    "    \"SST-5\": 0.6847,\n",
    "    \"Sem Eval\": 0.4498,\n",
    "    \"Dynasent\": 0.4271,\n",
    "    \"ToxiGen\": 0.6670,\n",
    "    \"Adv Civil\": 0.3050,\n",
    "    \"Implicit Hate\": 0.6454,\n",
    "    \"AG News Tweets\": 0.8857,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fix where each plot is 5 inches wide and 5 inches tall with 2 padding\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 6))\n",
    "\n",
    "def calculate_entropy_threshold_jugments(inference_log_frame, dataset_name, half=False):\n",
    "    threshold_scores = []\n",
    "    threshold_rewrite_rates = []\n",
    "    for t in tqdm(thresholds, desc=\"Calculating entropy threshold scores\"):\n",
    "        t_perf, t_rate = get_threshold_accuracy(t, inference_log_frame)\n",
    "        threshold_scores.append(t_perf)\n",
    "        threshold_rewrite_rates.append(t_rate)\n",
    "\n",
    "    thresholds_frame = pd.DataFrame({\"threshold\": thresholds, \"accuracy\": threshold_scores, \"rewrite_rate\": threshold_rewrite_rates})\n",
    "\n",
    "    # Set line splot\n",
    "    coordinates = {\n",
    "        \"SST-5\": 0,\n",
    "        \"ToxiGen\": 1,\n",
    "        \"AG News Tweets\": 2,\n",
    "    }\n",
    "\n",
    "    # Create a line plot with the coordinates in the grid\n",
    "    figure = axs[coordinates[dataset_name]]\n",
    "    figure = sns.lineplot(data=thresholds_frame, x=\"rewrite_rate\", y=\"accuracy\", label=\"TTA\", ax=figure)\n",
    "    figure.set_title(dataset_name, fontsize=18, pad=15)\n",
    "    figure.set_xlabel(\"Augmentation Rate\" if dataset_name == \"ToxiGen\" else \"\", labelpad=20, fontsize=14)\n",
    "    figure.set_ylabel(\"Accuracy\" if dataset_name == \"SST-5\" else \"\", labelpad=20, fontsize=14)\n",
    "    figure.title.set_size(18)\n",
    "    figure.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.0%}\".format(x)))\n",
    "    figure.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.2%}\".format(x)))\n",
    "    figure.set_xlim(left=0)\n",
    "    figure.lines[0].set_linewidth(2)\n",
    "    figure.legend_.remove()\n",
    "\n",
    "    # Display max accuracy point\n",
    "    accuracy_max_point = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1].to_dict()\n",
    "    figure.plot(accuracy_max_point[\"rewrite_rate\"],\n",
    "                accuracy_max_point[\"accuracy\"],\n",
    "                marker=\"o\",\n",
    "                markersize=6,\n",
    "                label=\"Optimal\",\n",
    "                )\n",
    "    figure.annotate(f\"{accuracy_max_point['accuracy']:.2%}\",\n",
    "                    (accuracy_max_point[\"rewrite_rate\"], accuracy_max_point[\"accuracy\"]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(10, 0),\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10)\n",
    "\n",
    "    # plot dashed gray line representing the baseline withour augmentation\n",
    "    figure.plot([0, 1], [baseline_perf[dataset_name], baseline_perf[dataset_name]], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75, label=\"No TTA (Baseline)\")\n",
    "    # figure.axhline(baseline_perf[dataset_name], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75)\n",
    "    if dataset_name == \"SST-5\":\n",
    "        figure.set_ylim(bottom=baseline_perf[dataset_name] - 0.005)\n",
    "\n",
    "    if dataset_name == \"ToxiGen\":\n",
    "        figure.legend(loc=\"upper center\", fontsize=12, frameon=False, ncol=3,\n",
    "                      bbox_to_anchor=(0.5, -0.2),\n",
    "                      )\n",
    "\n",
    "    target_threshold = None\n",
    "    if half is False:\n",
    "        target_threshold = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1]\n",
    "    else:\n",
    "        thresholds_deltas_list = abs(thresholds_frame[\"rewrite_rate\"] - 50).tolist()\n",
    "        closest_half_delta = min(thresholds_deltas_list)\n",
    "        closest_threshold_index = thresholds_deltas_list.index(closest_half_delta)\n",
    "        target_threshold = thresholds_frame.iloc[closest_threshold_index]\n",
    "\n",
    "    rewrite_rate = target_threshold[\"rewrite_rate\"] / 100\n",
    "    original_judgments = inference_log_frame.apply(lambda row: row[\"original_predicted_class\"] if row[\"original_prediction_entropy\"] < target_threshold[\"threshold\"] else row[\"tta_predicted_class\"], axis=1)\n",
    "    return original_judgments, rewrite_rate\n",
    "\n",
    "\n",
    "calculate_entropy_threshold_jugments(inference_logs[\"BOSS_Sentiment_ID_BERT_ICR\"].to_pandas(), \"SST-5\")\n",
    "calculate_entropy_threshold_jugments(inference_logs[\"BOSS_Toxicity_ID_BERT_ICR\"].to_pandas(), \"ToxiGen\")\n",
    "calculate_entropy_threshold_jugments(inference_logs[\"AgNewsTweets_ID_BERT_ICR\"].to_pandas(), \"AG News Tweets\")\n",
    "fig.tight_layout(pad=1.0)\n",
    "fig.savefig(\"../datasets/analysis/entropy_figures/main_acc_rewrite_curves.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix Entropy Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 10), nrows=2)\n",
    "\n",
    "def calculate_entropy_threshold_jugments(inference_log_frame, dataset_name, half=False):\n",
    "    # thresholds = np.arange(0, 1, 0.0001)\n",
    "    threshold_scores = []\n",
    "    threshold_rewrite_rates = []\n",
    "    for t in tqdm(thresholds, desc=\"Calculating entropy threshold scores\"):\n",
    "        t_perf, t_rate = get_threshold_accuracy(t, inference_log_frame)\n",
    "        threshold_scores.append(t_perf)\n",
    "        threshold_rewrite_rates.append(t_rate)\n",
    "\n",
    "    thresholds_frame = pd.DataFrame({\"threshold\": thresholds, \"accuracy\": threshold_scores, \"rewrite_rate\": threshold_rewrite_rates})\n",
    "\n",
    "    # Set line splot\n",
    "    coordinates = {\n",
    "        \"SST-5\": (0, 0),\n",
    "        \"Sem Eval\": (0, 1),\n",
    "        \"Dynasent\": (0, 2),\n",
    "        \"ToxiGen\": (0, 3),\n",
    "        \"Adv Civil\": (1, 0),\n",
    "        \"Implicit Hate\": (1, 1),\n",
    "        \"AG News Tweets\": (1, 2),\n",
    "    }\n",
    "\n",
    "    # Create a line plot with the coordinates in the grid\n",
    "    figure = axs[coordinates[dataset_name][0]][coordinates[dataset_name][1]]\n",
    "    figure = sns.lineplot(data=thresholds_frame, x=\"rewrite_rate\", y=\"accuracy\", label=\"TTA\", ax=figure)\n",
    "    figure.set_title(dataset_name, fontsize=18, pad=15)\n",
    "    figure.set_xlabel(\"Augmentation Rate\" if dataset_name in [\"ToxiGen\", \"Adv Civil\", \"Implicit Hate\", \"AG News Tweets\"] else \"\", labelpad=20, fontsize=14)\n",
    "    figure.set_ylabel(\"Accuracy\" if dataset_name in [\"SST-5\", \"Adv Civil\"] else \"\", labelpad=20, fontsize=14)\n",
    "    figure.title.set_size(18)\n",
    "    figure.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.0%}\".format(x)))\n",
    "    figure.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:.2%}\".format(x)))\n",
    "    figure.set_xlim(left=0)\n",
    "    figure.lines[0].set_linewidth(2)\n",
    "    figure.legend_.remove()\n",
    "\n",
    "    # Display max accuracy point\n",
    "    accuracy_max_point = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1].to_dict()\n",
    "    figure.plot(accuracy_max_point[\"rewrite_rate\"],\n",
    "                accuracy_max_point[\"accuracy\"],\n",
    "                marker=\"o\",\n",
    "                markersize=6,\n",
    "                label=\"Optimal\",\n",
    "                )\n",
    "    figure.annotate(f\"{accuracy_max_point['accuracy']:.2%}\",\n",
    "                    (accuracy_max_point[\"rewrite_rate\"], accuracy_max_point[\"accuracy\"]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(10, 0),\n",
    "                    ha=\"left\",\n",
    "                    fontsize=10)\n",
    "\n",
    "    figure.plot([0, 1], [baseline_perf[dataset_name], baseline_perf[dataset_name]], color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.75, label=\"No TTA (Baseline)\")\n",
    "\n",
    "    if dataset_name == \"SST-5\":\n",
    "        figure.set_ylim(bottom=baseline_perf[dataset_name] - 0.005)\n",
    "\n",
    "    target_threshold = None\n",
    "    if half is False:\n",
    "        target_threshold = thresholds_frame[thresholds_frame[\"accuracy\"] == thresholds_frame.max()[\"accuracy\"]].sort_values(\"rewrite_rate\").iloc[-1]\n",
    "    else:\n",
    "        thresholds_deltas_list = abs(thresholds_frame[\"rewrite_rate\"] - 50).tolist()\n",
    "        closest_half_delta = min(thresholds_deltas_list)\n",
    "        closest_threshold_index = thresholds_deltas_list.index(closest_half_delta)\n",
    "        target_threshold = thresholds_frame.iloc[closest_threshold_index]\n",
    "\n",
    "    rewrite_rate = target_threshold[\"rewrite_rate\"] / 100\n",
    "    original_judgments = inference_log_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < target_threshold[\"threshold\"] else row[\"judgment\"], axis=1)\n",
    "    return original_judgments, rewrite_rate\n",
    "\n",
    "\n",
    "def get_threshold_accuracy(threshold, inference_logs_frame):\n",
    "    threshold_judgments = inference_logs_frame.apply(lambda row: row[\"original judgment\"] if row[\"original entropy\"] < threshold else row[\"judgment\"], axis=1)\n",
    "    report = classification_report(inference_logs_frame[\"label\"], threshold_judgments, digits=4, output_dict=True)\n",
    "    llm_call_count = (inference_logs_frame[\"original entropy\"] >= threshold).sum()\n",
    "    llm_call_rate = llm_call_count / len(inference_logs_frame)\n",
    "    return report[\"accuracy\"], llm_call_rate\n",
    "\n",
    "\n",
    "calculate_entropy_threshold_jugments(sst5_data, \"SST-5\")\n",
    "calculate_entropy_threshold_jugments(semval_data, \"Sem Eval\")\n",
    "calculate_entropy_threshold_jugments(dynasent_data, \"Dynasent\")\n",
    "calculate_entropy_threshold_jugments(toxigen_data, \"ToxiGen\")\n",
    "calculate_entropy_threshold_jugments(adv_civil_data, \"Adv Civil\")\n",
    "calculate_entropy_threshold_jugments(implicit_hate_data, \"Implicit Hate\")\n",
    "calculate_entropy_threshold_jugments(agt_data, \"AG News Tweets\")\n",
    "\n",
    "fig.delaxes(axs[1, -1])\n",
    "fig.legend(loc=\"lower center\", fontsize=12, frameon=False, ncol=3, labels=[\"TTA\", \"No TTA (Baseline)\", \"Optimal Aug Rate\"], bbox_to_anchor=(0.5, -0.025))\n",
    "fig.tight_layout(pad=2.0)\n",
    "fig.savefig(\"../datasets/analysis/entropy_figures/appendix_acc_rewrite_curves.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_eval_original_entropies = semval_data[\"original entropy\"].tolist()\n",
    "figure = sns.scatterplot(data=semval_data, x=range(len(sem_eval_original_entropies)), y=\"original entropy\", hue=\"outcome\", s=5)\n",
    "# set legend to the right vertically\n",
    "figure.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0, frameon=False, title=\"Outcome\")\n",
    "# make y axis log scale\n",
    "figure.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst5_data[[\"original entropy\", \"outcome\"]].groupby(\"outcome\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap between original entropy and outcome\n",
    "pd.crosstab(sst5_data[\"original entropy\"], semval_data[\"outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
