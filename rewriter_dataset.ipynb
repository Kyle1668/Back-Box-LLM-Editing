{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import faiss\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import nlpaug.augmenter.word as naw\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from util_modeling import get_model_objects\n",
    "from util_data import get_formatted_dataset, get_num_labels\n",
    "from adaptive_methods import get_paraphrase_augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_formatted_dataset(\"boss_sentiment\")\n",
    "train_set = datasets[\"train\"].to_pandas().drop(columns=[\"__index_level_0__\"])\n",
    "test_set = datasets[\"validation\"].to_pandas().drop(columns=[\"__index_level_0__\"])\n",
    "display(train_set.head())\n",
    "display(test_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-roberta-large\")\n",
    "model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-roberta-large\").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_embeddings = torch.load(\"notebooks/dynasent_analysis/amazon_embeddings.pt\")\n",
    "train_set[\"embedding\"] = amazon_embeddings.tolist()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    return model(**tokens)[\"pooler_output\"].detach().cpu().numpy()\n",
    "\n",
    "test_set[\"embedding\"] = test_set[\"text\"].progress_apply(get_embedding)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_embeddings = torch.Tensor(np.stack(test_set[\"embedding\"])).squeeze(1)\n",
    "display(test_set_embeddings.shape)\n",
    "torch.save(test_set_embeddings, \"notebooks/dynasent_analysis/amazon_validation_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_set[\"label\"].unique()\n",
    "vector_stores = {}\n",
    "centroids = {}\n",
    "centroid_examples = {}\n",
    "k = 10\n",
    "d = 1024\n",
    "\n",
    "for label in labels:\n",
    "    label_instances = train_set[train_set[\"label\"] == label]\n",
    "    label_embeddings = np.stack(label_instances[\"embedding\"].to_numpy()).astype(np.float32)\n",
    "    \n",
    "    faiss.normalize_L2(label_embeddings)\n",
    "    vector_stores[label] = faiss.IndexFlatIP(d)\n",
    "    vector_stores[label].add(label_embeddings)\n",
    "    centroids[label] = label_embeddings.mean(axis=0)\n",
    "    \n",
    "    cosine_sims, centroid_example_indices = vector_stores[label].search(centroids[label].reshape(1, -1), k)\n",
    "    centroid_examples[label] = []\n",
    "    for index in centroid_example_indices[0]:\n",
    "        centroid_examples[label].append(label_instances.iloc[index][\"text\"])\n",
    "\n",
    "centroid_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set_records = []\n",
    "for inde, row in tqdm(train_set.iterrows(), total=len(train_set)):\n",
    "    current_label = row[\"label\"]\n",
    "    current_text = row[\"text\"]\n",
    "    for example in centroid_examples[current_label]:\n",
    "        new_train_set_records.append({\"text\": current_text, \"label\": example, \"class\": current_label})\n",
    "\n",
    "rewrite_train_set = pd.DataFrame(new_train_set_records).sample(frac=1).reset_index(drop=True)\n",
    "rewrite_train_set.to_csv(\"datasets/corrupted/boss_sentiment_train.csv\", index=False)\n",
    "display(rewrite_train_set)\n",
    "\n",
    "new_test_set_records = []\n",
    "for inde, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "    current_label = row[\"label\"]\n",
    "    current_text = row[\"text\"]\n",
    "    for example in centroid_examples[current_label]:\n",
    "        new_test_set_records.append({\"text\": current_text, \"label\": example, \"class\": current_label})\n",
    "\n",
    "rewrite_test_set = pd.DataFrame(new_test_set_records).sample(frac=1).reset_index(drop=True)\n",
    "rewrite_test_set.to_csv(\"datasets/corrupted/boss_sentiment_test.csv\", index=False)\n",
    "display(rewrite_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_tokenizer, paraphrase_model = get_model_objects(\"humarin/chatgpt_paraphraser_on_T5_base\", num_labels=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This product is essential for me to use every day, and I highly recommend it to anyone with special needs who has thin hair.',\n",
       " 'My daily routine involves this product and I highly recommend it to individuals with special needs who have thinning hair.',\n",
       " \"It's a lifesaver for anyone with special needs and hair loss, as it has transformed my daily routine.\",\n",
       " \"I use this product every day. It's a lifesaver for people with special needs and hair loss.\"]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"I use this every day I would recommend this for anyone who has special needs with thinning hair, it has made a huge difference in my daily life.\"\n",
    "get_paraphrase_augmentations(example_text,\n",
    "                             paraphrase_tokenizer,\n",
    "                             paraphrase_model,\n",
    "                             paraphrase_model.device,\n",
    "                             num_return_sequences=4,\n",
    "                             temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29999/29999 [7:47:40<00:00,  1.07it/s]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hadn't brewed tea in months and my son had n...</td>\n",
       "      <td>Works perfectly for what I need it for. Feels ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ended within a year.</td>\n",
       "      <td>EDIT: I'm leaving my original review below but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am bursting with food cravings, and this is ...</td>\n",
       "      <td>I like this product.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The color change on my entire body was quite s...</td>\n",
       "      <td>The ends are fairly sharp, but some were dulle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our mobility is compromised by the screws fall...</td>\n",
       "      <td>I bought this product because of the ratings, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499945</th>\n",
       "      <td>It's not entirely overstated, but it'll be a b...</td>\n",
       "      <td>My expectations were probably a bit high since...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499946</th>\n",
       "      <td>I have loved Steve since the mid 80's. I would...</td>\n",
       "      <td>I am not terribly impressed with this case, gl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499947</th>\n",
       "      <td>The quality of things is not good.</td>\n",
       "      <td>If I could have 0 stars I would, this was comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499948</th>\n",
       "      <td>The availability of multiple size options in C...</td>\n",
       "      <td>Great product and quality. I recommend this pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499949</th>\n",
       "      <td>Easily accessible, precise, and user-friendly ...</td>\n",
       "      <td>I like this product.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1499950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0        I hadn't brewed tea in months and my son had n...   \n",
       "1                                     Ended within a year.   \n",
       "2        I am bursting with food cravings, and this is ...   \n",
       "3        The color change on my entire body was quite s...   \n",
       "4        Our mobility is compromised by the screws fall...   \n",
       "...                                                    ...   \n",
       "1499945  It's not entirely overstated, but it'll be a b...   \n",
       "1499946  I have loved Steve since the mid 80's. I would...   \n",
       "1499947                 The quality of things is not good.   \n",
       "1499948  The availability of multiple size options in C...   \n",
       "1499949  Easily accessible, precise, and user-friendly ...   \n",
       "\n",
       "                                                     label  class  \n",
       "0        Works perfectly for what I need it for. Feels ...      1  \n",
       "1        EDIT: I'm leaving my original review below but...      0  \n",
       "2                                     I like this product.      1  \n",
       "3        The ends are fairly sharp, but some were dulle...      2  \n",
       "4        I bought this product because of the ratings, ...      0  \n",
       "...                                                    ...    ...  \n",
       "1499945  My expectations were probably a bit high since...      2  \n",
       "1499946  I am not terribly impressed with this case, gl...      2  \n",
       "1499947  If I could have 0 stars I would, this was comp...      0  \n",
       "1499948  Great product and quality. I recommend this pr...      1  \n",
       "1499949                               I like this product.      1  \n",
       "\n",
       "[1499950 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_train_set_records = []\n",
    "for _, row in tqdm(train_set.iterrows(), total=len(train_set)):\n",
    "    current_label = row[\"label\"]\n",
    "    current_text = row[\"text\"]\n",
    "    augmentations = get_paraphrase_augmentations(current_text,\n",
    "                             paraphrase_tokenizer,\n",
    "                             paraphrase_model,\n",
    "                             paraphrase_model.device,\n",
    "                             num_return_sequences=4,\n",
    "                             temperature=0.3)\n",
    "    \n",
    "    for example in centroid_examples[current_label]:\n",
    "        for text_input in [current_text] + augmentations:\n",
    "            new_train_set_records.append({\"text\": text_input, \"label\": example, \"class\": current_label})\n",
    "\n",
    "rewrite_train_set = pd.DataFrame(new_train_set_records).sample(frac=1).reset_index(drop=True)\n",
    "rewrite_train_set.to_csv(\"datasets/corruped/boss_sentiment_augmented_train.csv\", index=False)\n",
    "display(rewrite_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38904/38904 [8:47:49<00:00,  1.23it/s]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good quality</td>\n",
       "      <td>Works perfectly for what I need it for. Feels ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's a wonderful invention.</td>\n",
       "      <td>Really a very nice product. Works great and so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despite trying out other filament brands, I'll...</td>\n",
       "      <td>Really a very nice product. Works great and so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utilizing H &amp; R Block (Tax Cut) for over 10 ye...</td>\n",
       "      <td>Excellent product, I love it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staying steady is a great value. The price is ...</td>\n",
       "      <td>Works perfectly for what I need it for. Feels ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945195</th>\n",
       "      <td>Similar to my old experience of buying from be...</td>\n",
       "      <td>Really a very nice product. Works great and so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945196</th>\n",
       "      <td>Comprehending my expectations.</td>\n",
       "      <td>I like this product.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945197</th>\n",
       "      <td>I acquired this item for a project that is rel...</td>\n",
       "      <td>very nice &amp; I like it for everything I used it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945198</th>\n",
       "      <td>The matte finish necessitates clear coats, inc...</td>\n",
       "      <td>Nothing special. Just like every other strap o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945199</th>\n",
       "      <td>Almond breeze is a great brand of almond milk....</td>\n",
       "      <td>good product. I would buy it again. Excellent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1945200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0                                             Good quality   \n",
       "1                              It's a wonderful invention.   \n",
       "2        Despite trying out other filament brands, I'll...   \n",
       "3        Utilizing H & R Block (Tax Cut) for over 10 ye...   \n",
       "4        Staying steady is a great value. The price is ...   \n",
       "...                                                    ...   \n",
       "1945195  Similar to my old experience of buying from be...   \n",
       "1945196                     Comprehending my expectations.   \n",
       "1945197  I acquired this item for a project that is rel...   \n",
       "1945198  The matte finish necessitates clear coats, inc...   \n",
       "1945199  Almond breeze is a great brand of almond milk....   \n",
       "\n",
       "                                                     label  class  \n",
       "0        Works perfectly for what I need it for. Feels ...      1  \n",
       "1        Really a very nice product. Works great and so...      1  \n",
       "2        Really a very nice product. Works great and so...      1  \n",
       "3                            Excellent product, I love it.      1  \n",
       "4        Works perfectly for what I need it for. Feels ...      1  \n",
       "...                                                    ...    ...  \n",
       "1945195  Really a very nice product. Works great and so...      1  \n",
       "1945196                               I like this product.      1  \n",
       "1945197  very nice & I like it for everything I used it...      1  \n",
       "1945198  Nothing special. Just like every other strap o...      2  \n",
       "1945199      good product. I would buy it again. Excellent      1  \n",
       "\n",
       "[1945200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_test_set_records = []\n",
    "for _, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "    current_label = row[\"label\"]\n",
    "    current_text = row[\"text\"]\n",
    "    augmentations = get_paraphrase_augmentations(current_text,\n",
    "                             paraphrase_tokenizer,\n",
    "                             paraphrase_model,\n",
    "                             paraphrase_model.device,\n",
    "                             num_return_sequences=4,\n",
    "                             temperature=0.3)\n",
    "    \n",
    "    for example in centroid_examples[current_label]:\n",
    "        for text_input in [current_text] + augmentations:\n",
    "            new_test_set_records.append({\"text\": text_input, \"label\": example, \"class\": current_label})\n",
    "\n",
    "rewrite_test_set = pd.DataFrame(new_test_set_records).sample(frac=1).reset_index(drop=True)\n",
    "rewrite_test_set.to_csv(\"datasets/corruped/boss_sentiment_augmented_test.csv\", index=False)\n",
    "display(rewrite_test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
